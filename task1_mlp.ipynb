{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3Q--7ksYKDex",
    "outputId": "cb68d890-888d-4d4c-a3ab-def7dc13cd14"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "eimPJuSzKIEv",
    "outputId": "e28c6887-e5b5-449a-b49f-aebda987505a"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist \n",
    "(Xf_train_full, yf_train_full), (Xf_test, yf_test) = fashion_mnist.load_data()\n",
    "Xf_valid, Xf_train = Xf_train_full[:5000] / 255.0, Xf_train_full[5000:] / 255.0\n",
    "yf_valid, yf_train = yf_train_full[:5000], yf_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "Xm, ym = mnist[\"data\"].reshape(-1, 28, 28), mnist[\"target\"]\n",
    "ym = np.array(ym, dtype='uint8')\n",
    "Xm_train_full, Xm_test, ym_train_full, ym_test = Xm[:60000], Xm[60000:], ym[:60000], ym[60000:]\n",
    "Xm_valid, Xm_train = Xm_train_full[:5000] / 255.0, Xm_train_full[5000:] / 255.0\n",
    "ym_valid, ym_train = ym_train_full[:5000], ym_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQn8JJhOm067"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ei9z3XCT28oO"
   },
   "source": [
    "### MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BeEBUDhPils3"
   },
   "outputs": [],
   "source": [
    "mlp_model = keras.models.Sequential([\n",
    "                                 keras.layers.Flatten(input_shape=[28,28]),\n",
    "                                 keras.layers.Dense(300, activation=\"relu\"),\n",
    "                                 keras.layers.Dense(100, activation=\"relu\"),\n",
    "                                 keras.layers.Dense(10, activation=\"softmax\")\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "UlYzUUu8kYKq",
    "outputId": "7a842cc5-e3db-4e28-e83b-01c5608b2bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtJoiFiwlzM3"
   },
   "outputs": [],
   "source": [
    "mlp_model.compile(\n",
    "    optimizer=\"sgd\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Zd_JADIy7dx"
   },
   "source": [
    "### Training and Evaluation on MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kss5tratmM8x",
    "outputId": "7121c6cd-a5f1-418a-8e2d-ed1762e56aa6",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 5s 90us/step - loss: 0.6164 - accuracy: 0.8422 - val_loss: 0.2979 - val_accuracy: 0.9180\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.2837 - accuracy: 0.9190 - val_loss: 0.2346 - val_accuracy: 0.9334\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.2319 - accuracy: 0.9334 - val_loss: 0.2059 - val_accuracy: 0.9404\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 3s 57us/step - loss: 0.1990 - accuracy: 0.9423 - val_loss: 0.1735 - val_accuracy: 0.9508\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.1744 - accuracy: 0.9501 - val_loss: 0.1553 - val_accuracy: 0.9570\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.1553 - accuracy: 0.9556 - val_loss: 0.1439 - val_accuracy: 0.9620\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.1397 - accuracy: 0.9603 - val_loss: 0.1317 - val_accuracy: 0.9646\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 3s 57us/step - loss: 0.1264 - accuracy: 0.9636 - val_loss: 0.1240 - val_accuracy: 0.9678\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 3s 57us/step - loss: 0.1155 - accuracy: 0.9674 - val_loss: 0.1153 - val_accuracy: 0.9686\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.1058 - accuracy: 0.9705 - val_loss: 0.1097 - val_accuracy: 0.9700\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.0968 - accuracy: 0.9729 - val_loss: 0.1016 - val_accuracy: 0.9710\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.0897 - accuracy: 0.9751 - val_loss: 0.1036 - val_accuracy: 0.9722\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0830 - accuracy: 0.9767 - val_loss: 0.0949 - val_accuracy: 0.9730\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 3s 57us/step - loss: 0.0767 - accuracy: 0.9788 - val_loss: 0.0927 - val_accuracy: 0.9720\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.0711 - accuracy: 0.9803 - val_loss: 0.0875 - val_accuracy: 0.9754\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 3s 57us/step - loss: 0.0660 - accuracy: 0.9818 - val_loss: 0.0841 - val_accuracy: 0.9758\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.0618 - accuracy: 0.9833 - val_loss: 0.0825 - val_accuracy: 0.9762\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.0578 - accuracy: 0.9841 - val_loss: 0.0774 - val_accuracy: 0.9778\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.0542 - accuracy: 0.9853 - val_loss: 0.0748 - val_accuracy: 0.9782\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 3s 58us/step - loss: 0.0504 - accuracy: 0.9867 - val_loss: 0.0747 - val_accuracy: 0.9784\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0476 - accuracy: 0.9877 - val_loss: 0.0759 - val_accuracy: 0.9792\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 3s 59us/step - loss: 0.0447 - accuracy: 0.9883 - val_loss: 0.0734 - val_accuracy: 0.9786\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 4s 68us/step - loss: 0.0421 - accuracy: 0.9892 - val_loss: 0.0706 - val_accuracy: 0.9782\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 5s 89us/step - loss: 0.0397 - accuracy: 0.9903 - val_loss: 0.0710 - val_accuracy: 0.9782\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 5s 88us/step - loss: 0.0374 - accuracy: 0.9908 - val_loss: 0.0697 - val_accuracy: 0.9790\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 5s 90us/step - loss: 0.0353 - accuracy: 0.9913 - val_loss: 0.0675 - val_accuracy: 0.9806\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 5s 89us/step - loss: 0.0333 - accuracy: 0.9920 - val_loss: 0.0691 - val_accuracy: 0.9784\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 5s 88us/step - loss: 0.0314 - accuracy: 0.9927 - val_loss: 0.0679 - val_accuracy: 0.9790\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 5s 89us/step - loss: 0.0297 - accuracy: 0.9931 - val_loss: 0.0672 - val_accuracy: 0.9794\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 5s 89us/step - loss: 0.0281 - accuracy: 0.9937 - val_loss: 0.0654 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "mlp_history = mlp_model.fit(Xm_train, ym_train, epochs=30, validation_data=(Xm_valid, ym_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "O4O7bXLa0S8f",
    "outputId": "3c77df4a-2dc7-42f0-d052-32fbecb42087",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(mlp_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "fmtL9T1insJZ",
    "outputId": "86583531-029e-466a-f46b-8b36603fb2a8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 51us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.42245971186473, 0.9768000245094299]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.evaluate(Xm_test, ym_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjfaQv5u0ytj"
   },
   "source": [
    "### Training and Evaluation on Fashion MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lD71-63un0EG",
    "outputId": "3a2d6115-2737-42ef-e732-33cd4e7738e5",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.6216 - accuracy: 0.7959 - val_loss: 0.4530 - val_accuracy: 0.8492\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.4332 - accuracy: 0.8471 - val_loss: 0.4011 - val_accuracy: 0.8628\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.3948 - accuracy: 0.8611 - val_loss: 0.3736 - val_accuracy: 0.8764\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 4s 82us/step - loss: 0.3706 - accuracy: 0.8688 - val_loss: 0.3584 - val_accuracy: 0.8774\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 5s 85us/step - loss: 0.3507 - accuracy: 0.8762 - val_loss: 0.3735 - val_accuracy: 0.8696\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 0.3363 - accuracy: 0.8797 - val_loss: 0.3489 - val_accuracy: 0.8780\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 4s 82us/step - loss: 0.3237 - accuracy: 0.8843 - val_loss: 0.3404 - val_accuracy: 0.8788\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.3132 - accuracy: 0.8885 - val_loss: 0.3314 - val_accuracy: 0.8814\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.3035 - accuracy: 0.8912 - val_loss: 0.3171 - val_accuracy: 0.8864\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.2950 - accuracy: 0.8951 - val_loss: 0.3151 - val_accuracy: 0.8890\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 4s 81us/step - loss: 0.2874 - accuracy: 0.8969 - val_loss: 0.3202 - val_accuracy: 0.8854\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.2797 - accuracy: 0.8997 - val_loss: 0.3140 - val_accuracy: 0.8850\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.2741 - accuracy: 0.9013 - val_loss: 0.3067 - val_accuracy: 0.8904\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 4s 82us/step - loss: 0.2684 - accuracy: 0.9030 - val_loss: 0.3042 - val_accuracy: 0.8922\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.2611 - accuracy: 0.9050 - val_loss: 0.3078 - val_accuracy: 0.8934\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 4s 82us/step - loss: 0.2556 - accuracy: 0.9079 - val_loss: 0.3105 - val_accuracy: 0.8868\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.2505 - accuracy: 0.9107 - val_loss: 0.2951 - val_accuracy: 0.8942\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.2455 - accuracy: 0.9112 - val_loss: 0.2971 - val_accuracy: 0.8892\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.2413 - accuracy: 0.9123 - val_loss: 0.3084 - val_accuracy: 0.8856\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.2349 - accuracy: 0.9156 - val_loss: 0.2983 - val_accuracy: 0.8918\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s 82us/step - loss: 0.2309 - accuracy: 0.9169 - val_loss: 0.2914 - val_accuracy: 0.8970\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 5s 84us/step - loss: 0.2260 - accuracy: 0.9195 - val_loss: 0.3022 - val_accuracy: 0.8906\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.2222 - accuracy: 0.9192 - val_loss: 0.2993 - val_accuracy: 0.8940\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.2174 - accuracy: 0.9224 - val_loss: 0.3166 - val_accuracy: 0.8872\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s 82us/step - loss: 0.2142 - accuracy: 0.9231 - val_loss: 0.3071 - val_accuracy: 0.8928\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.2103 - accuracy: 0.9239 - val_loss: 0.2932 - val_accuracy: 0.8968\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.2065 - accuracy: 0.9245 - val_loss: 0.3061 - val_accuracy: 0.8906\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 5s 82us/step - loss: 0.2022 - accuracy: 0.9262 - val_loss: 0.2988 - val_accuracy: 0.8922\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.2003 - accuracy: 0.9282 - val_loss: 0.2909 - val_accuracy: 0.8950\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 4s 82us/step - loss: 0.1951 - accuracy: 0.9305 - val_loss: 0.3047 - val_accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "mlp_fashion_history = mlp_model.fit(Xf_train, yf_train, epochs=30, validation_data=(Xf_valid, yf_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "V8dMNU9W1LN5",
    "outputId": "12deac71-c1cb-41f0-a535-20785119076a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXycZb3//9c1+z5ZJnuzNN3SHWxpS8uSggoqUs8RWUREFDgeRRQUBY9y+PrV8z2Hr3r0+9Oj4gYIWlDEBaqoQAothS4shRK6pU2Tps2+TZLZr98f92SStJM2bdNOmnyej8f9uJe5Z+aaK+2857ru675vpbVGCCGEEJljynQBhBBCiKlOwlgIIYTIMAljIYQQIsMkjIUQQogMkzAWQgghMkzCWAghhMiw44axUuoXSqkWpdRbozyulFL/Tym1Rym1XSn1rvEvphBCCDF5jaVl/CBw+TEefx8wKzndCvzo1IslhBBCTB3HDWOt9QtAxzF2WQM8rA0vA1lKqaLxKqAQQggx2Y3HMeMSoGHYemNymxBCCCHGwDIOr6HSbEt7jU2l1K0YXdk4nc4lpaWl4/D2hkQigckk49GOJPWSntRLelIv6Um9pCf1kt5o9bJr1642rXVeuueMRxg3AsNTdRrQlG5HrfUDwAMAS5cu1Vu3bh2HtzfU1NRQXV09bq83WUi9pCf1kp7US3pSL+lJvaQ3Wr0opepHe854/KT5E/Dx5KjqFUC31vrQOLyuEEIIMSUct2WslPoNUA0ElFKNwL8DVgCt9Y+BdcD7gT1AP3DT6SqsEEIIMRkdN4y11tcd53ENfHbcSiSEEEJMMXLkXQghhMgwCWMhhBAiwySMhRBCiAyTMBZCCCEyTMJYCCGEyDAJYyGEECLDJIyFEEKIDJMwFkIIITJMwlgIIYTIMAljIYQQIsMkjIUQQogMkzAWQgghMkzCWAghhMiw4961SQghhDgb6GiURChEYmAAHQqRCIWMef8AiYF+Ev396IEBEv39ySm5PNCf2qZT2wZQNhuVf3jyjJRdwlgIIcSYaK0hFkPH4+hYHNXXR6yzE+JxdDxuzBMJY59EIrWuYzEYXE8+V4dDJMJhdCiMjoSN4AxHRi4ftU/YCNNwGB0aIDGQDNzkNmKxE/tAFgsmlwuT0zlibg7kYnW6MPv9p6ci0xXljL2TEEKIE6YTCRLBIIneXuK9val5vKeHRG+QeO/QXPcPGGEXj0E8MWweHxmY8Tg6EYfYsPng85LLqdAdtkwiMaJs+cDu0/GhTSaUw4HJbkfZ7am5stsxOZ2Ys7MwOYowOR0ohxOTw27MnQ6U3ZHc7sDkcKIcdkwOJya3a2Twulwom+10lP6kSBgLIQTJVl80anR1RiLoaBQdiaKjESyNjfS/+iqJvr5hUz+J/r6R2/r7SfT1EU+u63AElAIFCmUsm0xD25QChm8zthOLEw/2kugNkggGQetjll05nZi9XkxOJ1gtKJMZLGaUyYwym8FszJXNllw3ocyW1FyZTWCxGMuWwf0Hly3Gcyzmox7fu6+OmbPnGNtMZuN1TOaR68n3xmQaVhZLMkAdKJvdWLbbjSC121BW6xn5m08kEsZCiLOS1toIxJ5uo6XY3U2ip4d4d4/RWhy+3N1jtCSDQSNko1F0KnAjqW2jyQXqR3lMWa2Y3G5jcrkwud2YPV6sBYUou93YKZFIBqo2Ql+n2ZbQxrrWYDbj8Hoxeb1GyHq9mH3D132YvR5MPh9mjydj4fVmTQ051dUZee/JRsJYCHFMOhYjEQwSD/aR6DNaasZ6kESwz1gfGIBE8nhhQoNOoOOJZOAMLWudfHxw37hxPFFHo8Y8FoVoLLkcSz1GLIoevj0cJt7be+xjhEoZYeXzGQHm92EL5KKsNqOFaLUa0+DykfNhy2/v2c3CZcswu90olwvzsPCdSF2d4uwlYSzEJKVjMaPrNBWcQeOY42CABnuHArW3l3hfkKyGRvb94IcjnqNDobG/6WB3pFJGd+Rgt+yIZRNKDdtmtRjBZ7GiLJahyW7D5HYby9bkY1aLMejGbjdahz4fZr9vKHR9Pkw+v7HN7UaZxufszXBNDZ5Vq8bltYRIR8JYiDNocDRqIhxGh8PGaRfJUaM6nBwteuRo0oHBUzWSo0cH+tHJUaTDl3VowDhVY/DUjv7+4xfIbMbk8RgtPa8XFYthLizAVlaGyeNJTm7MHg8m9xHrg5Pbg8nlHLfgE2IqkjAWIumo7tje3pFdscFeY4BOOJw8BSNiBGo0YgTq4HokQiISTq4PbU9EIkYr84gRqWOmFMrpxORwYHI4UC6nMUrU4Rg2utSJchqjSE1ej9E9mwxRs3cwQL2pQFVOZ3IQkaGmpobFcgxQiDNOwlicdRIDA8S7uoh3dhLv6TVaj6HwyHMShy0nwslWZiiUapFmHWpi3w//J9U9mwj2oQcGjv/mShnHEe12lM2GyWYbsa7sNkwuJ+asrGHbjWOPJrvDOM0iOWpU2W1GqNrsI7ab7LaRo0ydTiNk7fYRwSnGkdbQ3wG9h6D38Mh5sJlFzY3Qswj8ZZA1bPIWgsmc6dKfHtEQDHRAf/uwaeT6vOZDEPobZJWCv3Ro7sw2RoZnSjwG4R4I90IkCDoBngJwBYxDJROQhLHICK21EY7JU0DiPb1GwA6GbFcX8S5jHuvsJN7Vndp+QscwrVYj5BwOIzgdRiCqSBRzfj620mlGy9HrPao7dqglaWwze49uSZ6QRAJiA8aX3KjzLoiFoG8AukPGcjwC8egR8+MsK7PxxZhVDtnlxjyrDHzFJx8ekX7o3Afte6GjDjr2Qnty3t8BnnzjC89bmFwuBG/BsHkBuPPBfIa/dmJh6G40pp6DaQL3MASbjbo7kjMHvEVYYhHY+Vfoaxn5uMkK/pJhAZ2sZ3+pMXflQKgbBrog1JWcdw9bTjMPdUMibjw/u2LYVG7MfSUn/zeMx4zP0NNk1MXgvLfZCNhU+HYYITYahx9cuXgGwrD1NePf73A2D/injQzowXrxTwNXLsTDxt8mFkrOh6+HjngsOY/2GwE7Yuo5etuR5RmkzMl/m6P8+xy+bLGfXB2fJAljcVK01kaXbkcHsY4OIyg7Ooh3dw917SYHDw2dhxk0zr9MPkY8PvobKIXZ68Hs92D2uLB6HDgKizA7yzC7zJjtCrMjgdluwuTxo7zZmLy5KG8uyh/A5M9H+fNR7ty0X/7j2h0bDhpf7D1NyS/4Q9BzCHqbkvND0NdmfPmcCrPN+PI3W41ls22UZasRyPteMMrEsHNUTVbjy3AwoFNBbSyb4mFoqU0G7t5hwVtnfGkP586DnEqoXA3uXOMz9h429q1/yfhiP4oCd2DoS8+dbwSWIwucWUaL6sjJ7jt2aybUA90N0NWQnB9Ihm9yW7B5ZB2A8X7eQmOquCC5XJT8MVGU/EFRAFYHAK/W1FBdXW38IOluTL7HAWM+OO3+e/K9ToDdl/zsfmMemGXMlTJe8+BW2PEk6GH/V0xWI+CyK5J/t4qhyeEz/gapsD00LHSbIHjYaCUOZ3EkfygFjJZjYI4Rlq6c5PyIZWe28W8M2FxTQ/XFFxsB3nVg2N+hcehvcXArDHSeWL0ci8kCdm9y8hlzTz7kzjh6++AEEGxJ/vA6bPz46G2Cptegr5Wj/n2A8TmzyuDW9WeklS9hLIDBczb7iLe1EWtvJ9beTryjk3hnB7GOZNCOWO4c/bxMpZKtSTcmj3H6h9lhxeLJwmT1Y7LEMZlimEwhTPRj1r2YEkHM5n7Mpj7MthhmawJ1rN6kOBB2QswKHT3H/nB231Ff9LM7gtD7B1CmNJMaZbvJaD31Hh4ZtOE072/3GV/qviIIXGQEl9VlfLlbnGOfW+zGZLKc3BfCYKuwc38yNOqhs96Yv/M09LeN2P0igBeHbXDlQs4MmH6REbw5lcaXXk6l0To65ntHjHAKtiS/AJMt0OHzllqjRRjtG/11lCkZWNlDf0eTJRmKDRDuHrm/2TbUKpv17mTXcrJF5p9m/F2szhOoxGFsLsibbUzpRAeGwrrrgNHSdfiHfmyklrON5bG0cOMx6En+DVNTvTFven2UHz2D5fUYvSG+YpixemjZVzI0P9UuZZX8geUOQMm70u8TDo4M6FCX8SPAbDPmFkfy3/px5lansTye4RiPGf8P0v37TETPWHe7hPEkpmMxVE8PoV27iLe3E2trJ95hzGMd7cTbjNAdXNaRNN10YHTZZmdjyfJhDfhxVBZj8Towu22Y3VYsLjNmp8Jij2O2RFCRNlTqS3hf+l/FymQElKcAPGXGL1u71/jysLmHlu2e5PyIdZtnqMWbiCe7AjuHTV1HrA+bug+S29sGPW8YrYTUpI9YP2JCG91cg62ovNlQWW0ErrfY2O4rNh6ze07Xn/XEWOxGeObOSP94pM/4ckwG9L7aN5j+rtWQW2mEsDPrFN7bluwqLz3+vrFw+r9ZKM22/nbjC9Q/DcrOHxa0ydB152fuuKDVabRuA7PG7zXNlqGWbzqh7qEfWKHu5I/AZNg6fONXjlNh90B+lTFNNGbLUC9JBkkYn4x4zDh2FgsZ3YGJmDHFo8YvqXgsOY8esT1q/BLOnm78Z/WVjOlXl45GibW0GF3A3d3GVYW6u4n3dJMYsd5DvKuLRJfRXZwYCJMP7DvyBc0Ki8uC2W3G4jJjzzFhnubE4nJhcYLZqbHYE6mWqineBvFdRxesPzmNeG17squvwAiAilXJwC0Y6vrzFhrdYeN17NBkTnaj5Yz5KZsGux1PxOAlCSfTICqbG/LnGhNQP1DD9EXVZ74cFrvxb8ZbcObf+2zn8EPRImMSZy0J47HQGlp3Ql2NMdVvTN81eaKsrmSrZRY6q5KoziPSZyfSFSdysJnIgXoi9fVEDzaNeqUhZTFjctkw28FsiWI19WN2xDD5EphtCXDasHsdRvC6TVjcVkxOC8psNULMZBk2DVs3W49omQ5rkdo9YPMe8Vhy/QwPejijJlMICyEmFAnj0XQfNIJ333qoW28c8wKjVbvgw1C6zGhVDA6oGQwwk9Vo8aW2D61rTESbGons2Epk1w4i+/cR2dRCtPVlIj2bQA992ZusGmuOHUdhNr4Fi7FNK8asezBHD2MaaMAcOoDZEkWZtZERWWWQVwV5c4wBGHlVkDebmpdfO/EWoBBCiDNKwnjQQCfs35Bs/a6H9uSNwVwBqLzYODY4/WJj9OkxaK2Jd3QQ2b+fyP7dRPbtI7x/P5H9+4nWHxgx6Em5XNjKy7GfX453WjG2gAubN47N3oM52oTq2ANtu2HgNejGOM6aUwllcyDvylTgEpht/DAQQghxVpq6YRwNQcPLRvDW1cCh141BOla3cZxz6U1G+ObPSzsYJNHfT6S+nsj+/YT37UuGr7Ge6BnqwlZWK9byMmwVFXhXr8ZWXo6tvBxreTmWvLyxnbPa32GcNpJVljrVQgghxOQxdcI4EYdDbwx1PR942RiAZbLAtPPgoi8brd+SJcYo0COfHokw8Oqr9G18ib6NGwnV1o64x6iluAh7RQX+Kz6ArWI6tukV2CoqsBYXG/fwPBUnODhJCCHE2WXyhrHWxgUL9tUkA/hF4zQJgPz5sPRTRvdz+cqhk8JHPF0T2bOH4MaN9L30Ev1bthqXS7RYcJ1zDoHPfAb7rJnYpk83LqrvPMnzFoUQQkx5kyuMe5uTA65qjO7nnkZju78U5l5hXClo+kXGOa1pxNrb6XtpE33JAI61GJe+s1VWkvXhD+NetRLXecswe+T4rBBCiPEzOcL4nXWct/krUHPAWHdmG6Fb+UXjuG9OZdrTUnQiQf/mzfRt2EBw40uEa2sBMPv9uFetxL3SmKzFxWfy0wghhJhiJkcY29yE7Tm4V37KOO5buOi4V+DR8ThNd99Dz5//DFYrrnPPJe8LX8C9ahWOeXNP/TivEEIIMUaTI4wrL2b74v9F9QXVY9pdx2JGED/1FIHbbiP3pk9gckvXsxBCiMyYHGF8AnQsRtOXv0LPunXkffFOArfckukiCSGEmOKmVBgbQfxletb9hfwvfZHcm2/OdJGEEEKIqRPGOhbj4F130fuXv5J/113kfuqTmS6SEEIIAUyRMNbRKAfv+jK9f/0r+V/+MrmfvCnTRRJCCCFSJn0Y62iUg1/8Er1/+xv5d3+F3E98ItNFEkIIIUaY1GGso1EO3vlFev/+dwliIYQQE9akDWMdiXDwi1+k9+//oOCr95Dz8Y9nukhCCCFEWpMyjHUkQuOddxL8x7MUfPWr5Hz8hkwXSQghhBjVsS9TlaSUulwptVMptUcpdXeax8uUUs8rpV5TSm1XSr1//Is6NjoSofGOZBB/7WsSxEIIISa844axUsoM/BB4HzAPuE4pNe+I3b4GPK61Phe4Fvif8S7oWCQiERo//wWCzz5Lwde/Rs7Hrs9EMYQQQogTMpaW8TJgj9a6TmsdAdYCa47YRwO+5LIfaBq/Io5RNMrB2z9P8PnnKbj36+RcL0EshBDi7KC01sfeQamrgMu11jcn128Almutbxu2TxHwNyAbcAPv1lpvS/NatwK3AhQUFCxZu3bt+HyKaBTP//wId20tPR+9joGLLhqf150EgsEgHo8n08WYcKRe0pN6SU/qJT2pl/RGq5fVq1dv01ovTfecsQzgOvreg0ZLeLjrgAe11t9RSp0P/EoptUBrnRjxJK0fAB4AWLp0qa6urh7D2x9f+y8fpKW2lsL77mPutdeMy2tOFjU1NYxXPU8mUi/pSb2kJ/WSntRLeidTL2MJ40agdNj6NI7uhv4UcDmA1nqTUsoBBICWEyrNScq54WPsDA1IEAshhDgrjeWY8RZgllJqulLKhjFA609H7HMAuBRAKTUXcACt41nQY1EWC5G5c8/U2wkhhBDj6rhhrLWOAbcBzwC1GKOmdyilvqGUujK52xeBW5RSbwC/AT6hj3cwWgghhBDAGC/6obVeB6w7Ytu9w5bfBlaNb9GEEEKIqWFMF/0QQgghxOkjYSyEEEJkmISxEEIIkWESxkIIIUSGSRgLIYQQGSZhLIQQQmSYhLEQQgiRYRLGQgghRIZJGAshhBAZJmEshBBCZJiEsRBCCJFhEsZCCCFEhkkYCyGEEBkmYSyEEEJkmISxEEIIkWESxkIIIUSGSRgLIYQQGSZhLIQQQmSYhLEQQgiRYRLGQgghRIZJGAshhBAZJmEshBBCZJiEsRBCCJFhEsZCCCFEhkkYCyGEEBkmYSyEEEJkmISxEEIIkWESxkIIIUSGSRgLIYQQGSZhLIQQQmSYhLEQQgiRYRLGQgghRIZJGAshhBAZJmEshBBCZJiEsRBCCJFhEsZCCCFEhkkYCyGEEBkmYSyEEEJkmISxEEIIkWESxkIIIUSGSRgLIYQQGTZpwjiu45kughBCCHFSJkUY/3nvn7m74W56Ij2ZLooQQghxwiZFGE/zTiOkQ2w+tDnTRRFCCCFO2KQI4wWBBTiUg5eaXsp0UYQQQogTNqYwVkpdrpTaqZTao5S6e5R9rlZKva2U2qGU+vX4FvPYrCYrsxyzeKnpJbTWZ/KthRBCiFN23DBWSpmBHwLvA+YB1yml5h2xzyzgHmCV1no+8IXTUNZjqnJWcTB4kIbehjP91kIIIcQpGUvLeBmwR2tdp7WOAGuBNUfscwvwQ611J4DWumV8i3l8cx1zAaSrWgghxFlnLGFcAgxvbjYmtw03G5itlNqolHpZKXX5eBVwrAKWACWeEgljIYQQZx3LGPZRabYdeWDWAswCqoFpwItKqQVa664RL6TUrcCtAAUFBdTU1JxoeUfV19dHBRVsatzEs88/i1mZx+21z2bBYHBc63mykHpJT+olPamX9KRe0juZehlLGDcCpcPWpwFNafZ5WWsdBfYppXZihPOW4TtprR8AHgBYunSprq6uPqHCHktNTQ1XLbyKjTUbyZ6XzbsK3jVur302q6mpYTzrebKQeklP6iU9qZf0pF7SO5l6GUs39RZgllJqulLKBlwL/OmIff4ArAZQSgUwuq3rTqgk42BZ0TJMyiRd1UIIIc4qxw1jrXUMuA14BqgFHtda71BKfUMpdWVyt2eAdqXU28DzwF1a6/bTVejR+Gw+FgYWsqlp05l+ayGEEOKkjaWbGq31OmDdEdvuHbasgTuTU0atLF7JT7b/hO5wN367P9PFEUIIIY5rUlyBa7iVxStJ6ASvHHol00URQgghxmTShfGCwAI8Vo8cNxZCCHHWmHRhbDFZWF60nE1Nm+TSmEIIIc4Kky6Mweiqbupror6nPtNFEUIIIY5rUobx+cXnA3JpTCGEEGeHSRnGpd5SSr2lcoqTEEKIs8KkDGMwuqo3H95MNBHNdFGEEEKIY5q0YXx+8fn0x/rZ3ro900URQgghjmnShvGywmWYlVmOGwshhJjwJm0Ye21eFuUtkuPGQgghJrxJG8YA5xedz1ttb9Ed7s50UYQQQohRTe4wLj4fjeblQy9nuihCCCHEqCZ1GC8ILMBr9UpXtRBCiAltUofx4KUxX2p6SS6NKYQQYsKa1GEMRlf1ob5D7O/Zn+miCCGEEGlN+jBeWbwSkEtjCiGEmLgmfRhP806jzFsmx42FEEJMWJM+jMHoqt58eDPRuFwaUwghxMQzJcJ4ZfFKBmIDvN76eqaLIoQQQhxlSoTx4KUxpataCCHERDQlwthj87A4b7EM4hJCCDEhTYkwBuO48dvtb9MZ6sx0UYQQQogRpkwYryxeiUbzyqFXMl0UIYQQYoQpE8bzc+fjtXmlq1oIIcSEM2XC2Gwys6JohVwaUwghxIQzZcIYjK7q5v5m9nXvy3RRhBBCiJQpFcbnF58PyKUxhRBCTCxTKoxLPCVU+CokjIUQQkwoUyqMwWgdb23eSiQeyXRRhBBCCGAKhnHq0pgtcmlMIYQQE8OUC+PzCs/DoizSVS2EEGLCmHJh7La6WZS3iE2H5DrVQgghJoYpF8ZgdFXXttfSEerIdFGEEEKIyRHGWmuagokx7y+XxhRCCDGRTIowfnhTPfduHOD5d1rGtP+83Hn4bD45biyEEGJCmBRh/KFzSijxmviXR7ZRs/P4gSyXxhRCCDGRTIow9rus3LXUwcw8D7f+ahsv7Go97nNWFq+kpb+Fuu66M1BCIYQQYnSTIowBPDbFozcvZ0aeh1se3sqG3W3H3F8ujSmEEGKimDRhDJDttvHozcuZHnDzqYe2sHHP6IFc7CmWS2MKIYSYECZVGAPkJAO5ItcI5Jf2jh7IK4tXsvXwVg73HT6DJRRCCCFGmnRhDJDrsfPoLcspy3HxyQe38HJde9r91sxcg0mZuOrPV/FC4wtnuJRCCCGEYVKGMUDAY+fRm1cwLdvFTb/cwitpAnle7jweu+IxCl2FfPbZz/Kdrd8hmohmoLRCCCGmskkbxgB5Xju/vmU5xVkObnpwC1v2H33FrQp/BY9+4FGumXMND+54kE/85RM0BZsyUFohhBBT1aQOY4B8r4Pf3LKCQr+DT/xiM1vTBLLdbOdrK77Gty/+NnXddVz156t47sBzGSitEEKIqWjShzFAvs/B2ltWUOBz8IlfbmFbfWfa/S6ruIzHr3icUm8pn3/+8/zX5v8iGpduayGEEKfXmMJYKXW5UmqnUmqPUuruY+x3lVJKK6WWjl8Rx0e+z8Gvb1lBwGPjxl9s5tUD6QO51FfKr973K66fez2P1D7CDX+5gYbehjNcWiGEEFPJccNYKWUGfgi8D5gHXKeUmpdmPy9wOzBh775Q6Hfwm1tXkOuxcePPN/N6Q1fa/WxmG3cvu5vvVX+PA70HuPrPV/P3+r+f4dIKIYSYKsbSMl4G7NFa12mtI8BaYE2a/f43cD8QGsfyjbsiv5Pf3LKCbLeNG37+Ctsb0wcywKXll/LbD/6W6f7p3FlzJ996+VuE4+EzWFohhBBTwVjCuAQY3k/bmNyWopQ6FyjVWj81jmU7bYqznPzm1hVkuaxc/9NX+Mn6vYSi8bT7lnhKeOjyh7hx3o2s3bmWG9bdQH1P/RkusRBCiMlMHe+uRUqpjwCXaa1vTq7fACzTWn8uuW4CngM+obXer5SqAb6ktd6a5rVuBW4FKCgoWLJ27dpx+yDBYBCPx3NCz2kfSPDQjgjb2+LkOBRrZlq5oNiC2aTS7v9m/5s80v4ICZ3gmtxrWOJaglLp950oTqZepgKpl/SkXtKTeklP6iW90epl9erV27TWacdUjSWMzwfu01pflly/B0Br/X+S635gLxBMPqUQ6ACuTBfIg5YuXaq3bh314RNWU1NDdXX1ST335bp2/uuv7/DagS5m5Lm567I5XDa/MG3QHu47zF3r7+L11teZmzOXTy38FO8uezdmk/kUP8HpcSr1MplJvaQn9ZKe1Et6Ui/pjVYvSqlRw3gs3dRbgFlKqelKKRtwLfCnwQe11t1a64DWukJrXQG8zHGCeKJZUZnL7/91JT+5wWjpfvqRV/nQ/7yU9rrWhe5CfnH5L/jGym8wEBvgS+u/xJo/ruGJXU8QiUcyUHohhBBnu+OGsdY6BtwGPAPUAo9rrXcopb6hlLrydBfwTFFKcdn8Qv76+Qu5/6pFtPaE+OhPX+GGn7/CWwe7R+xrNVn5p1n/xB/W/IHvVn8Xt9XNfZvu431PvI+HdjxEX7QvQ59CCCHE2cgylp201uuAdUdsu3eUfatPvViZYzGbuHppKVcuLuaRl+v5wfN7uOL/28AVi4r40nvnUBFwp/Y1m8y8p/w9vLvs3Ww6tIlfvPkLvr312zyw/QGuq7qO6+deT7YjO4OfRgghxNlgTGE8FTmsZm6+sJKrzyvlgfV1/HzDPv761mGuOa+Uz186i3yfI7WvUoqVxStZWbyS7a3b+fmbP+cn23/Cw28/zIdnfZgb599Iobswg59GCCHERDYlLod5KnwOK1+6bA7rv1zNdcvKeGxLAxf93+f5P+tqeetgN0cOgFuUt4jvX/J9/rjmj7yn/D2sfWct73vifXxtw9eo66474fePxBJs2N3G2s0H6B6QS3MKIcRkJC3jMcr3OvjfH1rAzRdO5zt/28UDL9bxkxfqKPDZuaQqn0uqClg1MxeXzajSyqxKvnXBt/jsOYU1VYIAACAASURBVJ/l4bcf5oldT/CnvX9idelqPjLnI5xfdP6oI7BbekPU7GzludoWNuxpIxiOAfDNp2u54fxyPrlqOnle+xn77EIIIU4vCeMTVJ7r5v9ddy5fv2IeNTtbeO6dFv70ehO/2dyAzWJi5YzcZDjnMy3bRbGnmLuX3c2ti27l17W/5rGdj/Fcw3MUuApYM3MNH5r5IUrc03irqZvn3jFeb3ujMWCs0Ofgg4uLubQqn4DXzs9erOPH6/fyiw37uG5ZGbdcVElJljPDNSKEEOJUSRifpDyvnY8sLeUjS0uJxBJs2d/Bs7UtPPtOM/f+cQf3/nEHcwq8XDI3n0ur8jm3LJvbzr2Nf1n0Lzzf8Dy/3fUEP93+Ux7Y/gCm0Cz62t9FPLiAc6bl8aX3zmZ1VT7zinwjznX+wUffxZ2tQX68fi+PvFzPIy/X80/nlvCv1TOozJMT74UQ4mwlYTwObBYTq2YGWDUzwNevmEtdWx/P1Rqt3J++UMePavaS5bJSPTuPWQVeNu3188q+NcTURXgCr2PL3kai5DHc1qdZUvkBVs/6J+bl+NJedKQyz8P9Vy3m8++ezU9fqOM3mw/wu1cbef/CIj5bPZN5xb4M1IAQQohTIWE8zpRSzMjzMCPPwy0XVdI9EOXF3cbx3+d3tvCH15uYkefmplXTWT1nOUsrrsNsgq2Ht/L7Pb/nD3v+wGM7H2N29mz+edY/84HpHyDLkXXU+5RkObnvyvncdslMfrFhH7/aVM/T2w9xSVU+n109gyXlORn49EIIIU6GhPFp5ndauWJRMVcsKiae0HT0RdIOvlpWtIxlRcvoWd7DX+r+wu/3/J7/3PyffGfrd7ik7BLWzFjDsqJl2M0jnxvw2Pny5VX8y8Uz+NWm/fxi434+/KNNLJ+ew22XzDxqtLcQQoiJR8L4DDKb1HFHQftsPq6puoZrqq5hZ8dOntzzJE/VPcUz+5/BaXGytGApq0pWcUHJBZR5y1Jd2X6nldsumcUnL5jObzY38NMX6rjh55uZ5lGsat/OrAIPswq8zMr3UOR3TPgbXAghxFQiYTyBzcmZw93L7uaOJXfwyqFX2HhwIxubNvLi5hcB4/aOF5RcwKriVSwrWobb6sZls/CpC6bzsRVlPPnqQX75/A7+UdvMY1uH7oLpsVuYme9hVr5nREgX+52YRrljlRBCiNNHwvgsYDfbuWjaRVw07SIAGnoa2NhkBPOf9v6Jx3Y+hsVk4dz8c1lVbLSaZ2fP5tplZRT211FdXU17MMzulqAxNfeyuznI8ztb+e22xtT7uGxmZuV7mJnvZXaBh9mFXqoKvRT6pCUthBCnk4TxWajUV8q1vmu5tupaovEor7W8ZoTzwY1879Xv8b1Xv0fAGWBl8Uqy+7KZ1z+PfE8+uR47KypzR7xWZ18kGdJGQO9u6eXF3a088epQSPudVuYUeJlTaExVhV5mF3rxOaxn+qMLIcSkJGF8lrOaranBX3csuYPW/lZeanqJjQc3sr5xPd3hbh767UOUectYUrCEpYVLWVKwhBJPCQDZbhvLpuewbPrI0ddd/RF2Hu5lZ3Mv7xzuZefhXp587WDqamBgjOgeHtBzCr1UBjzYLHKVVSGEOBESxpNMniuPNTPXsGbmGuKJOI/+/VH0NM225m08e+BZntzzJABF7iIjnAuMcC73lY/ois5y2VhemcvyYS1prTUHuwbYeXgooHce7uWFXa3EEsaobbvFxPLKXC6aFeDi2XnMzPdIF7cQQhyHhPEkZjaZKbOXUT2/mhvn30hCJ9jTtYeth7eytXkrLzW9xFN1TwEQcAZGhPOMrBmY1MgWrlKKadkupmW7uHRuQWp7JJagri3IzsO9vN7QxQu7Wvnm07V88+laivwOLpqVx0Wz87hgZgC/S7q2hRDiSBLGU4hJmZidPZvZ2bP56NyPorVmX88+tjVvSwX0M/ufAcBv9zM/d74xBeazIHcB+a78tK1cm8VEVaGPqkIfa84xur8Pdg3wwq5WXtjVyrq3DvHY1gZMChaXZnHRrDwunpPH4mlZmGX0thBCSBhPZUopKv2VVPor+cjsj6C1pjHYyLbmbbzW8ho72nbwi7d+QVzHAaP1vCB3AfMC81iQu4D5gfnkONJf6asky8l1y8q4blkZsXiCNxq7WL+rjfW7Wvl/z+3m+8/uxu+0csHMABfNDnBeRQ4+pxWH1YzTaj7pkI7EErQGw7T0hGjuCdPaG6KlN0xLT5iW5HJzT5jgQJiSbTWUZLsoyXIyLdtJSZaTkuS8wOeQHwpCiDNGwlikKKUo9ZZS6i3lQzM/BEAoFuKdjnfY0b6DHW072NG+g/WN69EYx4iL3cXMDwy1oOflzsNnG3l9bIvZxJLyHJaU53Dne2bT2Rdhw542o+W8u5Wn3zx0VFlsZhN2qwmn1YzTZsZhMeOwmXFaTanAdlrNoKB1WNh29h99z2eTMq5Ulu+zU+BzsLDET3vLISxeLwe7BthxsJv2vsjIMpsUhX7HiIA2QttFea6L4iynhLWYEA609/P0m4d4+s0m9rX2MavAy9wiH/OKjHlVkQ+PXb7qJzr5C4ljclgcnJN/Dufkn5PaFowEqe2oTYXzjvYd/L3+76nHSzwlzM2Zy5ycOVTlVFGVU0WBqyDVxZ3ttvHBxcV8cHExWmt2NQfZ3thFKBpnIBpnIJIgFIszEIkTisaHtkcThKJxOvoiqW2JBAS8dspyXZw3PZt8r4N8rxG8g8u5HvtRwVlT00F19ZLU+kAkzsGuAWPqHOBgV39yPsDLe9s53BMiMezKojazidIcJxW5bspz3UwPuCjPdVOR66Y4y4HFPHFHlCcSmr5IjL5wnGA4SjAcJxiKEQxHeaclxtJwTL68J7iGjn7WvXmIp988lLrl6jmlWfzTu0rY3Rzk6e1N/Gbz0JkP5bku5hb6mFvkY24ypKdlO2Vw5QQi/+PECfPYPJxXeB7nFZ6X2tYd7mZH+w7ebn+bdzreYWfHTp498GyqBZ1lzzLCObuKqtwqqrKrqPBXYDFZUqdHZZLTZmZmvoeZ+elvRRmNJzjcHaKhs5/69n72t/dR32bMN+5tIxRNpPa1mhWlyRa0EdAuSrJdeOwWPHYLLrsZt82C227GZbOccAs7ntD0hqJ0D0Tp6o/SNRClqz8ytN5vPGYEbSwZtsayEcCxY77+D9/4Gysqc7m0Kp9L5xZQmuM6ofKdDrF4gp3NxgDB1w500dIbZm6hl/klfhYU+6jIdU/6q8c1diYDePsh3kgG8OJpfr76/iret6BoxN9Ja01Td4japh5qD/VQe7iH2kO9PPP2YQYvV+91WJIB7WXhtCxWzcylyH/6748eisbpHoiS57FP+r/ZiZAwFuPCb/ezsnglK4tXprb1R/vZ1bmLdzreSU2/eec3RBJGl7DdbGdm1kyqcqqYkzOHmVkzqfRXkuPImXC/2K1mE6U5LkpzXKycMfIxrTUtvWH2t/Wxv72P/e391Lf3sb+tn1f2ddAfiR/ztZ1WcyqY3XYLbpsZl92Cx27GbDLRPRCluz+SDN0oPaEox7r/h8duweew4HEY4e93WpmW5cRtN+OxW5Pbh5a9duN9PXYL6zdtodNZzD9qm7nvz29z35/fZnaBh0vnFvDuufmcU5p9RrrnW3pDvHagKzl1sr2xm4FocuyCx0a+18Ev97YTiSdSn3lesY8FxX4WlPhYWOKnMs+T0UMJiYSmNxTDZTdjPcmekqauAda9eYinth/i9YYuABaW+Ln7fVV8YGHRqD+UlFKpQyvvnjd05kNfOMbO5l4joA8ZAf27bY08tKkegBl5bi6clceFswIsr8wdlx6SUDTOGw1dvFzXwct17bx6oJNwLIHdYkr9YJ0ecFOe60r2NLkyemne9mCYjXvb2bi7jcM9IR765LIz8r4SxuK0cVldR3VxxxIx9nfvp7ajlp0dO3mn8x3+ceAfPLH7idQ+WfYsKv2VzMiawYysGanlPGfehAtpML74CnwOCnyOEedlgxHUrcEwh7pC9EVi9IfjqS7ivnDM2BYxWqv94Rh9EWN790CUQ10DROMJ/E4rfpeN8lw3WS4rWcn1LKfVWHdZ8Tttybn1pL/4AVpyzVRXz+Wr75/LvrY+nq1t5tnaFh5I3pc7x22jek4e755bwIWzAnjH4Sps4VicHU09qeB97UAXB7sGAKOXYV6xn2vOK+XcsizeVZad6l6NxhPsbg7y1sFu3mrq5q2D3fx6c32ql8JpNTO3yMuCEr8xFfuZVeA5pfoZjdaawz0h3mjo4o3Gbt5o6OLNxm56k70QDqsJj9064keS12HBY7fidQwuDz3W2htm3ZuHePWAEcDzi318+fI5fGBhEeW57pMup9tu4V1l2byrLDu1LZHQ7GrpZcPuNl7c3cbaLQd48KX9WEyKd5Vlc8GsABfMCrCoxD+mwy+haJzXG7p4ua49Gb5dRGIJlDI+xw0ryinLddHYOcC+tj7q2/t4YVcr4dhQ75LNYqIsx0XFYEAH3KnlkqzxDepQNM6W/R1s2N3Ghj1t7GjqAcDnsLBqZoBILHFGLmQkYSzOKIvJwszsmczMnskHZ3wQML7Imvubqeuuo66rjr3de6nrquOZ/c/QE+lJPddr9VKZVTkioCv9lRS6C486J3qiUEolj107Ml2UEzY94ObmCyu5+ULjvtzrd7XyXDKcf//qQaxmxfLpuVxSlc/SimxiCU0oMnh8P3nMP5Y4etuw5ebeMLVNPakWbkmWk3PKsrhpVQXnlmUzv9iHw2pOWz6r2cS8Yh/zin1cTSlgdGfXtfUZAX2wh7cOdvPEtkYeTrb8zCajxViW46Is12XMB6dc15gv8drdH2X7wS7eaOji9YZutjcaXedGuZRxmt+5xVTkulM/tnpDUXpDseRyjPa2foLhGD3JQwhH9nbMK/Jx12VGAFcETj6Aj8dkUqlTE2++sJJQNM6r9Z28uKeNDbvb+O9/7OK7f9+F12Fh1QwjmC+cFUj9KDhe+H58RTkrKnM5b3oOfmf6+k0kjB8z+9v7jMNAyV6m+vZ+NuwZeRjIbjExPeBmRp6HyryheWWeZ0wt+URC8/ahHl7c3caGPa1s2d9JJJbAajZ+fHzpvbNZNTPAojN86qXK1P1uly5dqrdu3Tpur1dTU0N1dfW4vd5kcTbXi9aa9lB7KqD3du2lrruOvV176Qh1pPazm+2Uekup8FVQ7iunwl+RWs6yZ6VtTZ/N9XI6jaVeYvEE2+o7ee6dFv5R28ze1r4xvbbNbMJhNeG0GSPhHVYzWS4ri0uzOLc0m3PLsijwjf+PlkRCs7+9j7eaeth5uIcDHQMc6OinoaOfjiNG0We5rJQlD0eUDwvqHW++gTmvku2NRst3X9vQZ67Mc3POtCwWTfOzuDSLuUWj/4AYjdaa/kg8GdZR7BbzhDhWD9DRF2FjMpg37GlL9VqU5jhx6jD7exkRvium5x43fE9EIpE8DNTeR11rH3WtQerajPmBjv4RAysLfHYqAx5m5LupDAyFNcDGPW28uKeNl/a0pc66mFPgZdVM48fFsuk5uMdp4OJo/4+UUtu01kvTPUdaxmLCUkoRcAYIOAMsKxp53KYz1JkK5gM9B6jvqWdP1x5qGmqI6aEBSj6bLxXM5b5yyv3lVPgqCCfCZ/rjTBoWsyl1qdR73j+X/W19vHO4d+hUtOTpaIOBa5yaZsrYCHOTSVGZ56EyzwOLi0c81hOK0pAM5gPJqb69nx0Hu3nmrcOpy7wa3qbQ52BxqZ+PLJ3G4mlZLCjxj0vgKKWM8QJ2CzCxelFyjjj7YV9bX/LUxDbqmlqHWr4VOaflCnum5GmGhX7HUTe6CcfiHGjvZ29rkL2tRljvbQ3yp9eb6AkdPVAx32tn9Zx8o+t9ZoD80/Dj72RJGIuzUrYjmyWOJSwpWDJieywRoynYxP6e/dT31FPfU8/+nv1sad7Cn+v+PGLf+397PxW+ihEt6nJfOSWeEiwm+a8xVhUB92ntRj2dfA4r84v9zC/2H/VYLJ7gcE+IA+39bH71da67/ILT0nI/myg19MPm4+dXJFuA8zJWHrvFbNyPvWDk2Rhaa9r7IuxtMVrRkViC82fkMmsCXytfvnHEpGIxWSjzlVHmKzvqsYHYAA29DdT31PPc689hyjVR31PPM/XP0B3uHnoNZWGad9pRIV3hqyDgDEzY/8xifFnMptS12CONlikfxGcTpRQBj52Ax37UoMqJSsJYTBlOizN1bW7rPivVF1SnHusKdbG/Z/+IFvW+7n281PRS6lSswdcocBVQ4C4w5q4CCt2F5LvyU9uz7dkS2EKIEyJhLASQ5cjiHMfI07AAEjrB4b7D7O82grqht4Hm/maa+5t55dArtA20pa7dPchmshnh7C4g35VPoatwRHgXuAvIdeRiNp3YIB8hxOQlYSzEMZiUiWJPMcWeYlaWrDzq8XgiTnuonea+5lRID19+s/VN/tH/D6KJkdfMNiszea68EQE9OC90FVLgKiDgCmA1yS0nhZgKJIyFOAVmk5l8Vz75rnwWsjDtPlprOkIdtPS3HBXWzf3N7OrcxYsHX2QgNjDieQpFnjOPUl8p5b5ySr3GvMxbRqm3FJd1Ypz6IoQ4dRLGQpxmSilynbnkOnOZmzs37T5aa3qjvUNBnZwfDB6kobeB9Q3raQ+1j3hOnjPPGKzmLUvNB0NbglqIs4uEsRATgFIKn82Hz+ZjVvastPsEI0FjNHhvPQ09xqjwht4GXmh84aigznXkprq+8135FLoLU8uDcwlsISYOCWMhzhIem4e5uXPTtq77on0c6DnAgd4DHOg5QGOwkeb+Zhp6G9jWvG3EZUUHeW3e1DHrwQFnXb1d0GC0ugPOALnOXDnnWogzYEL9L4tGozQ2NhIKhU74uX6/n9ra2tNQqrPbqdSLw+Fg2rRpWK0yiGiic1vdowY1GOdYt/S3jDhePXx9V+cu2gba0GjWPrc29TyFItuRbYSzK0CeMy8V1Hmukct2s/1MfVwhJp0JFcaNjY14vV4qKipO+DzN3t5evN7M3hN3IjrZetFa097eTmNjI9OnTz8NJRNnktPiTF0SdDTRRJSnnnuKmYtn0jrQSttAG60DrbT2Dy3v7thNe6j9qNO5wGhpp8LaFSDfmZ8K6oAzGeSuPNzWs/NqXUKcThMqjEOh0EkFsRh/Silyc3NpbW3NdFHEGWI1Wcm2ZLMwL/2o8EHxRJzOcKcR0P3pQ/v1ltdp7W8dccGUQU6Lc0SLOtueTY4jhyxHFtmObHLsOWQ7ssl2ZJNlz5JucjElTLh/5RLEE4f8LUQ6ZpM5dQOPqpyqUffTWtMT6aG1vzVtS7ulv4WdHTvpCHWkPaYNRje5z+5LBfZgSOc6clPnfxe7iyl0F2Iz207XRxbitJtwYSyEmByUUvjtfvx2PzOzZx5z32giSne4m45QB52hTjpDnXSEOugKdw1tC3dS31PPay2v0RXuIqGH7nGrUOS58ih2Fw+FtKeYEncJRZ4iitxFOCxybWkxcUkYnwKPx0MwGEz72P79+7niiit46623znCphDj7WE3WVGt7LKKJKM19zRzqO8TB4EEOBZPzvkO80foGf9v/txG30gTjdK9Cd6HRurZnj+gKz7ZnG93kye0+m08uVyrOKAljIcRZx2qyMs07jWneaZzHeUc9Hk/EaR1o5WDwIE3BJpqCTRzqO8ThvsPGvbC76ugMdx511bNBCqNVn2U3jmPHe+O8uOlFAi7jB0PAEUgd88515GI1yxkH4tRM2DD+X3/ewdtN6Y8jpROPxzGbj/1Ldl6xj3//4PxRH//KV75CeXk5n/nMZwC47777UErxwgsv0NnZSTQa5Zvf/CZr1qwZc7nAGJj2r//6r2zduhWLxcJ3v/tdVq9ezY4dO7jpppuIRCIkEgmeeOIJiouLufrqq2lsbCQej/P1r3+da6655oTeT4ipzmwyU+gupNBdeNQ9r4cLxUJ0hbtS3eBdoS5jPrgtZCwfjh3mQP0BusJdaV/Hb/enAjrgGgrrXGduKtSz7Fn47X68Ni8mZTpdH12cpSZsGGfCtddeyxe+8IVUGD/++OP89a9/5Y477sDn89HW1saKFSu48sorT2hw0w9/+EMA3nzzTd555x3e+973smvXLn784x/z+c9/nuuvv55IJEI8HmfdunUUFxfz9NNPA9Dd3X2slxZCnAKHxUGhxQjtY6mpqaG6uppoPEp7qJ32gfbUoLTBaXDb6y2v0zbQRjgeTvtaJmXCZ/OlwnlwPjy0s+xZqW77gDMgV0ubAiZsGB+rBZvOeJxnfO6559LS0kJTUxOtra1kZ2dTVFTEHXfcwQsvvIDJZOLgwYM0NzdTWHjs/7zDbdiwgc997nMAVFVVUV5ezq5duzj//PP51re+RWNjI//8z//MrFmzWLhwIV/60pf4yle+whVXXMGFF154Sp9JCDF+rGZrqsV9LFpr+qJ9tIfa6Qp30R3upivcRVeoi+5I99B6uIvm/mZ2du6kO9w9are50+Ik15GbCudcZ+7Q3DEU2jnOHLn4yllqwoZxplx11VX87ne/4/Dhw1x77bU8+uijtLa2sm3bNqxWKxUVFSd8hTCtddrtH/3oR1m+fDlPP/00l112GT/72c+45JJL2LZtG+vWreOee+7hve99L/fee+94fDQhxBmilMJj8+CxeShn9AutHCkcD9Md7qYz1En7QDttobYRre+OgQ72de9jS/MWusPpe81sJhtemxevzYvP7jPmVl9qW7rtPrvRUpcu9MyRMD7Ctddeyy233EJbWxvr16/n8ccfJz8/H6vVyvPPP099ff0Jv+ZFF13Eo48+yiWXXMKuXbs4cOAAc+bMoa6ujsrKSm6//Xbq6urYvn07VVVV5OTk8LGPfQyPx8ODDz44/h9SCDEh2c321C05j2d4l3kqrEMd9EZ76Y0YU0+4h+5QN429jan1I0eZD5euCz01ObKOOv7dHesmEo/IOd7jYExhrJS6HPg+YAZ+prX+zyMevxO4GYgBrcAntdYnnloTwPz58+nt7aWkpISioiKuv/56PvjBD7J06VLOOeccqqpGv8jBaD7zmc/w6U9/moULF2KxWHjwwQex2+089thjPPLII1itVgoLC7n33nvZsmULd911FyaTCavVyo9+9KPT8CmFEGe7sXaZD6e1JhQPpYJ5MLiHd5un60LvCnURiqfvEfzaI1/DZXEdFeB+u58sR1b67fYsPFaPXFhomOOGsVLKDPwQeA/QCGxRSv1Ja/32sN1eA5ZqrfuVUv8K3A+ctUOA33zzzdRyIBBg06ZNafcb7RxjgIqKitQ5xg6HI20L95577uGee+4Zse2yyy7jsssuO4lSCyHEsSmlcFqcOC3OMbW+hxsceT48rDe/uZn8svyjjoM39TXRFe6iJ9yDJv1hOqvJalz+1JEzdHU1+8j14cuTPbzH0jJeBuzRWtcBKKXWAmuAVBhrrZ8ftv/LwMfGs5BCCCEyK93Ic/t+O9WLq0d9TjwRpzfSm7bVfeTV1g70HKAz3ElftC/ta1lNVnw2Hw6LA6fFicPswG6xG+tmp7FsNh6zm+2p/exmO26rm3xXPnmuPPKd+bit7gkX7Gq0wUWpHZS6Crhca31zcv0GYLnW+rZR9v8BcFhr/c00j90K3ApQUFCwZO3atSMe9/v9zJx57MvmjWYs5xmfDjt27ODWW28dsc1ms/H888+P8owz61TrZc+ePZPy9KpgMIjH48l0MSYcqZf0pF7SOx31EtVRgvEgvfFegomgsZzoJRgP0p/oJ6qjRHWUSCJCREeM5eHzhDGPc/SdxQbZlA2/2Y/f7Mdn9hnLFn9q2+BkN53cyPTR6mX16tXbtNZL0z1nLC3jdD8f0ia4UupjwFLg4nSPa60fAB4AWLp0qa6urh7xeG1t7UmfnpSpWyiuWLGC7du3n/H3HatTrReHw8G55547jiWaGAbPGxUjSb2kJ/WS3kSul1giRjgeZiA2QG+kN3Vzktb+VloGWmjrb6NlwFh/u//ttMfEcxw51Fxdc8Kt6JOpl7GEcSNQOmx9GtB05E5KqXcD/wZcrLVOf7a7EEIIcQZYTBYsJgtuq5uAM8B0/+j3ZddaE4wGU0Hd2t9KS38LkXjkjHVnjyWMtwCzlFLTgYPAtcBHh++glDoX+AlGd3bLuJdSCCGEOE2UUqlzsCuzKjNShuOe3a21jgG3Ac8AtcDjWusdSqlvKKWuTO72fwEP8Ful1OtKqT+dthILIYQQk8yYzjPWWq8D1h2x7d5hy+8e53IJIYQQU4Zc9+wUyOhKIYQQ40HCeBKIxUa/vJ0QQoiJb+Jem/ovd8PhN4+/X5IzHgPzcT5O4UJ433+O+vB43s84GAyyZs2atM97+OGH+fa3v41SikWLFvGrX/2K5uZmPv3pT1NXVwfAj370I4qLi7niiitSV/L69re/TTAY5L777qO6upqVK1eyceNGrrzySmbPns03v/lNIpEIubm5PProoxQUFBAMBrn99tvZunUrSin+/d//na6uLt566y3++7//G4Cf/vSn1NbW8t3vfve4n0sIIcT4m7hhnAHjeT9jh8PBk08+edTz3n77bb71rW+xceNGAoEAHR0dANx+++1cfPHFPPnkk8TjcYLBIJ2dncd8j66uLtavXw9AZ2cnL7/8Mkopfvazn3H//ffzne98h/vvvx+/35+6xGdnZyc2m41FixZx//33Y7Va+eUvf8lPfvKTU60+IYQQJ2nihvExWrDpDEyw+xlrrfnqV7961POee+45rrrqKgKBAAA5OTkAPPfcczz88MMAmM1m/H7/ccP4mmuGLv/d2NjINddcw6FDh4hEIkyfbpxTV1NTw+OPP57aLzs7G4BLLrmEp556irlz5xKNRlm4cOEJ1pYQQojxMnHDOEPG637Goz1Paz3mk8gtFguJRCK1T851WQAADNFJREFUfuT7ut3u1PLnPvc57rzzTq688kpqamq47777AEZ9v5tvvpn/+I//oKqqiptuumlM5RFCCHF6yACuI1x77bWsXbuW3/3ud1x11VV0d3ef1P2MR3vepZdeyuOPP057eztAqpv60ksvTd0uMR6P09PTQ0FBAS0tLbS3txMOh3nqqaeO+X4lJSUAPPTQQ6ntl1xyCT/4wQ9S64Ot7eXLl9PQ0MCvf/1rrrvuurFWjxBCiNNAwvgI6e5nvHXrVpYuXcqjjz465vsZj/a8+fPn82//9m9cfPHFLF68mDvvvBOA73//+zz//PMsXLiQJUuWsGPHDqxWK/feey/Lly/niiuuOOZ733fffXzkIx/hwgsvTHWBA9x11110dnayYMECFi9ePOIGFldffTWrVq1KdV0LIYTIDOmmTmM87md8rOfdeOON3HjjjSO2FRQU8Mc//vGofW+//XZuv/32o7bX1NSMWF+zZk3aUd4ej2dES3m4DRs2cMcdd4z2EYQQQpwh0jKegrq6upg9ezZOp5NLL70008URQogp7/9v7/5jo67vOI4/32kZHa1KuyGC4IbbEn+0PRBLFJcKuiEsGn4IU+IqbbTORI2LEZkoG7NO0U62+SOaboIwx4AIbCYqjjqwklRAsKw6sDrBCTItFFCiMHt974/79izlWg4tfK+91yMh3H3ue597980nffP5fL/3+Wpm/BXV19dTUlJyWFvv3r1Zt25dSBEdXd++fWloaAg7DBERCagYf0UFBQXU1dWFHYaIiHRjWqYWEREJmYqxiIhIyFSMRUREQqZi3I5uiygiIieairGIiEjIVIw74O5Mnz6d/Px8CgoKWLJkCQC7du2iuLiYoUOHkp+fzyuvvEI0GqW0tDR+bOutCUVERJKRsl9temD9A2xt2pr08dFolIyMjE6POSvvLGaMmJFUf8uXL6euro7Nmzeze/duioqKKC4uZtGiRVx22WXcddddRKNRPv30U+rq6ti5c2f8vsP79u1LOm4RERHNjDuwdu1apk6dSkZGBv379+fiiy9mw4YNFBUVMX/+fGbPnk19fT0nnXQSZ555Ju+++y633HILK1eu5OSTTw47fBER6UZSdmac7Ay21SddcD/jttw9YXtxcTE1NTU899xzlJSUMH36dK699lo2b97Miy++yGOPPcbSpUuZN29el8UiIiI9m2bGHSguLmbJkiVEo1EaGxupqalhxIgRvPfee5x66qmUl5dz3XXXsWnTJnbv3k1LSwtXXnklFRUVbNq0KezwRUSkG0nZmXHYJk6cSG1tLZFIBDPjwQcf5LTTTmPBggVUVlbSq1cvcnJyWLhwITt37qSsrIyWlhYA7r///pCjFxGR7kTFuJ3W2yKaGZWVlVRWVh72eqLbHwKaDYuIyJemZWoREZGQqRiLiIiETMVYREQkZCrGIiIiIVMxFhERCZmKsYiISMhUjEVEREKmYhyS5ubmsEMQEZEUoWKcwIQJExg+fDjnnnsuVVVVAKxcuZLzzjuPSCTCpZdeCsQ2CCkrK6OgoIDCwkKWLVsGQE5OTryvZ555htLSUgBKS0u57bbbGD16NDNmzGD9+vWMHDmSYcOGMXLkSN566y0gdgeq22+/Pd7vI488wksvvcTEiRPj/a5atYpJkyadiHSIiMhxlrI7cP33vvs4tCX5Wyg2R6M0HeUWir3PPovTZs48al/z5s0jLy+Pzz77jKKiIsaPH095eTk1NTUMGTKEpqYmACoqKjjllFOor68HYO/evUftu6GhgerqajIyMvj444+pqakhMzOT6upqZs6cybJly6iqqmLbtm28/vrrZGZm0tTURG5uLjfddBONjY3069eP+fPnU1ZWlkRmREQk1aVsMQ7Tww8/zIoVKwB4//33qaqqori4mCFDhgCQl5cHQHV1NYsXL46/Lzc396h9T5kyJX7f5f379zNt2jTefvttzIzPP/883u+NN95IZmbmYZ9XUlLC008/TVlZGbW1tSxcuLCLfmIREQlTyhbjZGawbXXVLRTXrFlDdXU1tbW19OnTh1GjRhGJROJLyG25O2Z2RHvbtoMHDx72WnZ2dvzxrFmzGD16NCtWrGD79u2MGjWq037Lysq44ooryMrKYsqUKfFiLSIi3ZvOGbezf/9+cnNz6dOnD1u3buXVV1/l0KFDvPzyy2zbtg0gvkw9ZswYHn300fh7W5ep+/fvz5YtW2hpaYnPsDv6rNNPPx2Ap556Kt4+ZswYnnjiifhFXq2fN3DgQAYOHMi9994bPw8tIiLdn4pxO2PHjqW5uZnCwkJmzZrFBRdcQL9+/aiqqmLSpElEIhGuuuoqAO6++2727t1Lfn4+kUiE1atXAzBnzhwuv/xyLrnkEgYMGNDhZ91xxx3ceeedXHTRRUSj0Xj79ddfzxlnnEFhYSGRSIRFixbFX7vmmmsYPHgw55xzznHKgIiInGha52ynd+/evPDCCwlfGzdu3GHPc3JyWLBgwRHHTZ48mcmTJx/R3nb2C3DhhRfS0NAQf15RUQFAZmYmc+fOZe7cuUf0sXbtWsrLy4/6c4iISPehYtyNDB8+nOzsbB566KGwQxERkS6kYtyNbNy4MewQRETkONA5YxERkZClXDF297BDkID+LUREToyUKsZZWVns2bNHRSAFuDt79uwhKysr7FBERHq8lDpnPGjQIHbs2EFjY+Mxv/fgwYMqHAl8lbxkZWUxaNCgLo5IRETaS6oYm9lY4PdABvBHd5/T7vXewEJgOLAHuMrdtx9rML169YpvOXms1qxZw7Bhw77Ue3sy5UVEJPUddZnazDKAx4BxwDnAVDNrv+PEdcBed/8u8Fvgga4OVEREpKdK5pzxCOAdd3/X3f8HLAbGtztmPNC6+8UzwKWWaHNlEREROUIyxfh04P02z3cEbQmPcfdmYD/wja4IUEREpKdL5pxxohlu+8udkzkGM7sBuCF4esDMjrwV0pf3TWB3F/bXUygviSkviSkviSkviSkviXWUl2919IZkivEOYHCb54OADzo4ZoeZZQKnAE3tO3L3KqAqic88Zmb2mruffzz67s6Ul8SUl8SUl8SUl8SUl8S+TF6SWabeAHzPzIaY2deAq4Fn2x3zLDAteDwZ+Ifry8IiIiJJOerM2N2bzexm4EViX22a5+5vmtk9wGvu/izwJPAnM3uH2Iz46uMZtIiISE+S1PeM3f154Pl2bb9o8/ggMKVrQztmx2X5uwdQXhJTXhJTXhJTXhJTXhI75ryYVpNFRETClVJ7U4uIiKSjHlGMzWysmb1lZu+Y2c/DjidVmNl2M6s3szozey3seMJiZvPM7CMze6NNW56ZrTKzt4O/c8OMMQwd5GW2me0Mxkydmf0ozBjDYGaDzWy1mW0xszfN7NagPa3HTCd5SesxY2ZZZrbezDYHeflV0D7EzNYF42VJcAF0x/1092XqYLvOBuCHxL5itQGY6u7/CjWwFGBm24Hz3T2tvwdoZsXAAWChu+cHbQ8CTe4+J/gPXK67zwgzzhOtg7zMBg64+2/CjC1MZjYAGODum8zsJGAjMAEoJY3HTCd5+TFpPGaC3Saz3f2AmfUC1gK3ArcBy919sZk9AWx298c76qcnzIyT2a5T0pi713Dk997bbuG6gNgvlbTSQV7SnrvvcvdNweNPgC3EdhlM6zHTSV7SmsccCJ72Cv44cAmx7aEhifHSE4pxMtt1pisH/m5mG4Pdz+QL/d19F8R+yQCnhhxPKrnZzP4ZLGOn1VJse2b2bWAYsA6Nmbh2eYE0HzNmlmFmdcBHwCrg38C+YHtoSKIu9YRinNRWnGnqInc/j9gdt24KliVFOvM48B1gKLALeCjccMJjZjnAMuBn7v5x2PGkigR5Sfsx4+5Rdx9KbIfKEcDZiQ7rrI+eUIyT2a4zLbn7B8HfHwEriA0SifkwOAfWei7so5DjSQnu/mHwi6UF+ANpOmaCc3/LgD+7+/KgOe3HTKK8aMx8wd33AWuAC4C+wfbQkERd6gnFOJntOtOOmWUHF1lgZtnAGOCNzt+VVtpu4ToN+FuIsaSM1mITmEgajpnggpwngS3uPrfNS2k9ZjrKS7qPGTPrZ2Z9g8dfB35A7Hz6amLbQ0MS46XbX00NEFxK/zu+2K7z1yGHFDozO5PYbBhiO60tSte8mNlfgFHE7qTyIfBL4K/AUuAM4D/AFHdPq4uZOsjLKGLLjQ5sB37aep40XZjZ94FXgHqgJWieSez8aNqOmU7yMpU0HjNmVkjsAq0MYhPcpe5+T/A7eDGQB7wO/MTdD3XYT08oxiIiIt1ZT1imFhER6dZUjEVEREKmYiwiIhIyFWMREZGQqRiLiIiETMVYREQkZCrGIiIiIVMxFhERCdn/AT+38kLrIwunAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(mlp_fashion_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PD-Xxur02Uat",
    "outputId": "a03a2480-83ef-4cb6-8757-3bf472b458c4",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 50us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[63.283047476959226, 0.855400025844574]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.evaluate(Xf_test, yf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rV4QKqQXnMAq",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def build_mlp_model_1(k_initializer='random_uniform', b_initializer='random_uniform', activation='relu', \n",
    "                      optimizer=\"sgd\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"], \n",
    "                      k_regularizer=None, b_regularizer=None):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[28,28]),\n",
    "        keras.layers.Dense(300, activation=activation, kernel_initializer=k_initializer, bias_initializer=b_initializer,\n",
    "                          kernel_regularizer=k_regularizer, bias_regularizer=b_regularizer),\n",
    "        keras.layers.Dense(100, activation=activation, kernel_initializer=k_initializer, bias_initializer=b_initializer,\n",
    "                          kernel_regularizer=k_regularizer, bias_regularizer=b_regularizer),\n",
    "        keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=k_initializer, bias_initializer=b_initializer,\n",
    "                          kernel_regularizer=k_regularizer, bias_regularizer=b_regularizer)\n",
    "                                 ])\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "keras_clas = keras.wrappers.scikit_learn.KerasClassifier(build_mlp_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 2s 68us/step - loss: 2.3020 - accuracy: 0.1108 - val_loss: 2.3013 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 67us/step - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 34us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 3s 69us/step - loss: 2.3018 - accuracy: 0.1108 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 67us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 3s 70us/step - loss: 2.3012 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 67us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 34us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 65us/step - loss: 2.3017 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 33us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 2s 63us/step - loss: 113970.8943 - accuracy: 0.1105 - val_loss: 2.3013 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 64us/step - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 61us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 62us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 62us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 33us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 83401.8872 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 60us/step - loss: 2.3012 - accuracy: 0.1113 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 61us/step - loss: 2.3012 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 34us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 67us/step - loss: 97789.8035 - accuracy: 0.1142 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 67us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 67us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 33us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 2s 64us/step - loss: 1.1789 - accuracy: 0.7044 - val_loss: 0.4953 - val_accuracy: 0.8620\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 62us/step - loss: 0.4163 - accuracy: 0.8825 - val_loss: 0.3430 - val_accuracy: 0.9014\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 62us/step - loss: 0.3323 - accuracy: 0.9039 - val_loss: 0.2966 - val_accuracy: 0.9148\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 61us/step - loss: 0.2907 - accuracy: 0.9167 - val_loss: 0.2605 - val_accuracy: 0.9282\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 62us/step - loss: 0.2612 - accuracy: 0.9242 - val_loss: 0.2378 - val_accuracy: 0.9346\n",
      "18334/18334 [==============================] - 1s 34us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 3s 68us/step - loss: 1.2463 - accuracy: 0.6905 - val_loss: 0.4858 - val_accuracy: 0.8774\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 67us/step - loss: 0.4106 - accuracy: 0.8851 - val_loss: 0.3415 - val_accuracy: 0.9038\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 0.3285 - accuracy: 0.9063 - val_loss: 0.2916 - val_accuracy: 0.9202\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 0.2883 - accuracy: 0.9173 - val_loss: 0.2657 - val_accuracy: 0.9270\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 0.2594 - accuracy: 0.9264 - val_loss: 0.2409 - val_accuracy: 0.9316\n",
      "18333/18333 [==============================] - 1s 34us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 1.1758 - accuracy: 0.6998 - val_loss: 0.4902 - val_accuracy: 0.8700\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 0.4158 - accuracy: 0.8838 - val_loss: 0.3344 - val_accuracy: 0.9072\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 0.3319 - accuracy: 0.9051 - val_loss: 0.2904 - val_accuracy: 0.9218\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 0.2916 - accuracy: 0.9154 - val_loss: 0.2569 - val_accuracy: 0.9280\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 0.2624 - accuracy: 0.9241 - val_loss: 0.2332 - val_accuracy: 0.9360\n",
      "18333/18333 [==============================] - 1s 35us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 3s 69us/step - loss: 2.3059 - accuracy: 0.1023 - val_loss: 2.3020 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.3031 - accuracy: 0.1078 - val_loss: 2.3000 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.2857 - accuracy: 0.1357 - val_loss: 2.2313 - val_accuracy: 0.1774\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.1361 - accuracy: 0.2123 - val_loss: 2.0657 - val_accuracy: 0.2326\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.0301 - accuracy: 0.2407 - val_loss: 1.9905 - val_accuracy: 0.2482\n",
      "18334/18334 [==============================] - 1s 35us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.3057 - accuracy: 0.1037 - val_loss: 2.3049 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 2.3027 - accuracy: 0.1069 - val_loss: 2.3021 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.2878 - accuracy: 0.1292 - val_loss: 2.2376 - val_accuracy: 0.1646\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.1382 - accuracy: 0.2110 - val_loss: 2.0625 - val_accuracy: 0.2264\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 2.0216 - accuracy: 0.2421 - val_loss: 1.9775 - val_accuracy: 0.2426\n",
      "18333/18333 [==============================] - 1s 35us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 68us/step - loss: 2.3058 - accuracy: 0.1056 - val_loss: 2.3029 - val_accuracy: 0.0990\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.3024 - accuracy: 0.1117 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.2828 - accuracy: 0.1343 - val_loss: 2.2231 - val_accuracy: 0.1774\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.1251 - accuracy: 0.2172 - val_loss: 2.0653 - val_accuracy: 0.2274\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 67us/step - loss: 2.0353 - accuracy: 0.2366 - val_loss: 2.0120 - val_accuracy: 0.2392\n",
      "18333/18333 [==============================] - 1s 34us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 3s 68us/step - loss: 65003.0909 - accuracy: 0.1105 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 65us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 35us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 3s 68us/step - loss: 71777.1710 - accuracy: 0.1112 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.3012 - accuracy: 0.1113 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 34us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 65us/step - loss: 24625.5530 - accuracy: 0.1139 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 33us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 3s 68us/step - loss: 0.8667 - accuracy: 0.7671 - val_loss: 0.4172 - val_accuracy: 0.8854\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 0.3899 - accuracy: 0.8856 - val_loss: 0.3551 - val_accuracy: 0.9012\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 0.3340 - accuracy: 0.9002 - val_loss: 0.2969 - val_accuracy: 0.9154\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 67us/step - loss: 0.3041 - accuracy: 0.9098 - val_loss: 0.2812 - val_accuracy: 0.9158\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 0.2826 - accuracy: 0.9162 - val_loss: 0.2560 - val_accuracy: 0.9246\n",
      "18334/18334 [==============================] - 1s 35us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 0.8446 - accuracy: 0.7773 - val_loss: 0.4064 - val_accuracy: 0.8900\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 0.3821 - accuracy: 0.8897 - val_loss: 0.3296 - val_accuracy: 0.9054\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 0.3325 - accuracy: 0.9038 - val_loss: 0.3002 - val_accuracy: 0.9154\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 0.3051 - accuracy: 0.9114 - val_loss: 0.3002 - val_accuracy: 0.9094\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 0.2852 - accuracy: 0.9163 - val_loss: 0.2694 - val_accuracy: 0.9236\n",
      "18333/18333 [==============================] - 1s 35us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 0.8554 - accuracy: 0.7745 - val_loss: 0.4134 - val_accuracy: 0.8848\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 61us/step - loss: 0.3874 - accuracy: 0.8880 - val_loss: 0.3328 - val_accuracy: 0.9048\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 0.3345 - accuracy: 0.9028 - val_loss: 0.2953 - val_accuracy: 0.9170\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 61us/step - loss: 0.3053 - accuracy: 0.9111 - val_loss: 0.2755 - val_accuracy: 0.9208\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 61us/step - loss: 0.2822 - accuracy: 0.9169 - val_loss: 0.2570 - val_accuracy: 0.9250\n",
      "18333/18333 [==============================] - 1s 32us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 2s 64us/step - loss: 2.3027 - accuracy: 0.1039 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 62us/step - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 61us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 63us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 62us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 34us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.3024 - accuracy: 0.1037 - val_loss: 2.3015 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 65us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 65us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 36us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 68us/step - loss: 2.3013 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 34us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 3s 69us/step - loss: 77993.0152 - accuracy: 0.1080 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 67us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 68us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 34us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 67us/step - loss: 54448.7880 - accuracy: 0.1081 - val_loss: 2.3014 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 3s 73us/step - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 2.3012 - accuracy: 0.1113 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.3012 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 2.3012 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 32us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 90781.7982 - accuracy: 0.1042 - val_loss: 2.3015 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3011 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 35us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 3s 69us/step - loss: 1.2072 - accuracy: 0.6959 - val_loss: 0.4968 - val_accuracy: 0.8630\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 0.4131 - accuracy: 0.8834 - val_loss: 0.3414 - val_accuracy: 0.9070\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 67us/step - loss: 0.3332 - accuracy: 0.9037 - val_loss: 0.2930 - val_accuracy: 0.9192\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 67us/step - loss: 0.2936 - accuracy: 0.9143 - val_loss: 0.2676 - val_accuracy: 0.9266\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 68us/step - loss: 0.2648 - accuracy: 0.9234 - val_loss: 0.2470 - val_accuracy: 0.9288\n",
      "18334/18334 [==============================] - 1s 37us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 3s 68us/step - loss: 1.1819 - accuracy: 0.7067 - val_loss: 0.4794 - val_accuracy: 0.8722\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 0.4026 - accuracy: 0.8892 - val_loss: 0.3369 - val_accuracy: 0.9072\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 0.3256 - accuracy: 0.9081 - val_loss: 0.2932 - val_accuracy: 0.9194\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 0.2876 - accuracy: 0.9191 - val_loss: 0.2597 - val_accuracy: 0.9268\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 0.2593 - accuracy: 0.9271 - val_loss: 0.2407 - val_accuracy: 0.9300\n",
      "18333/18333 [==============================] - 1s 34us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 65us/step - loss: 1.2199 - accuracy: 0.6942 - val_loss: 0.4761 - val_accuracy: 0.8792\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 0.4156 - accuracy: 0.8853 - val_loss: 0.3370 - val_accuracy: 0.9068\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 0.3307 - accuracy: 0.9053 - val_loss: 0.2788 - val_accuracy: 0.9230\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 0.2904 - accuracy: 0.9171 - val_loss: 0.2507 - val_accuracy: 0.9310\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 0.2603 - accuracy: 0.9249 - val_loss: 0.2309 - val_accuracy: 0.9348\n",
      "18333/18333 [==============================] - 1s 33us/step\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 4s 70us/step - loss: 0.9329 - accuracy: 0.7662 - val_loss: 0.3856 - val_accuracy: 0.8932\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 4s 70us/step - loss: 0.3524 - accuracy: 0.8993 - val_loss: 0.2905 - val_accuracy: 0.9186\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 4s 68us/step - loss: 0.2915 - accuracy: 0.9168 - val_loss: 0.2491 - val_accuracy: 0.9302\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 4s 69us/step - loss: 0.2537 - accuracy: 0.9271 - val_loss: 0.2228 - val_accuracy: 0.9370\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 4s 68us/step - loss: 0.2240 - accuracy: 0.9356 - val_loss: 0.1982 - val_accuracy: 0.9430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f61e03ef3d0>,\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'b_initializer': [<keras.initializers.Zeros object at 0x7f61940d68d0>,\n",
       "                                           <keras.initializers.Ones object at 0x7f61940d6910>,\n",
       "                                           <keras.initializers.RandomNormal object at 0x7f61940d6950>],\n",
       "                         'k_initializer': [<keras.initializers.Zeros object at 0x7f61940d68d0>,\n",
       "                                           <keras.initializers.Ones object at 0x7f61940d6910>,\n",
       "                                           <keras.initializers.RandomNormal object at 0x7f61940d6950>]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inits = [keras.initializers.Zeros(), \n",
    "         keras.initializers.Ones(), \n",
    "         keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)]\n",
    "param_distribs= {'k_initializer': inits, 'b_initializer': inits}\n",
    "\n",
    "grid_search_cv = GridSearchCV(keras_clas, param_distribs, cv=3)\n",
    "grid_search_cv.fit(Xm_train, ym_train, epochs=5, validation_data=(Xm_valid, ym_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_b_initializer</th>\n",
       "      <th>param_k_initializer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.536457</td>\n",
       "      <td>0.323750</td>\n",
       "      <td>0.620950</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f61940d...</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f61940d...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Zeros ob...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.154297</td>\n",
       "      <td>0.427630</td>\n",
       "      <td>0.612571</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f61940d...</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f61940d6...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Zeros ob...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.156895</td>\n",
       "      <td>0.381608</td>\n",
       "      <td>0.630729</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f61940d...</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Zeros ob...</td>\n",
       "      <td>0.922930</td>\n",
       "      <td>0.919926</td>\n",
       "      <td>0.925871</td>\n",
       "      <td>0.922909</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.475698</td>\n",
       "      <td>0.242146</td>\n",
       "      <td>0.633974</td>\n",
       "      <td>0.008485</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f61940d6...</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f61940d...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Ones obj...</td>\n",
       "      <td>0.252645</td>\n",
       "      <td>0.249332</td>\n",
       "      <td>0.241368</td>\n",
       "      <td>0.247782</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.467256</td>\n",
       "      <td>0.245772</td>\n",
       "      <td>0.623051</td>\n",
       "      <td>0.017444</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f61940d6...</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f61940d6...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Ones obj...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.210135</td>\n",
       "      <td>0.359876</td>\n",
       "      <td>0.625994</td>\n",
       "      <td>0.030082</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f61940d6...</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Ones obj...</td>\n",
       "      <td>0.915349</td>\n",
       "      <td>0.910762</td>\n",
       "      <td>0.918180</td>\n",
       "      <td>0.914764</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.291783</td>\n",
       "      <td>1.107483</td>\n",
       "      <td>0.639288</td>\n",
       "      <td>0.022315</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f61940d...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.RandomNo...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.584037</td>\n",
       "      <td>0.300642</td>\n",
       "      <td>0.618860</td>\n",
       "      <td>0.018806</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f61940d6...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.RandomNo...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.475256</td>\n",
       "      <td>0.360433</td>\n",
       "      <td>0.635954</td>\n",
       "      <td>0.026016</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.RandomNo...</td>\n",
       "      <td>0.920039</td>\n",
       "      <td>0.921671</td>\n",
       "      <td>0.926253</td>\n",
       "      <td>0.922655</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      12.536457      0.323750         0.620950        0.003739   \n",
       "1      12.154297      0.427630         0.612571        0.010585   \n",
       "2      12.156895      0.381608         0.630729        0.006444   \n",
       "3      12.475698      0.242146         0.633974        0.008485   \n",
       "4      12.467256      0.245772         0.623051        0.017444   \n",
       "5      12.210135      0.359876         0.625994        0.030082   \n",
       "6      11.291783      1.107483         0.639288        0.022315   \n",
       "7      12.584037      0.300642         0.618860        0.018806   \n",
       "8      12.475256      0.360433         0.635954        0.026016   \n",
       "\n",
       "                                 param_b_initializer  \\\n",
       "0  <keras.initializers.Zeros object at 0x7f61940d...   \n",
       "1  <keras.initializers.Zeros object at 0x7f61940d...   \n",
       "2  <keras.initializers.Zeros object at 0x7f61940d...   \n",
       "3  <keras.initializers.Ones object at 0x7f61940d6...   \n",
       "4  <keras.initializers.Ones object at 0x7f61940d6...   \n",
       "5  <keras.initializers.Ones object at 0x7f61940d6...   \n",
       "6  <keras.initializers.RandomNormal object at 0x7...   \n",
       "7  <keras.initializers.RandomNormal object at 0x7...   \n",
       "8  <keras.initializers.RandomNormal object at 0x7...   \n",
       "\n",
       "                                 param_k_initializer  \\\n",
       "0  <keras.initializers.Zeros object at 0x7f61940d...   \n",
       "1  <keras.initializers.Ones object at 0x7f61940d6...   \n",
       "2  <keras.initializers.RandomNormal object at 0x7...   \n",
       "3  <keras.initializers.Zeros object at 0x7f61940d...   \n",
       "4  <keras.initializers.Ones object at 0x7f61940d6...   \n",
       "5  <keras.initializers.RandomNormal object at 0x7...   \n",
       "6  <keras.initializers.Zeros object at 0x7f61940d...   \n",
       "7  <keras.initializers.Ones object at 0x7f61940d6...   \n",
       "8  <keras.initializers.RandomNormal object at 0x7...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'b_initializer': <keras.initializers.Zeros ob...           0.114159   \n",
       "1  {'b_initializer': <keras.initializers.Zeros ob...           0.114159   \n",
       "2  {'b_initializer': <keras.initializers.Zeros ob...           0.922930   \n",
       "3  {'b_initializer': <keras.initializers.Ones obj...           0.252645   \n",
       "4  {'b_initializer': <keras.initializers.Ones obj...           0.114159   \n",
       "5  {'b_initializer': <keras.initializers.Ones obj...           0.915349   \n",
       "6  {'b_initializer': <keras.initializers.RandomNo...           0.114159   \n",
       "7  {'b_initializer': <keras.initializers.RandomNo...           0.114159   \n",
       "8  {'b_initializer': <keras.initializers.RandomNo...           0.920039   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.114384           0.108493         0.112345        0.002726   \n",
       "1           0.114384           0.108493         0.112345        0.002726   \n",
       "2           0.919926           0.925871         0.922909        0.002427   \n",
       "3           0.249332           0.241368         0.247782        0.004733   \n",
       "4           0.114384           0.108493         0.112345        0.002726   \n",
       "5           0.910762           0.918180         0.914764        0.003057   \n",
       "6           0.114384           0.108493         0.112345        0.002726   \n",
       "7           0.114384           0.108493         0.112345        0.002726   \n",
       "8           0.921671           0.926253         0.922655        0.002630   \n",
       "\n",
       "   rank_test_score  \n",
       "0                5  \n",
       "1                5  \n",
       "2                1  \n",
       "3                4  \n",
       "4                5  \n",
       "5                3  \n",
       "6                5  \n",
       "7                5  \n",
       "8                2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inits_df = pd.DataFrame(grid_search_cv.cv_results_)\n",
    "inits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b_initializer': <keras.initializers.Zeros at 0x7f61940d68d0>,\n",
       " 'k_initializer': <keras.initializers.RandomNormal at 0x7f61940d6950>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9383999705314636"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = grid_search_cv.best_estimator_\n",
    "est.score(Xm_test, ym_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 6s 176us/step - loss: 2.3025 - accuracy: 0.1105 - val_loss: 2.3001 - val_accuracy: 0.1500\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 6s 173us/step - loss: 2.2986 - accuracy: 0.1176 - val_loss: 2.2974 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 6s 167us/step - loss: 2.2933 - accuracy: 0.1284 - val_loss: 2.2881 - val_accuracy: 0.2268\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 6s 169us/step - loss: 2.2846 - accuracy: 0.1634 - val_loss: 2.2770 - val_accuracy: 0.2014\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 6s 167us/step - loss: 2.2646 - accuracy: 0.2163 - val_loss: 2.2441 - val_accuracy: 0.3058\n",
      "18334/18334 [==============================] - 2s 96us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 6s 175us/step - loss: 2.3018 - accuracy: 0.1098 - val_loss: 2.2990 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 6s 176us/step - loss: 2.2986 - accuracy: 0.1183 - val_loss: 2.2952 - val_accuracy: 0.0986\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 6s 171us/step - loss: 2.2936 - accuracy: 0.1279 - val_loss: 2.2882 - val_accuracy: 0.1236\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 6s 171us/step - loss: 2.2857 - accuracy: 0.1628 - val_loss: 2.2780 - val_accuracy: 0.1872\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 6s 172us/step - loss: 2.2679 - accuracy: 0.2116 - val_loss: 2.2508 - val_accuracy: 0.2308\n",
      "18333/18333 [==============================] - 2s 97us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 6s 172us/step - loss: 2.3014 - accuracy: 0.1116 - val_loss: 2.2980 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 6s 171us/step - loss: 2.2978 - accuracy: 0.1219 - val_loss: 2.2958 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 6s 171us/step - loss: 2.2928 - accuracy: 0.1337 - val_loss: 2.2890 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 6s 169us/step - loss: 2.2837 - accuracy: 0.1496 - val_loss: 2.2751 - val_accuracy: 0.1530\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 6s 171us/step - loss: 2.2634 - accuracy: 0.2111 - val_loss: 2.2423 - val_accuracy: 0.3772\n",
      "18333/18333 [==============================] - 2s 97us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 6s 176us/step - loss: 1.8305 - accuracy: 0.4564 - val_loss: 0.8764 - val_accuracy: 0.7720\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 7s 179us/step - loss: 0.5940 - accuracy: 0.8357 - val_loss: 0.4406 - val_accuracy: 0.8802\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 7s 188us/step - loss: 0.4004 - accuracy: 0.8857 - val_loss: 0.3488 - val_accuracy: 0.9028\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 7s 186us/step - loss: 0.3408 - accuracy: 0.9025 - val_loss: 0.3086 - val_accuracy: 0.9146\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 7s 197us/step - loss: 0.3059 - accuracy: 0.9121 - val_loss: 0.2803 - val_accuracy: 0.9204\n",
      "18334/18334 [==============================] - 2s 111us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 7s 198us/step - loss: 1.8437 - accuracy: 0.5198 - val_loss: 0.8658 - val_accuracy: 0.7808\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 7s 191us/step - loss: 0.5858 - accuracy: 0.8356 - val_loss: 0.4415 - val_accuracy: 0.8766\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 7s 198us/step - loss: 0.4037 - accuracy: 0.8859 - val_loss: 0.3513 - val_accuracy: 0.9012\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 7s 201us/step - loss: 0.3446 - accuracy: 0.9026 - val_loss: 0.3141 - val_accuracy: 0.9132\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 7s 191us/step - loss: 0.3082 - accuracy: 0.9135 - val_loss: 0.2816 - val_accuracy: 0.9208\n",
      "18333/18333 [==============================] - 2s 111us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 7s 192us/step - loss: 1.8450 - accuracy: 0.5167 - val_loss: 0.8640 - val_accuracy: 0.7776\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 7s 191us/step - loss: 0.5921 - accuracy: 0.8391 - val_loss: 0.4336 - val_accuracy: 0.8816\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 7s 189us/step - loss: 0.4058 - accuracy: 0.8852 - val_loss: 0.3494 - val_accuracy: 0.9016\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 7s 190us/step - loss: 0.3485 - accuracy: 0.9014 - val_loss: 0.3104 - val_accuracy: 0.9114\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 7s 191us/step - loss: 0.3123 - accuracy: 0.9113 - val_loss: 0.2814 - val_accuracy: 0.9246\n",
      "18333/18333 [==============================] - 2s 113us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 7s 190us/step - loss: 1.4305 - accuracy: 0.6703 - val_loss: 0.6833 - val_accuracy: 0.8254\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 7s 196us/step - loss: 0.5389 - accuracy: 0.8538 - val_loss: 0.4248 - val_accuracy: 0.8860\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 8s 214us/step - loss: 0.3988 - accuracy: 0.8872 - val_loss: 0.3480 - val_accuracy: 0.9040\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 7s 190us/step - loss: 0.3455 - accuracy: 0.9011 - val_loss: 0.3077 - val_accuracy: 0.9154\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 8s 206us/step - loss: 0.3152 - accuracy: 0.9090 - val_loss: 0.2858 - val_accuracy: 0.9192\n",
      "18334/18334 [==============================] - 2s 113us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 7s 192us/step - loss: 1.4537 - accuracy: 0.6555 - val_loss: 0.7043 - val_accuracy: 0.8120\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 7s 188us/step - loss: 0.5342 - accuracy: 0.8605 - val_loss: 0.4172 - val_accuracy: 0.8866\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 7s 188us/step - loss: 0.3897 - accuracy: 0.8934 - val_loss: 0.3430 - val_accuracy: 0.9042\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 7s 192us/step - loss: 0.3398 - accuracy: 0.9035 - val_loss: 0.3074 - val_accuracy: 0.9142\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 7s 191us/step - loss: 0.3114 - accuracy: 0.9121 - val_loss: 0.2875 - val_accuracy: 0.9176\n",
      "18333/18333 [==============================] - 2s 114us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 7s 190us/step - loss: 1.4362 - accuracy: 0.6461 - val_loss: 0.6831 - val_accuracy: 0.8298\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 7s 191us/step - loss: 0.5374 - accuracy: 0.8594 - val_loss: 0.4186 - val_accuracy: 0.8894\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 7s 191us/step - loss: 0.4009 - accuracy: 0.8902 - val_loss: 0.3468 - val_accuracy: 0.9056\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 7s 191us/step - loss: 0.3513 - accuracy: 0.9000 - val_loss: 0.3122 - val_accuracy: 0.9118\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 7s 191us/step - loss: 0.3222 - accuracy: 0.9075 - val_loss: 0.2962 - val_accuracy: 0.9170\n",
      "18333/18333 [==============================] - 2s 114us/step\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 13s 239us/step - loss: 1.4514 - accuracy: 0.5949 - val_loss: 0.5294 - val_accuracy: 0.8502\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 13s 238us/step - loss: 0.4314 - accuracy: 0.8767 - val_loss: 0.3569 - val_accuracy: 0.9002\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 13s 238us/step - loss: 0.3377 - accuracy: 0.9032 - val_loss: 0.2914 - val_accuracy: 0.9182\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 13s 240us/step - loss: 0.2894 - accuracy: 0.9171 - val_loss: 0.2540 - val_accuracy: 0.9280\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 13s 237us/step - loss: 0.2530 - accuracy: 0.9277 - val_loss: 0.2191 - val_accuracy: 0.9396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000002B74E4099A0>,\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'activation': ['sigmoid', 'relu', 'tanh']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activs = ['sigmoid', 'relu', 'tanh']\n",
    "param_distribs= {'activation': activs}\n",
    "\n",
    "grid_search_cv2 = GridSearchCV(keras_clas, param_distribs, cv=3)\n",
    "grid_search_cv2.fit(Xm_train, ym_train, epochs=5, validation_data=(Xm_valid, ym_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.375996</td>\n",
       "      <td>0.311839</td>\n",
       "      <td>1.782810</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'activation': 'sigmoid'}</td>\n",
       "      <td>0.305498</td>\n",
       "      <td>0.215513</td>\n",
       "      <td>0.369225</td>\n",
       "      <td>0.296745</td>\n",
       "      <td>0.063057</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.606786</td>\n",
       "      <td>0.824242</td>\n",
       "      <td>2.051533</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'activation': 'relu'}</td>\n",
       "      <td>0.912949</td>\n",
       "      <td>0.907326</td>\n",
       "      <td>0.917417</td>\n",
       "      <td>0.912564</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.166280</td>\n",
       "      <td>0.760547</td>\n",
       "      <td>2.089895</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'activation': 'tanh'}</td>\n",
       "      <td>0.908803</td>\n",
       "      <td>0.905526</td>\n",
       "      <td>0.909398</td>\n",
       "      <td>0.907909</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      32.375996      0.311839         1.782810        0.016885   \n",
       "1      35.606786      0.824242         2.051533        0.017222   \n",
       "2      36.166280      0.760547         2.089895        0.008220   \n",
       "\n",
       "  param_activation                     params  split0_test_score  \\\n",
       "0          sigmoid  {'activation': 'sigmoid'}           0.305498   \n",
       "1             relu     {'activation': 'relu'}           0.912949   \n",
       "2             tanh     {'activation': 'tanh'}           0.908803   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.215513           0.369225         0.296745        0.063057   \n",
       "1           0.907326           0.917417         0.912564        0.004129   \n",
       "2           0.905526           0.909398         0.907909        0.001703   \n",
       "\n",
       "   rank_test_score  \n",
       "0                3  \n",
       "1                1  \n",
       "2                2  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activs_df = pd.DataFrame(grid_search_cv2.cv_results_)\n",
    "activs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 104us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9307000041007996"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est2 = grid_search_cv2.best_estimator_\n",
    "est2.score(Xm_test, ym_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 3s 70us/step - loss: 2.2950 - accuracy: 0.1880 - val_loss: 2.2886 - val_accuracy: 0.2542\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 54us/step - loss: 2.2799 - accuracy: 0.2893 - val_loss: 2.2700 - val_accuracy: 0.3078\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 53us/step - loss: 2.2563 - accuracy: 0.3701 - val_loss: 2.2388 - val_accuracy: 0.3872\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 54us/step - loss: 2.2144 - accuracy: 0.4129 - val_loss: 2.1820 - val_accuracy: 0.4134\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 53us/step - loss: 2.1368 - accuracy: 0.4398 - val_loss: 2.0769 - val_accuracy: 0.4678\n",
      "18334/18334 [==============================] - 1s 29us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 54us/step - loss: 2.2949 - accuracy: 0.1270 - val_loss: 2.2867 - val_accuracy: 0.1662\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 52us/step - loss: 2.2778 - accuracy: 0.2276 - val_loss: 2.2661 - val_accuracy: 0.2868\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 52us/step - loss: 2.2512 - accuracy: 0.3210 - val_loss: 2.2319 - val_accuracy: 0.3336\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 52us/step - loss: 2.2043 - accuracy: 0.3614 - val_loss: 2.1692 - val_accuracy: 0.3814\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 54us/step - loss: 2.1165 - accuracy: 0.4398 - val_loss: 2.0506 - val_accuracy: 0.4830\n",
      "18333/18333 [==============================] - 1s 30us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 55us/step - loss: 2.2972 - accuracy: 0.1062 - val_loss: 2.2914 - val_accuracy: 0.1298\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 59us/step - loss: 2.2830 - accuracy: 0.1883 - val_loss: 2.2748 - val_accuracy: 0.2270\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 57us/step - loss: 2.2618 - accuracy: 0.3116 - val_loss: 2.2475 - val_accuracy: 0.3666\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 54us/step - loss: 2.2246 - accuracy: 0.4354 - val_loss: 2.1980 - val_accuracy: 0.4420\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 54us/step - loss: 2.1555 - accuracy: 0.4664 - val_loss: 2.1049 - val_accuracy: 0.4884\n",
      "18333/18333 [==============================] - 1s 30us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 2s 64us/step - loss: 0.3222 - accuracy: 0.9046 - val_loss: 0.1485 - val_accuracy: 0.9566\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 61us/step - loss: 0.1284 - accuracy: 0.9612 - val_loss: 0.1077 - val_accuracy: 0.9700\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 60us/step - loss: 0.0878 - accuracy: 0.9739 - val_loss: 0.0846 - val_accuracy: 0.9766\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 61us/step - loss: 0.0676 - accuracy: 0.9803 - val_loss: 0.0997 - val_accuracy: 0.9728\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 61us/step - loss: 0.0522 - accuracy: 0.9843 - val_loss: 0.0939 - val_accuracy: 0.9778\n",
      "18334/18334 [==============================] - 1s 28us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 0.3216 - accuracy: 0.9027 - val_loss: 0.1623 - val_accuracy: 0.9516\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 60us/step - loss: 0.1285 - accuracy: 0.9611 - val_loss: 0.1115 - val_accuracy: 0.9654\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 60us/step - loss: 0.0871 - accuracy: 0.9746 - val_loss: 0.0957 - val_accuracy: 0.9714\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 60us/step - loss: 0.0684 - accuracy: 0.9801 - val_loss: 0.1053 - val_accuracy: 0.9708\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 60us/step - loss: 0.0524 - accuracy: 0.9848 - val_loss: 0.0867 - val_accuracy: 0.9776\n",
      "18333/18333 [==============================] - 1s 28us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 0.3234 - accuracy: 0.9024 - val_loss: 0.1394 - val_accuracy: 0.9584\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 61us/step - loss: 0.1264 - accuracy: 0.9626 - val_loss: 0.0919 - val_accuracy: 0.9734\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 60us/step - loss: 0.0857 - accuracy: 0.9751 - val_loss: 0.0988 - val_accuracy: 0.9696\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 61us/step - loss: 0.0640 - accuracy: 0.9815 - val_loss: 0.0860 - val_accuracy: 0.9780\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 60us/step - loss: 0.0524 - accuracy: 0.9847 - val_loss: 0.0945 - val_accuracy: 0.9782\n",
      "18333/18333 [==============================] - 1s 27us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 2s 59us/step - loss: 0.7670 - accuracy: 0.8176 - val_loss: 0.4618 - val_accuracy: 0.8790\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 57us/step - loss: 0.4289 - accuracy: 0.8831 - val_loss: 0.3805 - val_accuracy: 0.8974\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 57us/step - loss: 0.3765 - accuracy: 0.8951 - val_loss: 0.3466 - val_accuracy: 0.9064\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 58us/step - loss: 0.3498 - accuracy: 0.9023 - val_loss: 0.3258 - val_accuracy: 0.9118\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 56us/step - loss: 0.3328 - accuracy: 0.9059 - val_loss: 0.3126 - val_accuracy: 0.9140\n",
      "18334/18334 [==============================] - 1s 28us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 59us/step - loss: 0.7597 - accuracy: 0.8246 - val_loss: 0.4699 - val_accuracy: 0.8792\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 58us/step - loss: 0.4321 - accuracy: 0.8837 - val_loss: 0.3889 - val_accuracy: 0.8962\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 58us/step - loss: 0.3799 - accuracy: 0.8959 - val_loss: 0.3530 - val_accuracy: 0.9044\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 58us/step - loss: 0.3542 - accuracy: 0.9025 - val_loss: 0.3335 - val_accuracy: 0.9064\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 57us/step - loss: 0.3380 - accuracy: 0.9066 - val_loss: 0.3204 - val_accuracy: 0.9106\n",
      "18333/18333 [==============================] - 1s 27us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 60us/step - loss: 0.7673 - accuracy: 0.8221 - val_loss: 0.4630 - val_accuracy: 0.8854\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 58us/step - loss: 0.4395 - accuracy: 0.8824 - val_loss: 0.3835 - val_accuracy: 0.8984\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 58us/step - loss: 0.3877 - accuracy: 0.8938 - val_loss: 0.3500 - val_accuracy: 0.9048\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 58us/step - loss: 0.3612 - accuracy: 0.9010 - val_loss: 0.3302 - val_accuracy: 0.9088\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 58us/step - loss: 0.3442 - accuracy: 0.9043 - val_loss: 0.3164 - val_accuracy: 0.9134\n",
      "18333/18333 [==============================] - 1s 28us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 3s 70us/step - loss: 0.3284 - accuracy: 0.9043 - val_loss: 0.1518 - val_accuracy: 0.9542\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 0.1272 - accuracy: 0.9611 - val_loss: 0.0958 - val_accuracy: 0.9716\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 2s 67us/step - loss: 0.0835 - accuracy: 0.9741 - val_loss: 0.1087 - val_accuracy: 0.9682\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 2s 66us/step - loss: 0.0567 - accuracy: 0.9817 - val_loss: 0.0850 - val_accuracy: 0.9764\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 2s 65us/step - loss: 0.0426 - accuracy: 0.9853 - val_loss: 0.0885 - val_accuracy: 0.9756\n",
      "18334/18334 [==============================] - 1s 28us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 3s 69us/step - loss: 0.2287 - accuracy: 0.9289 - val_loss: 0.1013 - val_accuracy: 0.9684\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 67us/step - loss: 0.0898 - accuracy: 0.9717 - val_loss: 0.0949 - val_accuracy: 0.9718\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 0.0575 - accuracy: 0.9812 - val_loss: 0.0733 - val_accuracy: 0.9764\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 67us/step - loss: 0.0397 - accuracy: 0.9867 - val_loss: 0.0917 - val_accuracy: 0.9722\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 66us/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.0835 - val_accuracy: 0.9776\n",
      "18333/18333 [==============================] - 0s 27us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 0.2261 - accuracy: 0.9295 - val_loss: 0.1054 - val_accuracy: 0.9692\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 2s 61us/step - loss: 0.0890 - accuracy: 0.9732 - val_loss: 0.0867 - val_accuracy: 0.9746\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 0.0552 - accuracy: 0.9819 - val_loss: 0.0818 - val_accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 2s 62us/step - loss: 0.0393 - accuracy: 0.9869 - val_loss: 0.0877 - val_accuracy: 0.9754\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 2s 61us/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0817 - val_accuracy: 0.9772\n",
      "18333/18333 [==============================] - 1s 28us/step\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 4s 74us/step - loss: 0.1887 - accuracy: 0.9421 - val_loss: 0.0996 - val_accuracy: 0.9722\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 4s 71us/step - loss: 0.0771 - accuracy: 0.9757 - val_loss: 0.0887 - val_accuracy: 0.9738\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.0525 - accuracy: 0.9828 - val_loss: 0.0792 - val_accuracy: 0.9752\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 4s 71us/step - loss: 0.0387 - accuracy: 0.9872 - val_loss: 0.0755 - val_accuracy: 0.9788\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.0850 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f82e9a434d0>,\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'optimizer': [<keras.optimizers.SGD object at 0x7f82e8725390>,\n",
       "                                       <keras.optimizers.RMSprop object at 0x7f82e8725950>,\n",
       "                                       <keras.optimizers.Adagrad object at 0x7f82e8725410>,\n",
       "                                       <keras.optimizers.Adam object at 0x7f82e8725a50>]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optims = [keras.optimizers.SGD(learning_rate=0.001),\n",
    "          keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
    "          keras.optimizers.Adagrad(learning_rate=0.001),\n",
    "          keras.optimizers.Adam(learning_rate=0.001)]\n",
    "\n",
    "param_distribs= {'optimizer': optims}\n",
    "\n",
    "grid_search_cv3 = GridSearchCV(keras_clas, param_distribs, cv=3)\n",
    "grid_search_cv3.fit(Xm_train, ym_train, epochs=5, validation_data=(Xm_valid, ym_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_optimizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.510416</td>\n",
       "      <td>0.369299</td>\n",
       "      <td>0.541016</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>&lt;keras.optimizers.SGD object at 0x7f82e8725390&gt;</td>\n",
       "      <td>{'optimizer': &lt;keras.optimizers.SGD object at ...</td>\n",
       "      <td>0.467983</td>\n",
       "      <td>0.470627</td>\n",
       "      <td>0.494354</td>\n",
       "      <td>0.477655</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.580349</td>\n",
       "      <td>0.058608</td>\n",
       "      <td>0.513869</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>&lt;keras.optimizers.RMSprop object at 0x7f82e872...</td>\n",
       "      <td>{'optimizer': &lt;keras.optimizers.RMSprop object...</td>\n",
       "      <td>0.972837</td>\n",
       "      <td>0.971145</td>\n",
       "      <td>0.971199</td>\n",
       "      <td>0.971727</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.031430</td>\n",
       "      <td>0.039424</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>&lt;keras.optimizers.Adagrad object at 0x7f82e872...</td>\n",
       "      <td>{'optimizer': &lt;keras.optimizers.Adagrad object...</td>\n",
       "      <td>0.905858</td>\n",
       "      <td>0.898271</td>\n",
       "      <td>0.906889</td>\n",
       "      <td>0.903673</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.473540</td>\n",
       "      <td>0.349054</td>\n",
       "      <td>0.510408</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>&lt;keras.optimizers.Adam object at 0x7f82e8725a50&gt;</td>\n",
       "      <td>{'optimizer': &lt;keras.optimizers.Adam object at...</td>\n",
       "      <td>0.971365</td>\n",
       "      <td>0.971690</td>\n",
       "      <td>0.973218</td>\n",
       "      <td>0.972091</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      10.510416      0.369299         0.541016        0.003587   \n",
       "1      11.580349      0.058608         0.513869        0.008036   \n",
       "2      11.031430      0.039424         0.509604        0.005535   \n",
       "3      12.473540      0.349054         0.510408        0.007193   \n",
       "\n",
       "                                     param_optimizer  \\\n",
       "0    <keras.optimizers.SGD object at 0x7f82e8725390>   \n",
       "1  <keras.optimizers.RMSprop object at 0x7f82e872...   \n",
       "2  <keras.optimizers.Adagrad object at 0x7f82e872...   \n",
       "3   <keras.optimizers.Adam object at 0x7f82e8725a50>   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'optimizer': <keras.optimizers.SGD object at ...           0.467983   \n",
       "1  {'optimizer': <keras.optimizers.RMSprop object...           0.972837   \n",
       "2  {'optimizer': <keras.optimizers.Adagrad object...           0.905858   \n",
       "3  {'optimizer': <keras.optimizers.Adam object at...           0.971365   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.470627           0.494354         0.477655        0.011858   \n",
       "1           0.971145           0.971199         0.971727        0.000785   \n",
       "2           0.898271           0.906889         0.903673        0.003843   \n",
       "3           0.971690           0.973218         0.972091        0.000808   \n",
       "\n",
       "   rank_test_score  \n",
       "0                4  \n",
       "1                2  \n",
       "2                3  \n",
       "3                1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optims_df = pd.DataFrame(grid_search_cv3.cv_results_)\n",
    "optims_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': <keras.optimizers.Adam at 0x7f82e8725a50>}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9757999777793884"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est3 = grid_search_cv3.best_estimator_\n",
    "est3.score(Xm_test, ym_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 4s 100us/step - loss: 25.3265 - accuracy: 0.0995 - val_loss: 15.6360 - val_accuracy: 0.0958\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 4s 96us/step - loss: 15.6332 - accuracy: 0.1009 - val_loss: 15.6364 - val_accuracy: 0.0986\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 4s 98us/step - loss: 15.6332 - accuracy: 0.1029 - val_loss: 15.6355 - val_accuracy: 0.0958\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 4s 97us/step - loss: 15.6332 - accuracy: 0.0990 - val_loss: 15.6351 - val_accuracy: 0.0986\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 4s 99us/step - loss: 15.6332 - accuracy: 0.1001 - val_loss: 15.6354 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 63us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 101us/step - loss: 25.3344 - accuracy: 0.1020 - val_loss: 15.6252 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 15.6332 - accuracy: 0.0995 - val_loss: 15.6248 - val_accuracy: 0.0990\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 15.6332 - accuracy: 0.0982 - val_loss: 15.6248 - val_accuracy: 0.0990\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 15.6332 - accuracy: 0.0995 - val_loss: 15.6246 - val_accuracy: 0.0976\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 15.6332 - accuracy: 0.1001 - val_loss: 15.6250 - val_accuracy: 0.1100\n",
      "18333/18333 [==============================] - 1s 64us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 25.3331 - accuracy: 0.1004 - val_loss: 15.6372 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 15.6332 - accuracy: 0.1031 - val_loss: 15.6370 - val_accuracy: 0.0958\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 15.6332 - accuracy: 0.0991 - val_loss: 15.6363 - val_accuracy: 0.0986\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 3s 95us/step - loss: 15.6332 - accuracy: 0.1000 - val_loss: 15.6370 - val_accuracy: 0.0924\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 97us/step - loss: 15.6332 - accuracy: 0.1014 - val_loss: 15.6369 - val_accuracy: 0.1002\n",
      "18333/18333 [==============================] - 1s 61us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 4s 98us/step - loss: 7.1368 - accuracy: 0.1924 - val_loss: 2.5490 - val_accuracy: 0.0990\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 4s 103us/step - loss: 2.3723 - accuracy: 0.1037 - val_loss: 2.3260 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 3s 95us/step - loss: 2.3237 - accuracy: 0.0992 - val_loss: 2.3239 - val_accuracy: 0.0924\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 3s 95us/step - loss: 2.3232 - accuracy: 0.1009 - val_loss: 2.3235 - val_accuracy: 0.0986\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 4s 96us/step - loss: 2.3232 - accuracy: 0.0999 - val_loss: 2.3234 - val_accuracy: 0.1002\n",
      "18334/18334 [==============================] - 1s 61us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 7.1477 - accuracy: 0.2738 - val_loss: 2.5508 - val_accuracy: 0.1070\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 3s 95us/step - loss: 2.3723 - accuracy: 0.1035 - val_loss: 2.3258 - val_accuracy: 0.0976\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 3s 94us/step - loss: 2.3237 - accuracy: 0.1022 - val_loss: 2.3234 - val_accuracy: 0.0924\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 3s 95us/step - loss: 2.3232 - accuracy: 0.0999 - val_loss: 2.3237 - val_accuracy: 0.1002\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 3s 94us/step - loss: 2.3232 - accuracy: 0.1007 - val_loss: 2.3237 - val_accuracy: 0.0986\n",
      "18333/18333 [==============================] - 1s 62us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 7.1409 - accuracy: 0.2394 - val_loss: 2.5500 - val_accuracy: 0.1016\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 2.3723 - accuracy: 0.1070 - val_loss: 2.3265 - val_accuracy: 0.0986\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 2.3237 - accuracy: 0.1011 - val_loss: 2.3240 - val_accuracy: 0.0868\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 2.3232 - accuracy: 0.1040 - val_loss: 2.3238 - val_accuracy: 0.0924\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 2.3232 - accuracy: 0.1027 - val_loss: 2.3240 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 65us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 4s 104us/step - loss: 11.9218 - accuracy: 0.1204 - val_loss: 2.4560 - val_accuracy: 0.1002\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 4s 100us/step - loss: 2.4563 - accuracy: 0.1001 - val_loss: 2.4558 - val_accuracy: 0.0958\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 4s 100us/step - loss: 2.4563 - accuracy: 0.1035 - val_loss: 2.4560 - val_accuracy: 0.0958\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 4s 102us/step - loss: 2.4563 - accuracy: 0.1011 - val_loss: 2.4563 - val_accuracy: 0.0868\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 4s 101us/step - loss: 2.4563 - accuracy: 0.1008 - val_loss: 2.4559 - val_accuracy: 0.0990\n",
      "18334/18334 [==============================] - 1s 65us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 104us/step - loss: 11.9200 - accuracy: 0.1258 - val_loss: 2.4567 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 101us/step - loss: 2.4563 - accuracy: 0.0993 - val_loss: 2.4566 - val_accuracy: 0.0976\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 99us/step - loss: 2.4563 - accuracy: 0.1010 - val_loss: 2.4566 - val_accuracy: 0.0976\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 102us/step - loss: 2.4563 - accuracy: 0.0999 - val_loss: 2.4565 - val_accuracy: 0.0990\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 100us/step - loss: 2.4563 - accuracy: 0.1000 - val_loss: 2.4566 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 63us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 105us/step - loss: 11.9236 - accuracy: 0.1323 - val_loss: 2.4552 - val_accuracy: 0.1070\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 101us/step - loss: 2.4563 - accuracy: 0.1022 - val_loss: 2.4552 - val_accuracy: 0.1100\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 101us/step - loss: 2.4563 - accuracy: 0.1006 - val_loss: 2.4553 - val_accuracy: 0.0986\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 100us/step - loss: 2.4563 - accuracy: 0.1009 - val_loss: 2.4552 - val_accuracy: 0.1070\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 101us/step - loss: 2.4563 - accuracy: 0.0989 - val_loss: 2.4556 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 66us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 4s 100us/step - loss: 25.3150 - accuracy: 0.1075 - val_loss: 15.6163 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 4s 98us/step - loss: 15.6123 - accuracy: 0.1114 - val_loss: 15.6154 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 4s 97us/step - loss: 15.6123 - accuracy: 0.1114 - val_loss: 15.6155 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 4s 96us/step - loss: 15.6123 - accuracy: 0.1114 - val_loss: 15.6156 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 4s 97us/step - loss: 15.6123 - accuracy: 0.1114 - val_loss: 15.6155 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 61us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 100us/step - loss: 25.3027 - accuracy: 0.1107 - val_loss: 15.6006 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 15.6123 - accuracy: 0.1113 - val_loss: 15.6004 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 97us/step - loss: 15.6122 - accuracy: 0.1113 - val_loss: 15.6005 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 15.6122 - accuracy: 0.1113 - val_loss: 15.6001 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 15.6122 - accuracy: 0.1113 - val_loss: 15.6003 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 64us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 25.2828 - accuracy: 0.1118 - val_loss: 15.5782 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 15.6122 - accuracy: 0.1143 - val_loss: 15.5774 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 15.6121 - accuracy: 0.1143 - val_loss: 15.5777 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 97us/step - loss: 15.6121 - accuracy: 0.1143 - val_loss: 15.5778 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 15.6121 - accuracy: 0.1143 - val_loss: 15.5782 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 64us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 4s 96us/step - loss: 7.1036 - accuracy: 0.1316 - val_loss: 2.5288 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 3s 94us/step - loss: 2.3514 - accuracy: 0.1114 - val_loss: 2.3042 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 4s 96us/step - loss: 2.3028 - accuracy: 0.1114 - val_loss: 2.3020 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 4s 100us/step - loss: 2.3023 - accuracy: 0.1114 - val_loss: 2.3020 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 4s 96us/step - loss: 2.3023 - accuracy: 0.1112 - val_loss: 2.3021 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 62us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 7.1080 - accuracy: 0.1196 - val_loss: 2.5288 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 3s 95us/step - loss: 2.3512 - accuracy: 0.1113 - val_loss: 2.3045 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 3s 95us/step - loss: 2.3027 - accuracy: 0.1113 - val_loss: 2.3022 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 99us/step - loss: 2.3022 - accuracy: 0.1113 - val_loss: 2.3021 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 102us/step - loss: 2.3022 - accuracy: 0.1113 - val_loss: 2.3020 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 64us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 7.1154 - accuracy: 0.1220 - val_loss: 2.5295 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 3s 94us/step - loss: 2.3513 - accuracy: 0.1143 - val_loss: 2.3046 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 3s 95us/step - loss: 2.3026 - accuracy: 0.1143 - val_loss: 2.3022 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 96us/step - loss: 2.3022 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 97us/step - loss: 2.3021 - accuracy: 0.1143 - val_loss: 2.3021 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 75us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 4s 111us/step - loss: 11.9418 - accuracy: 0.1176 - val_loss: 2.4354 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 4s 100us/step - loss: 2.4355 - accuracy: 0.1114 - val_loss: 2.4350 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 4s 99us/step - loss: 2.4354 - accuracy: 0.1114 - val_loss: 2.4351 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 4s 99us/step - loss: 2.4354 - accuracy: 0.1114 - val_loss: 2.4352 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 4s 99us/step - loss: 2.4354 - accuracy: 0.1114 - val_loss: 2.4350 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 65us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 104us/step - loss: 11.9130 - accuracy: 0.1108 - val_loss: 2.4353 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 99us/step - loss: 2.4354 - accuracy: 0.1107 - val_loss: 2.4351 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 100us/step - loss: 2.4353 - accuracy: 0.1113 - val_loss: 2.4350 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 100us/step - loss: 2.4353 - accuracy: 0.1113 - val_loss: 2.4350 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 101us/step - loss: 2.4353 - accuracy: 0.1113 - val_loss: 2.4351 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 66us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 103us/step - loss: 11.8619 - accuracy: 0.1176 - val_loss: 2.4356 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 2.4353 - accuracy: 0.1143 - val_loss: 2.4352 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 97us/step - loss: 2.4353 - accuracy: 0.1143 - val_loss: 2.4351 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 100us/step - loss: 2.4353 - accuracy: 0.1143 - val_loss: 2.4353 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 101us/step - loss: 2.4353 - accuracy: 0.1143 - val_loss: 2.4353 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 64us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 4s 103us/step - loss: 25.2901 - accuracy: 0.1072 - val_loss: 15.6444 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 4s 102us/step - loss: 15.6129 - accuracy: 0.1114 - val_loss: 15.6443 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 4s 101us/step - loss: 15.6129 - accuracy: 0.1111 - val_loss: 15.6442 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 4s 101us/step - loss: 15.6129 - accuracy: 0.1111 - val_loss: 15.6445 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 4s 101us/step - loss: 15.6129 - accuracy: 0.1114 - val_loss: 15.6445 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 63us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 102us/step - loss: 25.3259 - accuracy: 0.1099 - val_loss: 15.6125 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 102us/step - loss: 15.6129 - accuracy: 0.1104 - val_loss: 15.6127 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 15.6129 - accuracy: 0.1113 - val_loss: 15.6127 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 101us/step - loss: 15.6129 - accuracy: 0.1108 - val_loss: 15.6123 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 100us/step - loss: 15.6129 - accuracy: 0.1107 - val_loss: 15.6124 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 66us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 107us/step - loss: 25.2993 - accuracy: 0.1107 - val_loss: 15.6217 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 103us/step - loss: 15.6128 - accuracy: 0.1143 - val_loss: 15.6218 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 104us/step - loss: 15.6128 - accuracy: 0.1143 - val_loss: 15.6219 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 103us/step - loss: 15.6128 - accuracy: 0.1143 - val_loss: 15.6224 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 66us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 4s 101us/step - loss: 7.1036 - accuracy: 0.1852 - val_loss: 2.5289 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 4s 100us/step - loss: 2.3518 - accuracy: 0.1104 - val_loss: 2.3051 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 4s 99us/step - loss: 2.3034 - accuracy: 0.1101 - val_loss: 2.3030 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 4s 99us/step - loss: 2.3029 - accuracy: 0.1114 - val_loss: 2.3029 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 4s 98us/step - loss: 2.3029 - accuracy: 0.1111 - val_loss: 2.3028 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 67us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 104us/step - loss: 7.1269 - accuracy: 0.1449 - val_loss: 2.5301 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 103us/step - loss: 2.3521 - accuracy: 0.1108 - val_loss: 2.3052 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 102us/step - loss: 2.3034 - accuracy: 0.1087 - val_loss: 2.3028 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 102us/step - loss: 2.3029 - accuracy: 0.1106 - val_loss: 2.3028 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 101us/step - loss: 2.3029 - accuracy: 0.1108 - val_loss: 2.3029 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 66us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 103us/step - loss: 7.0910 - accuracy: 0.1450 - val_loss: 2.5283 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 99us/step - loss: 2.3516 - accuracy: 0.1143 - val_loss: 2.3052 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 99us/step - loss: 2.3033 - accuracy: 0.1143 - val_loss: 2.3029 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 2.3029 - accuracy: 0.1143 - val_loss: 2.3028 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 98us/step - loss: 2.3028 - accuracy: 0.1143 - val_loss: 2.3030 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 64us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 4s 106us/step - loss: 11.9232 - accuracy: 0.1071 - val_loss: 2.4360 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 4s 104us/step - loss: 2.4360 - accuracy: 0.1112 - val_loss: 2.4361 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 4s 103us/step - loss: 2.4360 - accuracy: 0.1099 - val_loss: 2.4360 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 4s 100us/step - loss: 2.4360 - accuracy: 0.1099 - val_loss: 2.4361 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 4s 101us/step - loss: 2.4360 - accuracy: 0.1108 - val_loss: 2.4360 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 66us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 105us/step - loss: 11.8891 - accuracy: 0.1213 - val_loss: 2.4358 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 103us/step - loss: 2.4360 - accuracy: 0.1111 - val_loss: 2.4358 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 103us/step - loss: 2.4360 - accuracy: 0.1108 - val_loss: 2.4358 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 101us/step - loss: 2.4360 - accuracy: 0.1101 - val_loss: 2.4359 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 69us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 4s 109us/step - loss: 11.8847 - accuracy: 0.1288 - val_loss: 2.4362 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 4s 105us/step - loss: 2.4360 - accuracy: 0.1143 - val_loss: 2.4362 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 4s 104us/step - loss: 2.4359 - accuracy: 0.1143 - val_loss: 2.4361 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 4s 103us/step - loss: 2.4360 - accuracy: 0.1143 - val_loss: 2.4360 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 4s 103us/step - loss: 2.4360 - accuracy: 0.1143 - val_loss: 2.4361 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 68us/step\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 6s 103us/step - loss: 22.0744 - accuracy: 0.1115 - val_loss: 15.6279 - val_accuracy: 0.1126\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 6s 101us/step - loss: 15.6122 - accuracy: 0.1123 - val_loss: 15.5960 - val_accuracy: 0.1126\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 6s 101us/step - loss: 15.6122 - accuracy: 0.1123 - val_loss: 15.6278 - val_accuracy: 0.1126\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 6s 101us/step - loss: 15.6122 - accuracy: 0.1123 - val_loss: 15.5961 - val_accuracy: 0.1126\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 6s 102us/step - loss: 15.6122 - accuracy: 0.1123 - val_loss: 15.6282 - val_accuracy: 0.1126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f82e9a434d0>,\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'b_regularizer': [<keras.regularizers.L1L2 object at 0x7f8390d975d0>,\n",
       "                                           <keras.regularizers.L1L2 object at 0x7f8390d97250>,\n",
       "                                           <keras.regularizers.L1L2 object at 0x7f8390d97390>],\n",
       "                         'k_regularizer': [<keras.regularizers.L1L2 object at 0x7f8390d975d0>,\n",
       "                                           <keras.regularizers.L1L2 object at 0x7f8390d97250>,\n",
       "                                           <keras.regularizers.L1L2 object at 0x7f8390d97390>]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reguls = [keras.regularizers.l1(0.1),\n",
    "          keras.regularizers.l2(0.1),\n",
    "          keras.regularizers.l1_l2(l1=0.01, l2=0.01)]\n",
    "\n",
    "param_distribs= {'k_regularizer': reguls, 'b_regularizer': reguls}\n",
    "\n",
    "grid_search_cv4 = GridSearchCV(keras_clas, param_distribs, cv=3)\n",
    "grid_search_cv4.fit(Xm_train, ym_train, epochs=5, validation_data=(Xm_valid, ym_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_b_regularizer</th>\n",
       "      <th>param_k_regularizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.593502</td>\n",
       "      <td>0.145974</td>\n",
       "      <td>1.145094</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.102656</td>\n",
       "      <td>0.096929</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.387894</td>\n",
       "      <td>0.172272</td>\n",
       "      <td>1.156773</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.098124</td>\n",
       "      <td>0.098620</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.101745</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.365125</td>\n",
       "      <td>0.029791</td>\n",
       "      <td>1.189711</td>\n",
       "      <td>0.026178</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.101069</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.107982</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.630279</td>\n",
       "      <td>0.150336</td>\n",
       "      <td>1.164648</td>\n",
       "      <td>0.024885</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.433165</td>\n",
       "      <td>0.180109</td>\n",
       "      <td>1.230751</td>\n",
       "      <td>0.103386</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.209026</td>\n",
       "      <td>0.131314</td>\n",
       "      <td>1.198782</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.279883</td>\n",
       "      <td>1.408285</td>\n",
       "      <td>1.195355</td>\n",
       "      <td>0.026958</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.169538</td>\n",
       "      <td>0.262044</td>\n",
       "      <td>1.209569</td>\n",
       "      <td>0.017994</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.517962</td>\n",
       "      <td>1.864314</td>\n",
       "      <td>1.241285</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f8390d97...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.114159</td>\n",
       "      <td>0.114384</td>\n",
       "      <td>0.108493</td>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      18.593502      0.145974         1.145094        0.021679   \n",
       "1      18.387894      0.172272         1.156773        0.030864   \n",
       "2      19.365125      0.029791         1.189711        0.026178   \n",
       "3      18.630279      0.150336         1.164648        0.024885   \n",
       "4      18.433165      0.180109         1.230751        0.103386   \n",
       "5      19.209026      0.131314         1.198782        0.011620   \n",
       "6      18.279883      1.408285         1.195355        0.026958   \n",
       "7      19.169538      0.262044         1.209569        0.017994   \n",
       "8      18.517962      1.864314         1.241285        0.019132   \n",
       "\n",
       "                                 param_b_regularizer  \\\n",
       "0  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "1  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "2  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "3  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "4  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "5  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "6  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "7  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "8  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "\n",
       "                                 param_k_regularizer  \\\n",
       "0  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "1  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "2  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "3  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "4  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "5  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "6  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "7  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "8  <keras.regularizers.L1L2 object at 0x7f8390d97...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'b_regularizer': <keras.regularizers.L1L2 obj...           0.114159   \n",
       "1  {'b_regularizer': <keras.regularizers.L1L2 obj...           0.098124   \n",
       "2  {'b_regularizer': <keras.regularizers.L1L2 obj...           0.101069   \n",
       "3  {'b_regularizer': <keras.regularizers.L1L2 obj...           0.114159   \n",
       "4  {'b_regularizer': <keras.regularizers.L1L2 obj...           0.114159   \n",
       "5  {'b_regularizer': <keras.regularizers.L1L2 obj...           0.114159   \n",
       "6  {'b_regularizer': <keras.regularizers.L1L2 obj...           0.114159   \n",
       "7  {'b_regularizer': <keras.regularizers.L1L2 obj...           0.114159   \n",
       "8  {'b_regularizer': <keras.regularizers.L1L2 obj...           0.114159   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.102656           0.096929         0.104582        0.007165   \n",
       "1           0.098620           0.108493         0.101745        0.004775   \n",
       "2           0.114384           0.108493         0.107982        0.005448   \n",
       "3           0.114384           0.108493         0.112345        0.002726   \n",
       "4           0.114384           0.108493         0.112345        0.002726   \n",
       "5           0.114384           0.108493         0.112345        0.002726   \n",
       "6           0.114384           0.108493         0.112345        0.002726   \n",
       "7           0.114384           0.108493         0.112345        0.002726   \n",
       "8           0.114384           0.108493         0.112345        0.002726   \n",
       "\n",
       "   rank_test_score  \n",
       "0                8  \n",
       "1                9  \n",
       "2                7  \n",
       "3                1  \n",
       "4                1  \n",
       "5                1  \n",
       "6                1  \n",
       "7                1  \n",
       "8                1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reguls_df = pd.DataFrame(grid_search_cv4.cv_results_)\n",
    "reguls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b_regularizer': <keras.regularizers.L1L2 at 0x7f8390d97250>,\n",
       " 'k_regularizer': <keras.regularizers.L1L2 at 0x7f8390d975d0>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 58us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11349999904632568"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est4 = grid_search_cv4.best_estimator_\n",
    "est4.score(Xm_test, ym_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now; first, We will change model's hyper parameters and then we will change the structure of the model and observe the effects of this change.\n",
    "\n",
    "1. Initializers\n",
    "2. Activation functions\n",
    "3. Optimizers\n",
    "4. Regularizers\n",
    "\n",
    "Then;\n",
    "\n",
    "5. Number of Hidden layers\n",
    "6. Number of Neurons\n",
    "7. Learning Rate\n",
    "\n",
    "Then using one of libraries for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yD1q7004oTPp"
   },
   "source": [
    "#### Building model with different structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_model_2(n_hidden=3, n_neurons=97, learning_rate=3e-3):\n",
    "    k_initializer = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "    b_initializer = keras.initializers.Zeros()\n",
    "    \n",
    "    model = keras.models.Sequential([keras.layers.Flatten(input_shape=[28,28])])\n",
    "    subtraction = int(n_neurons/n_hidden)\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons-layer*subtraction, activation='relu', \n",
    "                                     kernel_initializer=k_initializer, bias_initializer=b_initializer))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\", \n",
    "                                 kernel_initializer=k_initializer, bias_initializer=b_initializer))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                  metrics=[\"accuracy\"],\n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFEjBq3pGJIb",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 7s 186us/step - loss: 0.6928 - accuracy: 0.7443 - val_loss: 0.4701 - val_accuracy: 0.8400\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 5s 144us/step - loss: 0.4542 - accuracy: 0.8393 - val_loss: 0.4042 - val_accuracy: 0.8544\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 2s 56us/step - loss: 0.3946 - accuracy: 0.8578 - val_loss: 0.3890 - val_accuracy: 0.8602\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 6s 165us/step - loss: 0.3614 - accuracy: 0.8688 - val_loss: 0.3631 - val_accuracy: 0.8678\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 6s 158us/step - loss: 0.3391 - accuracy: 0.8773 - val_loss: 0.3400 - val_accuracy: 0.8778\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 2s 59us/step - loss: 0.3210 - accuracy: 0.8826 - val_loss: 0.3708 - val_accuracy: 0.8678\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 7s 182us/step - loss: 0.3056 - accuracy: 0.8877 - val_loss: 0.3399 - val_accuracy: 0.8774\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 7s 180us/step - loss: 0.2926 - accuracy: 0.8917 - val_loss: 0.3433 - val_accuracy: 0.8772\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 7s 182us/step - loss: 0.2812 - accuracy: 0.8969 - val_loss: 0.3450 - val_accuracy: 0.8778\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 7s 182us/step - loss: 0.2687 - accuracy: 0.9014 - val_loss: 0.3220 - val_accuracy: 0.8894\n",
      "18334/18334 [==============================] - 2s 83us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 7s 189us/step - loss: 0.7053 - accuracy: 0.7371 - val_loss: 0.4871 - val_accuracy: 0.8324\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 7s 196us/step - loss: 0.4561 - accuracy: 0.8339 - val_loss: 0.3980 - val_accuracy: 0.8568\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 7s 197us/step - loss: 0.3947 - accuracy: 0.8544 - val_loss: 0.3829 - val_accuracy: 0.8592\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 7s 197us/step - loss: 0.3630 - accuracy: 0.8662 - val_loss: 0.3644 - val_accuracy: 0.8676\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 7s 197us/step - loss: 0.3433 - accuracy: 0.8727 - val_loss: 0.3628 - val_accuracy: 0.8708\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 7s 196us/step - loss: 0.3236 - accuracy: 0.8784 - val_loss: 0.3734 - val_accuracy: 0.8622\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 7s 197us/step - loss: 0.3129 - accuracy: 0.8847 - val_loss: 0.3388 - val_accuracy: 0.8832\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 7s 196us/step - loss: 0.2978 - accuracy: 0.8882 - val_loss: 0.3386 - val_accuracy: 0.8826\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 7s 196us/step - loss: 0.2902 - accuracy: 0.8905 - val_loss: 0.3369 - val_accuracy: 0.8844\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 7s 197us/step - loss: 0.2778 - accuracy: 0.8957 - val_loss: 0.3325 - val_accuracy: 0.8856\n",
      "18333/18333 [==============================] - 2s 86us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 6s 176us/step - loss: 0.6960 - accuracy: 0.7405 - val_loss: 0.4652 - val_accuracy: 0.8402\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 6s 174us/step - loss: 0.4511 - accuracy: 0.8386 - val_loss: 0.4138 - val_accuracy: 0.8528\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 7s 185us/step - loss: 0.3976 - accuracy: 0.8560 - val_loss: 0.4113 - val_accuracy: 0.8522\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 7s 184us/step - loss: 0.3654 - accuracy: 0.8656 - val_loss: 0.3532 - val_accuracy: 0.8718\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 7s 186us/step - loss: 0.3443 - accuracy: 0.8736 - val_loss: 0.3842 - val_accuracy: 0.8666\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 7s 184us/step - loss: 0.3211 - accuracy: 0.8820 - val_loss: 0.3511 - val_accuracy: 0.8744\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 7s 185us/step - loss: 0.3076 - accuracy: 0.8872 - val_loss: 0.3484 - val_accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 7s 186us/step - loss: 0.2959 - accuracy: 0.8925 - val_loss: 0.3702 - val_accuracy: 0.8718\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 7s 183us/step - loss: 0.2815 - accuracy: 0.8952 - val_loss: 0.3357 - val_accuracy: 0.8834\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 7s 183us/step - loss: 0.2700 - accuracy: 0.8993 - val_loss: 0.3479 - val_accuracy: 0.8790\n",
      "18333/18333 [==============================] - 2s 85us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 6s 155us/step - loss: 0.6362 - accuracy: 0.7753 - val_loss: 0.5062 - val_accuracy: 0.8142\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 6s 160us/step - loss: 0.4280 - accuracy: 0.8484 - val_loss: 0.4090 - val_accuracy: 0.8552\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 6s 157us/step - loss: 0.3852 - accuracy: 0.8608 - val_loss: 0.3665 - val_accuracy: 0.8704\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 6s 158us/step - loss: 0.3540 - accuracy: 0.8704 - val_loss: 0.3603 - val_accuracy: 0.8724\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 6s 160us/step - loss: 0.3348 - accuracy: 0.8767 - val_loss: 0.3446 - val_accuracy: 0.8754\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 6s 159us/step - loss: 0.3171 - accuracy: 0.8845 - val_loss: 0.3574 - val_accuracy: 0.8756\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 6s 161us/step - loss: 0.3017 - accuracy: 0.8881 - val_loss: 0.3354 - val_accuracy: 0.8810\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 4s 116us/step - loss: 0.2908 - accuracy: 0.8929 - val_loss: 0.3372 - val_accuracy: 0.8798\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 2s 54us/step - loss: 0.2780 - accuracy: 0.8976 - val_loss: 0.3159 - val_accuracy: 0.8874\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 5s 125us/step - loss: 0.2699 - accuracy: 0.9002 - val_loss: 0.3246 - val_accuracy: 0.8884\n",
      "18334/18334 [==============================] - 2s 85us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 5s 149us/step - loss: 0.6561 - accuracy: 0.7611 - val_loss: 0.4660 - val_accuracy: 0.8356\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 6s 160us/step - loss: 0.4369 - accuracy: 0.8419 - val_loss: 0.3855 - val_accuracy: 0.8662\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 2s 56us/step - loss: 0.3864 - accuracy: 0.8578 - val_loss: 0.3773 - val_accuracy: 0.8638\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 2s 51us/step - loss: 0.3591 - accuracy: 0.8660 - val_loss: 0.3699 - val_accuracy: 0.8714\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 3s 92us/step - loss: 0.3386 - accuracy: 0.8741 - val_loss: 0.3535 - val_accuracy: 0.8754\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 6s 159us/step - loss: 0.3208 - accuracy: 0.8801 - val_loss: 0.3384 - val_accuracy: 0.8790\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 6s 161us/step - loss: 0.3059 - accuracy: 0.8854 - val_loss: 0.3564 - val_accuracy: 0.8726\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 6s 156us/step - loss: 0.2954 - accuracy: 0.8894 - val_loss: 0.3291 - val_accuracy: 0.8850\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 6s 159us/step - loss: 0.2840 - accuracy: 0.8937 - val_loss: 0.3586 - val_accuracy: 0.8734\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 6s 161us/step - loss: 0.2761 - accuracy: 0.8967 - val_loss: 0.3331 - val_accuracy: 0.8834\n",
      "18333/18333 [==============================] - 2s 83us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 6s 154us/step - loss: 0.6394 - accuracy: 0.7730 - val_loss: 0.4462 - val_accuracy: 0.8462\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 6s 162us/step - loss: 0.4311 - accuracy: 0.8442 - val_loss: 0.4135 - val_accuracy: 0.8534\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 6s 160us/step - loss: 0.3844 - accuracy: 0.8627 - val_loss: 0.3833 - val_accuracy: 0.8634\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 6s 162us/step - loss: 0.3514 - accuracy: 0.8726 - val_loss: 0.3620 - val_accuracy: 0.8728\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 6s 161us/step - loss: 0.3311 - accuracy: 0.8779 - val_loss: 0.3431 - val_accuracy: 0.8758\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 4s 106us/step - loss: 0.3151 - accuracy: 0.8841 - val_loss: 0.3476 - val_accuracy: 0.8748\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 2s 49us/step - loss: 0.3000 - accuracy: 0.8899 - val_loss: 0.3516 - val_accuracy: 0.8786\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 6s 157us/step - loss: 0.2919 - accuracy: 0.8911 - val_loss: 0.3477 - val_accuracy: 0.8728\n",
      "18333/18333 [==============================] - 2s 82us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 5s 126us/step - loss: 0.6906 - accuracy: 0.7631 - val_loss: 0.4781 - val_accuracy: 0.8396\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 2s 47us/step - loss: 0.4682 - accuracy: 0.8393 - val_loss: 0.4450 - val_accuracy: 0.8482\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 6s 153us/step - loss: 0.4315 - accuracy: 0.8495 - val_loss: 0.4195 - val_accuracy: 0.8548\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 6s 160us/step - loss: 0.4089 - accuracy: 0.8574 - val_loss: 0.4153 - val_accuracy: 0.8568\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 6s 153us/step - loss: 0.3927 - accuracy: 0.8628 - val_loss: 0.4156 - val_accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 6s 159us/step - loss: 0.3786 - accuracy: 0.8655 - val_loss: 0.3961 - val_accuracy: 0.8632\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 5s 137us/step - loss: 0.3678 - accuracy: 0.8696 - val_loss: 0.3783 - val_accuracy: 0.8644\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 6s 154us/step - loss: 0.3584 - accuracy: 0.8736 - val_loss: 0.3991 - val_accuracy: 0.8596\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 6s 160us/step - loss: 0.3491 - accuracy: 0.8743 - val_loss: 0.3696 - val_accuracy: 0.8712\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 6s 160us/step - loss: 0.3427 - accuracy: 0.8768 - val_loss: 0.3736 - val_accuracy: 0.8706\n",
      "18334/18334 [==============================] - 1s 81us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 5s 137us/step - loss: 0.7142 - accuracy: 0.7510 - val_loss: 0.5023 - val_accuracy: 0.8252\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 5s 140us/step - loss: 0.4739 - accuracy: 0.8329 - val_loss: 0.4465 - val_accuracy: 0.8486\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 5s 145us/step - loss: 0.4320 - accuracy: 0.8484 - val_loss: 0.4196 - val_accuracy: 0.8568\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 3s 71us/step - loss: 0.4115 - accuracy: 0.8547 - val_loss: 0.4013 - val_accuracy: 0.8640\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.3978 - accuracy: 0.8578 - val_loss: 0.3947 - val_accuracy: 0.8610\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 2s 47us/step - loss: 0.3825 - accuracy: 0.8652 - val_loss: 0.3954 - val_accuracy: 0.8616\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.3715 - accuracy: 0.8665 - val_loss: 0.3853 - val_accuracy: 0.8632\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.3634 - accuracy: 0.8691 - val_loss: 0.3750 - val_accuracy: 0.8686\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.3543 - accuracy: 0.8719 - val_loss: 0.3766 - val_accuracy: 0.8694\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.3472 - accuracy: 0.8752 - val_loss: 0.3925 - val_accuracy: 0.8624\n",
      "18333/18333 [==============================] - 0s 23us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 2s 50us/step - loss: 0.7078 - accuracy: 0.7520 - val_loss: 0.5044 - val_accuracy: 0.8264\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.4754 - accuracy: 0.8338 - val_loss: 0.4363 - val_accuracy: 0.8522\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.4367 - accuracy: 0.8472 - val_loss: 0.4263 - val_accuracy: 0.8544\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.4175 - accuracy: 0.8537 - val_loss: 0.4091 - val_accuracy: 0.8626\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.4001 - accuracy: 0.8580 - val_loss: 0.4074 - val_accuracy: 0.8600\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.3891 - accuracy: 0.8613 - val_loss: 0.3964 - val_accuracy: 0.8636\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.3807 - accuracy: 0.8663 - val_loss: 0.4155 - val_accuracy: 0.8562\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.3698 - accuracy: 0.8682 - val_loss: 0.4011 - val_accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 2s 48us/step - loss: 0.3623 - accuracy: 0.8717 - val_loss: 0.3896 - val_accuracy: 0.8684\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 0.3550 - accuracy: 0.8730 - val_loss: 0.3839 - val_accuracy: 0.8670\n",
      "18333/18333 [==============================] - 2s 92us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 6s 168us/step - loss: 0.6829 - accuracy: 0.7566 - val_loss: 0.5198 - val_accuracy: 0.8130\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 7s 179us/step - loss: 0.4582 - accuracy: 0.8383 - val_loss: 0.4209 - val_accuracy: 0.8504\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 7s 179us/step - loss: 0.4122 - accuracy: 0.8538 - val_loss: 0.4068 - val_accuracy: 0.8606\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 6s 175us/step - loss: 0.3827 - accuracy: 0.8624 - val_loss: 0.3966 - val_accuracy: 0.8562\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 6s 172us/step - loss: 0.3587 - accuracy: 0.8705 - val_loss: 0.3742 - val_accuracy: 0.8646\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 6s 177us/step - loss: 0.3447 - accuracy: 0.8760 - val_loss: 0.4188 - val_accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 6s 177us/step - loss: 0.3291 - accuracy: 0.8785 - val_loss: 0.3380 - val_accuracy: 0.8776\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 6s 167us/step - loss: 0.3160 - accuracy: 0.8850 - val_loss: 0.3430 - val_accuracy: 0.8788\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 6s 176us/step - loss: 0.3036 - accuracy: 0.8899 - val_loss: 0.3387 - val_accuracy: 0.8788\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 6s 175us/step - loss: 0.2915 - accuracy: 0.8931 - val_loss: 0.3365 - val_accuracy: 0.8810\n",
      "18334/18334 [==============================] - 2s 82us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 6s 171us/step - loss: 0.7003 - accuracy: 0.7436 - val_loss: 0.4787 - val_accuracy: 0.8314\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.4644 - accuracy: 0.8353 - val_loss: 0.4143 - val_accuracy: 0.8542\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.4108 - accuracy: 0.8520 - val_loss: 0.3971 - val_accuracy: 0.8574\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 7s 179us/step - loss: 0.3801 - accuracy: 0.8607 - val_loss: 0.3551 - val_accuracy: 0.8764\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.3560 - accuracy: 0.8704 - val_loss: 0.3687 - val_accuracy: 0.8666\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.3354 - accuracy: 0.8779 - val_loss: 0.3430 - val_accuracy: 0.8768\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.3230 - accuracy: 0.8800 - val_loss: 0.3577 - val_accuracy: 0.8712\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.3112 - accuracy: 0.8844 - val_loss: 0.3354 - val_accuracy: 0.8812\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 7s 179us/step - loss: 0.3002 - accuracy: 0.8901 - val_loss: 0.3286 - val_accuracy: 0.8840\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.2907 - accuracy: 0.8920 - val_loss: 0.3423 - val_accuracy: 0.8754\n",
      "18333/18333 [==============================] - 2s 82us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 4s 121us/step - loss: 0.6750 - accuracy: 0.7630 - val_loss: 0.4817 - val_accuracy: 0.8310\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 2s 53us/step - loss: 0.4505 - accuracy: 0.8410 - val_loss: 0.4345 - val_accuracy: 0.8498\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 6s 169us/step - loss: 0.4109 - accuracy: 0.8542 - val_loss: 0.3897 - val_accuracy: 0.8660\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 6s 175us/step - loss: 0.3821 - accuracy: 0.8629 - val_loss: 0.4179 - val_accuracy: 0.8478\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 5s 145us/step - loss: 0.3631 - accuracy: 0.8694 - val_loss: 0.3724 - val_accuracy: 0.8676\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 2s 57us/step - loss: 0.3450 - accuracy: 0.8751 - val_loss: 0.3644 - val_accuracy: 0.8670\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 2s 53us/step - loss: 0.3287 - accuracy: 0.8788 - val_loss: 0.3523 - val_accuracy: 0.8698\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 6s 151us/step - loss: 0.3184 - accuracy: 0.8825 - val_loss: 0.3374 - val_accuracy: 0.8770\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 6s 167us/step - loss: 0.3047 - accuracy: 0.8865 - val_loss: 0.3425 - val_accuracy: 0.8790\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 6s 174us/step - loss: 0.2943 - accuracy: 0.8897 - val_loss: 0.3422 - val_accuracy: 0.8774\n",
      "18333/18333 [==============================] - 2s 85us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 6s 165us/step - loss: 0.8727 - accuracy: 0.6796 - val_loss: 0.5843 - val_accuracy: 0.7884\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 6s 174us/step - loss: 0.5559 - accuracy: 0.8029 - val_loss: 0.5135 - val_accuracy: 0.8254\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 6s 176us/step - loss: 0.5026 - accuracy: 0.8259 - val_loss: 0.4735 - val_accuracy: 0.8380\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 6s 174us/step - loss: 0.4686 - accuracy: 0.8378 - val_loss: 0.4437 - val_accuracy: 0.8478\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 4s 115us/step - loss: 0.4451 - accuracy: 0.8460 - val_loss: 0.4411 - val_accuracy: 0.8518\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 3s 88us/step - loss: 0.4284 - accuracy: 0.8500 - val_loss: 0.4208 - val_accuracy: 0.8568\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 6s 175us/step - loss: 0.4159 - accuracy: 0.8540 - val_loss: 0.4237 - val_accuracy: 0.8548\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 2s 64us/step - loss: 0.4073 - accuracy: 0.8569 - val_loss: 0.4109 - val_accuracy: 0.8578\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 5s 140us/step - loss: 0.3975 - accuracy: 0.8608 - val_loss: 0.4075 - val_accuracy: 0.8572\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 6s 174us/step - loss: 0.3895 - accuracy: 0.8623 - val_loss: 0.4155 - val_accuracy: 0.8522\n",
      "18334/18334 [==============================] - 2s 83us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 6s 154us/step - loss: 0.8456 - accuracy: 0.6785 - val_loss: 0.5716 - val_accuracy: 0.8054\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 6s 161us/step - loss: 0.5472 - accuracy: 0.8071 - val_loss: 0.4960 - val_accuracy: 0.8290\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 6s 160us/step - loss: 0.4927 - accuracy: 0.8266 - val_loss: 0.4584 - val_accuracy: 0.8414\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 6s 162us/step - loss: 0.4593 - accuracy: 0.8385 - val_loss: 0.4316 - val_accuracy: 0.8484\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 6s 162us/step - loss: 0.4335 - accuracy: 0.8471 - val_loss: 0.4159 - val_accuracy: 0.8564\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 6s 159us/step - loss: 0.4160 - accuracy: 0.8518 - val_loss: 0.4115 - val_accuracy: 0.8560\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 6s 155us/step - loss: 0.4037 - accuracy: 0.8561 - val_loss: 0.4071 - val_accuracy: 0.8592\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 6s 158us/step - loss: 0.3929 - accuracy: 0.8612 - val_loss: 0.3969 - val_accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 6s 160us/step - loss: 0.3838 - accuracy: 0.8636 - val_loss: 0.3988 - val_accuracy: 0.8620\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 6s 151us/step - loss: 0.3741 - accuracy: 0.8667 - val_loss: 0.4054 - val_accuracy: 0.8552\n",
      "18333/18333 [==============================] - 2s 84us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 5s 149us/step - loss: 0.8438 - accuracy: 0.6849 - val_loss: 0.5958 - val_accuracy: 0.8016\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 6s 159us/step - loss: 0.5626 - accuracy: 0.8038 - val_loss: 0.5322 - val_accuracy: 0.8216\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 6s 156us/step - loss: 0.5031 - accuracy: 0.8229 - val_loss: 0.5007 - val_accuracy: 0.8268\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 6s 158us/step - loss: 0.4767 - accuracy: 0.8326 - val_loss: 0.4717 - val_accuracy: 0.8370\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 6s 159us/step - loss: 0.4552 - accuracy: 0.8421 - val_loss: 0.4461 - val_accuracy: 0.8468\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 6s 160us/step - loss: 0.4376 - accuracy: 0.8456 - val_loss: 0.4370 - val_accuracy: 0.8498\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 6s 160us/step - loss: 0.4255 - accuracy: 0.8509 - val_loss: 0.4305 - val_accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 6s 160us/step - loss: 0.4129 - accuracy: 0.8556 - val_loss: 0.4193 - val_accuracy: 0.8578\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 6s 160us/step - loss: 0.4047 - accuracy: 0.8588 - val_loss: 0.4233 - val_accuracy: 0.8562\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 6s 159us/step - loss: 0.3966 - accuracy: 0.8602 - val_loss: 0.4236 - val_accuracy: 0.8550\n",
      "18333/18333 [==============================] - 2s 83us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 6s 163us/step - loss: 1.0061 - accuracy: 0.6297 - val_loss: 0.7396 - val_accuracy: 0.7422\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 6s 170us/step - loss: 0.6863 - accuracy: 0.7568 - val_loss: 0.6425 - val_accuracy: 0.7792\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 6s 170us/step - loss: 0.6173 - accuracy: 0.7806 - val_loss: 0.5966 - val_accuracy: 0.7982\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 6s 170us/step - loss: 0.5723 - accuracy: 0.7986 - val_loss: 0.5523 - val_accuracy: 0.8188\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 6s 170us/step - loss: 0.5341 - accuracy: 0.8153 - val_loss: 0.5150 - val_accuracy: 0.8344\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 6s 171us/step - loss: 0.5092 - accuracy: 0.8253 - val_loss: 0.4988 - val_accuracy: 0.8374\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 6s 171us/step - loss: 0.4894 - accuracy: 0.8317 - val_loss: 0.5110 - val_accuracy: 0.8308\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 6s 171us/step - loss: 0.4770 - accuracy: 0.8355 - val_loss: 0.4796 - val_accuracy: 0.8444\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 6s 159us/step - loss: 0.4689 - accuracy: 0.8380 - val_loss: 0.4803 - val_accuracy: 0.8374\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 6s 170us/step - loss: 0.4581 - accuracy: 0.8406 - val_loss: 0.4590 - val_accuracy: 0.8480\n",
      "18334/18334 [==============================] - 2s 83us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 6s 167us/step - loss: 0.9701 - accuracy: 0.6350 - val_loss: 0.6915 - val_accuracy: 0.7456\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.6355 - accuracy: 0.7705 - val_loss: 0.5758 - val_accuracy: 0.8020\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.5537 - accuracy: 0.8049 - val_loss: 0.5223 - val_accuracy: 0.8220\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.5106 - accuracy: 0.8205 - val_loss: 0.4848 - val_accuracy: 0.8346\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.4820 - accuracy: 0.8309 - val_loss: 0.4918 - val_accuracy: 0.8296\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.4625 - accuracy: 0.8388 - val_loss: 0.4524 - val_accuracy: 0.8448\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.4461 - accuracy: 0.8430 - val_loss: 0.4435 - val_accuracy: 0.8434\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 7s 178us/step - loss: 0.4312 - accuracy: 0.8475 - val_loss: 0.4332 - val_accuracy: 0.8522\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 5s 148us/step - loss: 0.4218 - accuracy: 0.8512 - val_loss: 0.4274 - val_accuracy: 0.8542\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 2s 63us/step - loss: 0.4121 - accuracy: 0.8546 - val_loss: 0.4239 - val_accuracy: 0.8550\n",
      "18333/18333 [==============================] - 0s 25us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 6s 155us/step - loss: 0.9526 - accuracy: 0.6349 - val_loss: 0.6618 - val_accuracy: 0.7640\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 6s 163us/step - loss: 0.6093 - accuracy: 0.7791 - val_loss: 0.5575 - val_accuracy: 0.8072\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 5s 148us/step - loss: 0.5437 - accuracy: 0.8093 - val_loss: 0.5173 - val_accuracy: 0.8162\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 2s 52us/step - loss: 0.5089 - accuracy: 0.8192 - val_loss: 0.4908 - val_accuracy: 0.8312\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 2s 49us/step - loss: 0.4884 - accuracy: 0.8271 - val_loss: 0.4739 - val_accuracy: 0.8338\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 4s 102us/step - loss: 0.4713 - accuracy: 0.8334 - val_loss: 0.4621 - val_accuracy: 0.8428\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 6s 161us/step - loss: 0.4599 - accuracy: 0.8365 - val_loss: 0.4524 - val_accuracy: 0.8444\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 6s 161us/step - loss: 0.4512 - accuracy: 0.8399 - val_loss: 0.4482 - val_accuracy: 0.8440\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 6s 159us/step - loss: 0.4428 - accuracy: 0.8432 - val_loss: 0.4319 - val_accuracy: 0.8520\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 6s 163us/step - loss: 0.4353 - accuracy: 0.8452 - val_loss: 0.4333 - val_accuracy: 0.8520\n",
      "18333/18333 [==============================] - 1s 54us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 2s 49us/step - loss: 0.5842 - accuracy: 0.7970 - val_loss: 0.4700 - val_accuracy: 0.8374\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 6s 153us/step - loss: 0.4250 - accuracy: 0.8504 - val_loss: 0.4092 - val_accuracy: 0.8524\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 4s 112us/step - loss: 0.3789 - accuracy: 0.8645 - val_loss: 0.3776 - val_accuracy: 0.8646\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 2s 47us/step - loss: 0.3498 - accuracy: 0.8754 - val_loss: 0.3656 - val_accuracy: 0.8650\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 6s 162us/step - loss: 0.3327 - accuracy: 0.8804 - val_loss: 0.3518 - val_accuracy: 0.8676\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 6s 159us/step - loss: 0.3120 - accuracy: 0.8862 - val_loss: 0.3545 - val_accuracy: 0.8698\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 6s 159us/step - loss: 0.2983 - accuracy: 0.8912 - val_loss: 0.3226 - val_accuracy: 0.8816\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 6s 159us/step - loss: 0.2839 - accuracy: 0.8954 - val_loss: 0.3293 - val_accuracy: 0.8856\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 6s 159us/step - loss: 0.2734 - accuracy: 0.8996 - val_loss: 0.3559 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 6s 159us/step - loss: 0.2653 - accuracy: 0.9019 - val_loss: 0.3175 - val_accuracy: 0.8862\n",
      "18334/18334 [==============================] - 1s 80us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 5s 136us/step - loss: 0.5902 - accuracy: 0.7955 - val_loss: 0.4402 - val_accuracy: 0.8488\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 5s 134us/step - loss: 0.4256 - accuracy: 0.8477 - val_loss: 0.4353 - val_accuracy: 0.8430\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 5s 146us/step - loss: 0.3828 - accuracy: 0.8615 - val_loss: 0.3698 - val_accuracy: 0.8680\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 5s 147us/step - loss: 0.3526 - accuracy: 0.8714 - val_loss: 0.3672 - val_accuracy: 0.8686\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 5s 147us/step - loss: 0.3293 - accuracy: 0.8789 - val_loss: 0.3396 - val_accuracy: 0.8812\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 5s 147us/step - loss: 0.3120 - accuracy: 0.8858 - val_loss: 0.3586 - val_accuracy: 0.8686\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 5s 147us/step - loss: 0.2985 - accuracy: 0.8902 - val_loss: 0.3386 - val_accuracy: 0.8762\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 5s 146us/step - loss: 0.2858 - accuracy: 0.8946 - val_loss: 0.3388 - val_accuracy: 0.8806\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 5s 147us/step - loss: 0.2740 - accuracy: 0.8980 - val_loss: 0.3654 - val_accuracy: 0.8666\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 5s 146us/step - loss: 0.2664 - accuracy: 0.9011 - val_loss: 0.3278 - val_accuracy: 0.8850\n",
      "18333/18333 [==============================] - 1s 80us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 5s 136us/step - loss: 0.5817 - accuracy: 0.7957 - val_loss: 0.4406 - val_accuracy: 0.8508\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 5s 144us/step - loss: 0.4271 - accuracy: 0.8488 - val_loss: 0.4141 - val_accuracy: 0.8490\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 5s 144us/step - loss: 0.3803 - accuracy: 0.8626 - val_loss: 0.3705 - val_accuracy: 0.8684\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 5s 136us/step - loss: 0.3513 - accuracy: 0.8701 - val_loss: 0.3616 - val_accuracy: 0.8726\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 5s 144us/step - loss: 0.3292 - accuracy: 0.8807 - val_loss: 0.3412 - val_accuracy: 0.8738\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 3s 76us/step - loss: 0.3092 - accuracy: 0.8861 - val_loss: 0.3399 - val_accuracy: 0.8772\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 2s 43us/step - loss: 0.2959 - accuracy: 0.8914 - val_loss: 0.3512 - val_accuracy: 0.8754\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 5s 129us/step - loss: 0.2831 - accuracy: 0.8956 - val_loss: 0.3162 - val_accuracy: 0.8840\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 5s 144us/step - loss: 0.2717 - accuracy: 0.8996 - val_loss: 0.3402 - val_accuracy: 0.8718\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 5s 123us/step - loss: 0.2596 - accuracy: 0.9042 - val_loss: 0.3258 - val_accuracy: 0.8856\n",
      "18333/18333 [==============================] - 0s 24us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 5s 129us/step - loss: 1.0712 - accuracy: 0.5757 - val_loss: 0.7727 - val_accuracy: 0.6988\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 7s 193us/step - loss: 0.6909 - accuracy: 0.7465 - val_loss: 0.6178 - val_accuracy: 0.7852\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 7s 195us/step - loss: 0.5984 - accuracy: 0.7909 - val_loss: 0.5752 - val_accuracy: 0.8060\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 7s 195us/step - loss: 0.5549 - accuracy: 0.8076 - val_loss: 0.5406 - val_accuracy: 0.8214\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 7s 196us/step - loss: 0.5297 - accuracy: 0.8161 - val_loss: 0.5013 - val_accuracy: 0.8338\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 7s 196us/step - loss: 0.5072 - accuracy: 0.8253 - val_loss: 0.5202 - val_accuracy: 0.8222\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 7s 196us/step - loss: 0.4942 - accuracy: 0.8265 - val_loss: 0.4751 - val_accuracy: 0.8376\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 7s 195us/step - loss: 0.4811 - accuracy: 0.8321 - val_loss: 0.4650 - val_accuracy: 0.8442\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 7s 195us/step - loss: 0.4690 - accuracy: 0.8346 - val_loss: 0.4564 - val_accuracy: 0.8476\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 7s 195us/step - loss: 0.4591 - accuracy: 0.8390 - val_loss: 0.4597 - val_accuracy: 0.8450\n",
      "18334/18334 [==============================] - 2s 85us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 6s 169us/step - loss: 1.1991 - accuracy: 0.4957 - val_loss: 0.9688 - val_accuracy: 0.5718\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 7s 187us/step - loss: 0.9164 - accuracy: 0.6276 - val_loss: 0.8641 - val_accuracy: 0.6664\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 7s 185us/step - loss: 0.8368 - accuracy: 0.6787 - val_loss: 0.7893 - val_accuracy: 0.7160\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 7s 191us/step - loss: 0.7694 - accuracy: 0.7164 - val_loss: 0.7224 - val_accuracy: 0.7314\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 7s 186us/step - loss: 0.7046 - accuracy: 0.7484 - val_loss: 0.6839 - val_accuracy: 0.7578\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 7s 193us/step - loss: 0.6673 - accuracy: 0.7651 - val_loss: 0.6315 - val_accuracy: 0.7918\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 7s 194us/step - loss: 0.6395 - accuracy: 0.7746 - val_loss: 0.6607 - val_accuracy: 0.7532\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 7s 192us/step - loss: 0.6153 - accuracy: 0.7805 - val_loss: 0.5922 - val_accuracy: 0.7942\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 7s 193us/step - loss: 0.5970 - accuracy: 0.7846 - val_loss: 0.5882 - val_accuracy: 0.7974\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 5s 129us/step - loss: 0.5794 - accuracy: 0.7913 - val_loss: 0.5733 - val_accuracy: 0.8014\n",
      "18333/18333 [==============================] - 0s 26us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 4s 113us/step - loss: 1.0807 - accuracy: 0.5648 - val_loss: 0.8014 - val_accuracy: 0.7242\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 7s 181us/step - loss: 0.7503 - accuracy: 0.7364 - val_loss: 0.6921 - val_accuracy: 0.7608\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 7s 180us/step - loss: 0.6698 - accuracy: 0.7656 - val_loss: 0.6266 - val_accuracy: 0.7934\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 3s 73us/step - loss: 0.6002 - accuracy: 0.7893 - val_loss: 0.5982 - val_accuracy: 0.8026\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 2s 54us/step - loss: 0.5465 - accuracy: 0.8088 - val_loss: 0.5232 - val_accuracy: 0.8240\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 4s 114us/step - loss: 0.5130 - accuracy: 0.8219 - val_loss: 0.4986 - val_accuracy: 0.8350\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 4s 119us/step - loss: 0.4895 - accuracy: 0.8307 - val_loss: 0.5016 - val_accuracy: 0.8328\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 3s 93us/step - loss: 0.4746 - accuracy: 0.8359 - val_loss: 0.4859 - val_accuracy: 0.8392\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 6s 176us/step - loss: 0.4574 - accuracy: 0.8434 - val_loss: 0.4590 - val_accuracy: 0.8486\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 2s 61us/step - loss: 0.4448 - accuracy: 0.8452 - val_loss: 0.4628 - val_accuracy: 0.8498\n",
      "18333/18333 [==============================] - 0s 24us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 5s 143us/step - loss: 0.6920 - accuracy: 0.7654 - val_loss: 0.4803 - val_accuracy: 0.8338\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 5s 146us/step - loss: 0.4590 - accuracy: 0.8415 - val_loss: 0.4296 - val_accuracy: 0.8530\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 5s 146us/step - loss: 0.4229 - accuracy: 0.8510 - val_loss: 0.4139 - val_accuracy: 0.8590\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 5s 146us/step - loss: 0.3992 - accuracy: 0.8609 - val_loss: 0.3907 - val_accuracy: 0.8660\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 5s 147us/step - loss: 0.3824 - accuracy: 0.8661 - val_loss: 0.3753 - val_accuracy: 0.8692\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 5s 137us/step - loss: 0.3698 - accuracy: 0.8708 - val_loss: 0.3691 - val_accuracy: 0.8718\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 5s 145us/step - loss: 0.3593 - accuracy: 0.8732 - val_loss: 0.3930 - val_accuracy: 0.8650\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 5s 146us/step - loss: 0.3492 - accuracy: 0.8769 - val_loss: 0.3826 - val_accuracy: 0.8674\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 5s 146us/step - loss: 0.3435 - accuracy: 0.8793 - val_loss: 0.3676 - val_accuracy: 0.8704\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 5s 146us/step - loss: 0.3365 - accuracy: 0.8820 - val_loss: 0.3619 - val_accuracy: 0.8716\n",
      "18334/18334 [==============================] - 1s 81us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 5s 137us/step - loss: 0.7123 - accuracy: 0.7466 - val_loss: 0.4992 - val_accuracy: 0.8212\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 5s 148us/step - loss: 0.4839 - accuracy: 0.8293 - val_loss: 0.4461 - val_accuracy: 0.8478\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 5s 138us/step - loss: 0.4436 - accuracy: 0.8423 - val_loss: 0.4321 - val_accuracy: 0.8486\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 5s 149us/step - loss: 0.4221 - accuracy: 0.8504 - val_loss: 0.4251 - val_accuracy: 0.8498\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 5s 149us/step - loss: 0.4030 - accuracy: 0.8566 - val_loss: 0.4280 - val_accuracy: 0.8500\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 5s 148us/step - loss: 0.3880 - accuracy: 0.8623 - val_loss: 0.3819 - val_accuracy: 0.8668\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 5s 148us/step - loss: 0.3719 - accuracy: 0.8658 - val_loss: 0.4089 - val_accuracy: 0.8550\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 5s 149us/step - loss: 0.3598 - accuracy: 0.8703 - val_loss: 0.3683 - val_accuracy: 0.8718\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 5s 148us/step - loss: 0.3527 - accuracy: 0.8726 - val_loss: 0.3707 - val_accuracy: 0.8698\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 5s 148us/step - loss: 0.3454 - accuracy: 0.8756 - val_loss: 0.3709 - val_accuracy: 0.8720\n",
      "18333/18333 [==============================] - 1s 81us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 6s 155us/step - loss: 0.7031 - accuracy: 0.7601 - val_loss: 0.4999 - val_accuracy: 0.8294\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 6s 163us/step - loss: 0.4692 - accuracy: 0.8364 - val_loss: 0.4419 - val_accuracy: 0.8484\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 6s 163us/step - loss: 0.4308 - accuracy: 0.8483 - val_loss: 0.4105 - val_accuracy: 0.8604\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 6s 163us/step - loss: 0.4106 - accuracy: 0.8560 - val_loss: 0.3983 - val_accuracy: 0.8640\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 6s 163us/step - loss: 0.3987 - accuracy: 0.8596 - val_loss: 0.4161 - val_accuracy: 0.8590\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 6s 164us/step - loss: 0.3845 - accuracy: 0.8629 - val_loss: 0.4027 - val_accuracy: 0.8612\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 6s 155us/step - loss: 0.3749 - accuracy: 0.8676 - val_loss: 0.3879 - val_accuracy: 0.8658\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 6s 160us/step - loss: 0.3643 - accuracy: 0.8707 - val_loss: 0.3807 - val_accuracy: 0.8676\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 6s 159us/step - loss: 0.3551 - accuracy: 0.8728 - val_loss: 0.3765 - val_accuracy: 0.8704\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 6s 158us/step - loss: 0.3481 - accuracy: 0.8762 - val_loss: 0.3712 - val_accuracy: 0.8716\n",
      "18333/18333 [==============================] - 1s 82us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 6s 172us/step - loss: 0.9759 - accuracy: 0.6114 - val_loss: 0.6893 - val_accuracy: 0.7472\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 7s 181us/step - loss: 0.6024 - accuracy: 0.7871 - val_loss: 0.5308 - val_accuracy: 0.8206\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 7s 183us/step - loss: 0.5195 - accuracy: 0.8213 - val_loss: 0.4882 - val_accuracy: 0.8306\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 7s 180us/step - loss: 0.4821 - accuracy: 0.8341 - val_loss: 0.4507 - val_accuracy: 0.8494\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 7s 183us/step - loss: 0.4552 - accuracy: 0.8416 - val_loss: 0.4402 - val_accuracy: 0.8512\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 7s 182us/step - loss: 0.4301 - accuracy: 0.8511 - val_loss: 0.4359 - val_accuracy: 0.8520\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 7s 183us/step - loss: 0.4169 - accuracy: 0.8549 - val_loss: 0.4365 - val_accuracy: 0.8490\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 7s 182us/step - loss: 0.4015 - accuracy: 0.8606 - val_loss: 0.4181 - val_accuracy: 0.8560\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 7s 182us/step - loss: 0.3912 - accuracy: 0.8645 - val_loss: 0.4162 - val_accuracy: 0.8602\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 7s 183us/step - loss: 0.3808 - accuracy: 0.8680 - val_loss: 0.4021 - val_accuracy: 0.8646\n",
      "18334/18334 [==============================] - 2s 85us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 7s 191us/step - loss: 0.9695 - accuracy: 0.6308 - val_loss: 0.7863 - val_accuracy: 0.7166\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 7s 196us/step - loss: 0.6923 - accuracy: 0.7445 - val_loss: 0.6103 - val_accuracy: 0.7742\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 7s 197us/step - loss: 0.5980 - accuracy: 0.7809 - val_loss: 0.5521 - val_accuracy: 0.8048\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 7s 197us/step - loss: 0.5519 - accuracy: 0.7983 - val_loss: 0.5165 - val_accuracy: 0.8154\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 7s 188us/step - loss: 0.5162 - accuracy: 0.8163 - val_loss: 0.4900 - val_accuracy: 0.8310\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 7s 196us/step - loss: 0.4918 - accuracy: 0.8240 - val_loss: 0.4723 - val_accuracy: 0.8344\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 7s 197us/step - loss: 0.4707 - accuracy: 0.8315 - val_loss: 0.4429 - val_accuracy: 0.8474\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 6s 151us/step - loss: 0.4515 - accuracy: 0.8384 - val_loss: 0.4464 - val_accuracy: 0.8370\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 2s 59us/step - loss: 0.4328 - accuracy: 0.8449 - val_loss: 0.4316 - val_accuracy: 0.8522\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 7s 188us/step - loss: 0.4208 - accuracy: 0.8482 - val_loss: 0.4517 - val_accuracy: 0.8428\n",
      "18333/18333 [==============================] - 1s 59us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 2s 64us/step - loss: 1.0159 - accuracy: 0.6075 - val_loss: 0.7394 - val_accuracy: 0.7310\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 7s 197us/step - loss: 0.6664 - accuracy: 0.7586 - val_loss: 0.6043 - val_accuracy: 0.7920\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 2s 68us/step - loss: 0.5858 - accuracy: 0.7912 - val_loss: 0.6016 - val_accuracy: 0.7894\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 2s 58us/step - loss: 0.5350 - accuracy: 0.8119 - val_loss: 0.5225 - val_accuracy: 0.8232\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 6s 163us/step - loss: 0.5015 - accuracy: 0.8298 - val_loss: 0.4664 - val_accuracy: 0.8436\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 7s 196us/step - loss: 0.4739 - accuracy: 0.8374 - val_loss: 0.4525 - val_accuracy: 0.8484\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 7s 196us/step - loss: 0.4496 - accuracy: 0.8473 - val_loss: 0.4458 - val_accuracy: 0.8480\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 7s 196us/step - loss: 0.4312 - accuracy: 0.8504 - val_loss: 0.4232 - val_accuracy: 0.8560\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 7s 196us/step - loss: 0.4154 - accuracy: 0.8563 - val_loss: 0.4173 - val_accuracy: 0.8602\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 7s 196us/step - loss: 0.3996 - accuracy: 0.8584 - val_loss: 0.4354 - val_accuracy: 0.8486\n",
      "18333/18333 [==============================] - 2s 84us/step\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 7s 133us/step - loss: 0.5323 - accuracy: 0.8156 - val_loss: 0.4203 - val_accuracy: 0.8514\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 7s 136us/step - loss: 0.3917 - accuracy: 0.8601 - val_loss: 0.3498 - val_accuracy: 0.8740\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 6s 102us/step - loss: 0.3506 - accuracy: 0.8727 - val_loss: 0.3440 - val_accuracy: 0.8746\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 6s 100us/step - loss: 0.3277 - accuracy: 0.8796 - val_loss: 0.3419 - val_accuracy: 0.8738\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 8s 141us/step - loss: 0.3071 - accuracy: 0.8868 - val_loss: 0.3383 - val_accuracy: 0.8776\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 8s 141us/step - loss: 0.2956 - accuracy: 0.8914 - val_loss: 0.3197 - val_accuracy: 0.8852\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 8s 141us/step - loss: 0.2823 - accuracy: 0.8966 - val_loss: 0.3198 - val_accuracy: 0.8856\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 8s 141us/step - loss: 0.2719 - accuracy: 0.8990 - val_loss: 0.3193 - val_accuracy: 0.8834\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 8s 140us/step - loss: 0.2610 - accuracy: 0.9038 - val_loss: 0.3154 - val_accuracy: 0.8862\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 8s 140us/step - loss: 0.2544 - accuracy: 0.9049 - val_loss: 0.3286 - val_accuracy: 0.8842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f6b002a6890>,\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f6b002a6850>,\n",
       "                                        'n_hidden': [1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "keras_clas = keras.wrappers.scikit_learn.KerasClassifier(build_mlp_model_2)\n",
    "\n",
    "param_distribs= {\n",
    "    'n_hidden': [1, 2, 3],\n",
    "    'n_neurons':np.arange(1, 100), \n",
    "    'learning_rate':reciprocal(3e-4, 3e-2)\n",
    "    }\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_clas, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(Xf_train, yf_train, epochs=10, validation_data=(Xf_valid, yf_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iilvog8vRhmE",
    "outputId": "70143191-d51d-4224-d1de-e0adbca42146",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_hidden</th>\n",
       "      <th>param_n_neurons</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.843194</td>\n",
       "      <td>7.147386</td>\n",
       "      <td>1.559496</td>\n",
       "      <td>0.020295</td>\n",
       "      <td>0.00682364</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>{'learning_rate': 0.0068236448395058895, 'n_hi...</td>\n",
       "      <td>0.878750</td>\n",
       "      <td>0.881580</td>\n",
       "      <td>0.879561</td>\n",
       "      <td>0.879964</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.030672</td>\n",
       "      <td>4.492470</td>\n",
       "      <td>1.534257</td>\n",
       "      <td>0.025166</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>{'learning_rate': 0.010983950530248155, 'n_hid...</td>\n",
       "      <td>0.875477</td>\n",
       "      <td>0.880761</td>\n",
       "      <td>0.872689</td>\n",
       "      <td>0.876309</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.098480</td>\n",
       "      <td>14.029069</td>\n",
       "      <td>1.198951</td>\n",
       "      <td>0.560672</td>\n",
       "      <td>0.00115391</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>{'learning_rate': 0.0011539128289684653, 'n_hi...</td>\n",
       "      <td>0.858514</td>\n",
       "      <td>0.866088</td>\n",
       "      <td>0.864834</td>\n",
       "      <td>0.863145</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.825824</td>\n",
       "      <td>8.579169</td>\n",
       "      <td>1.529390</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>0.0297593</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>{'learning_rate': 0.02975933289359122, 'n_hidd...</td>\n",
       "      <td>0.869914</td>\n",
       "      <td>0.875525</td>\n",
       "      <td>0.871543</td>\n",
       "      <td>0.872327</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.637600</td>\n",
       "      <td>2.335186</td>\n",
       "      <td>1.537436</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.0197456</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>{'learning_rate': 0.019745567147119655, 'n_hid...</td>\n",
       "      <td>0.840733</td>\n",
       "      <td>0.851197</td>\n",
       "      <td>0.848143</td>\n",
       "      <td>0.846691</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56.831757</td>\n",
       "      <td>5.949237</td>\n",
       "      <td>0.992344</td>\n",
       "      <td>0.438586</td>\n",
       "      <td>0.000803111</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>{'learning_rate': 0.0008031114249482332, 'n_hi...</td>\n",
       "      <td>0.830588</td>\n",
       "      <td>0.852943</td>\n",
       "      <td>0.842906</td>\n",
       "      <td>0.842145</td>\n",
       "      <td>0.009142</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48.951844</td>\n",
       "      <td>3.348276</td>\n",
       "      <td>1.131573</td>\n",
       "      <td>0.490932</td>\n",
       "      <td>0.000421389</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>{'learning_rate': 0.00042138860510843035, 'n_h...</td>\n",
       "      <td>0.880004</td>\n",
       "      <td>0.887962</td>\n",
       "      <td>0.881471</td>\n",
       "      <td>0.883145</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59.871607</td>\n",
       "      <td>11.908661</td>\n",
       "      <td>0.826804</td>\n",
       "      <td>0.519855</td>\n",
       "      <td>0.00107887</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>{'learning_rate': 0.0010788748627323355, 'n_hi...</td>\n",
       "      <td>0.829061</td>\n",
       "      <td>0.798233</td>\n",
       "      <td>0.839633</td>\n",
       "      <td>0.822309</td>\n",
       "      <td>0.017563</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55.462281</td>\n",
       "      <td>2.584413</td>\n",
       "      <td>1.491978</td>\n",
       "      <td>0.008405</td>\n",
       "      <td>0.000377879</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>{'learning_rate': 0.0003778787441156093, 'n_hi...</td>\n",
       "      <td>0.864296</td>\n",
       "      <td>0.871925</td>\n",
       "      <td>0.866688</td>\n",
       "      <td>0.867636</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62.746475</td>\n",
       "      <td>4.525778</td>\n",
       "      <td>1.397908</td>\n",
       "      <td>0.218211</td>\n",
       "      <td>0.00928811</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>{'learning_rate': 0.009288105413199988, 'n_hid...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.833688</td>\n",
       "      <td>0.839306</td>\n",
       "      <td>0.842309</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      64.843194      7.147386         1.559496        0.020295   \n",
       "1      47.030672      4.492470         1.534257        0.025166   \n",
       "2      33.098480     14.029069         1.198951        0.560672   \n",
       "3      58.825824      8.579169         1.529390        0.021876   \n",
       "4      56.637600      2.335186         1.537436        0.009977   \n",
       "5      56.831757      5.949237         0.992344        0.438586   \n",
       "6      48.951844      3.348276         1.131573        0.490932   \n",
       "7      59.871607     11.908661         0.826804        0.519855   \n",
       "8      55.462281      2.584413         1.491978        0.008405   \n",
       "9      62.746475      4.525778         1.397908        0.218211   \n",
       "\n",
       "  param_learning_rate param_n_hidden param_n_neurons  \\\n",
       "0          0.00682364              3              87   \n",
       "1            0.010984              2              77   \n",
       "2          0.00115391              1              22   \n",
       "3           0.0297593              2              54   \n",
       "4           0.0197456              2              22   \n",
       "5         0.000803111              2              12   \n",
       "6         0.000421389              1              89   \n",
       "7          0.00107887              3              14   \n",
       "8         0.000377879              1              21   \n",
       "9          0.00928811              3              22   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.0068236448395058895, 'n_hi...           0.878750   \n",
       "1  {'learning_rate': 0.010983950530248155, 'n_hid...           0.875477   \n",
       "2  {'learning_rate': 0.0011539128289684653, 'n_hi...           0.858514   \n",
       "3  {'learning_rate': 0.02975933289359122, 'n_hidd...           0.869914   \n",
       "4  {'learning_rate': 0.019745567147119655, 'n_hid...           0.840733   \n",
       "5  {'learning_rate': 0.0008031114249482332, 'n_hi...           0.830588   \n",
       "6  {'learning_rate': 0.00042138860510843035, 'n_h...           0.880004   \n",
       "7  {'learning_rate': 0.0010788748627323355, 'n_hi...           0.829061   \n",
       "8  {'learning_rate': 0.0003778787441156093, 'n_hi...           0.864296   \n",
       "9  {'learning_rate': 0.009288105413199988, 'n_hid...           0.853933   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.881580           0.879561         0.879964        0.001190   \n",
       "1           0.880761           0.872689         0.876309        0.003348   \n",
       "2           0.866088           0.864834         0.863145        0.003315   \n",
       "3           0.875525           0.871543         0.872327        0.002357   \n",
       "4           0.851197           0.848143         0.846691        0.004394   \n",
       "5           0.852943           0.842906         0.842145        0.009142   \n",
       "6           0.887962           0.881471         0.883145        0.003458   \n",
       "7           0.798233           0.839633         0.822309        0.017563   \n",
       "8           0.871925           0.866688         0.867636        0.003186   \n",
       "9           0.833688           0.839306         0.842309        0.008533   \n",
       "\n",
       "   rank_test_score  \n",
       "0                2  \n",
       "1                3  \n",
       "2                6  \n",
       "3                4  \n",
       "4                7  \n",
       "5                9  \n",
       "6                1  \n",
       "7               10  \n",
       "8                5  \n",
       "9                8  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df = pd.DataFrame(rnd_search_cv.cv_results_)\n",
    "params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.00042138860510843035, 'n_hidden': 1, 'n_neurons': 89}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8490999937057495"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mlp = rnd_search_cv.best_estimator_\n",
    "best_mlp.score(Xf_test, yf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_34 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 89)                69865     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 10)                900       \n",
      "=================================================================\n",
      "Total params: 70,765\n",
      "Trainable params: 70,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_mlp.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.5371 - accuracy: 0.8124 - val_loss: 0.4057 - val_accuracy: 0.8584\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 9s 155us/step - loss: 0.3872 - accuracy: 0.8606 - val_loss: 0.3562 - val_accuracy: 0.8744\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 6s 108us/step - loss: 0.3474 - accuracy: 0.8747 - val_loss: 0.3321 - val_accuracy: 0.8774\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 5s 83us/step - loss: 0.3236 - accuracy: 0.8814 - val_loss: 0.3369 - val_accuracy: 0.8776\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 5s 87us/step - loss: 0.3060 - accuracy: 0.8871 - val_loss: 0.3202 - val_accuracy: 0.8812\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 5s 99us/step - loss: 0.2880 - accuracy: 0.8952 - val_loss: 0.3279 - val_accuracy: 0.8802\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.2790 - accuracy: 0.8971 - val_loss: 0.3080 - val_accuracy: 0.8934\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 0.2675 - accuracy: 0.9012 - val_loss: 0.3082 - val_accuracy: 0.8902\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 3s 48us/step - loss: 0.2570 - accuracy: 0.9043 - val_loss: 0.3075 - val_accuracy: 0.8916\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 5s 96us/step - loss: 0.2493 - accuracy: 0.9078 - val_loss: 0.3205 - val_accuracy: 0.8872\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.2413 - accuracy: 0.9087 - val_loss: 0.3118 - val_accuracy: 0.8900\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.2333 - accuracy: 0.9135 - val_loss: 0.2991 - val_accuracy: 0.8932\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.2264 - accuracy: 0.9165 - val_loss: 0.3082 - val_accuracy: 0.8944\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.2197 - accuracy: 0.9187 - val_loss: 0.3091 - val_accuracy: 0.8966\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 8s 150us/step - loss: 0.2150 - accuracy: 0.9211 - val_loss: 0.3156 - val_accuracy: 0.8924\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.2091 - accuracy: 0.9216 - val_loss: 0.3244 - val_accuracy: 0.8968\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 8s 146us/step - loss: 0.2024 - accuracy: 0.9242 - val_loss: 0.3220 - val_accuracy: 0.8910\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 8s 150us/step - loss: 0.2001 - accuracy: 0.9253 - val_loss: 0.3170 - val_accuracy: 0.8950\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.1946 - accuracy: 0.9277 - val_loss: 0.3357 - val_accuracy: 0.8928\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 8s 150us/step - loss: 0.1895 - accuracy: 0.9294 - val_loss: 0.3198 - val_accuracy: 0.8958\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 8s 145us/step - loss: 0.1842 - accuracy: 0.9317 - val_loss: 0.3395 - val_accuracy: 0.8944\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.1817 - accuracy: 0.9321 - val_loss: 0.3657 - val_accuracy: 0.8898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6ac31754d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mlp.fit(Xf_train, yf_train, epochs=30, validation_data=(Xf_valid, yf_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 84us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[88.5731869403839, 0.8514999747276306]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mlp.model.evaluate(Xf_test, yf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp.model.save(\"./models/mlp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4Zd_JADIy7dx"
   ],
   "name": "Task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
