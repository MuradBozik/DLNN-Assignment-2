{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3Q--7ksYKDex",
    "outputId": "cb68d890-888d-4d4c-a3ab-def7dc13cd14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "eimPJuSzKIEv",
    "outputId": "e28c6887-e5b5-449a-b49f-aebda987505a"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist \n",
    "(Xf_train_full, yf_train_full), (Xf_test, yf_test) = fashion_mnist.load_data()\n",
    "Xf_test = Xf_test/255.0\n",
    "Xf_valid, Xf_train = Xf_train_full[:5000] / 255.0, Xf_train_full[5000:] / 255.0\n",
    "yf_valid, yf_train = yf_train_full[:5000], yf_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "Xm, ym = mnist[\"data\"].reshape(-1, 28, 28), mnist[\"target\"]\n",
    "ym = np.array(ym, dtype='uint8')\n",
    "Xm_train_full, Xm_test, ym_train_full, ym_test = Xm[:60000], Xm[60000:], ym[:60000], ym[60000:]\n",
    "Xm_valid, Xm_train = Xm_train_full[:5000] / 255.0, Xm_train_full[5000:] / 255.0\n",
    "ym_valid, ym_train = ym_train_full[:5000], ym_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQn8JJhOm067"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEJQcd1k3zf7"
   },
   "outputs": [],
   "source": [
    "def preprocessing_image_for_cnn(input_data):\n",
    "    return np.expand_dims(input_data, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TQdP1wp3PLs"
   },
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdrFlRvT3Stu"
   },
   "outputs": [],
   "source": [
    "cnn_model = keras.models.Sequential([\n",
    "              keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\", input_shape=[28, 28, 1]),\n",
    "              keras.layers.MaxPooling2D(2),\n",
    "              keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "              keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "              keras.layers.MaxPooling2D(2),\n",
    "              keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "              keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "              keras.layers.MaxPooling2D(2),\n",
    "              keras.layers.Flatten(),\n",
    "              keras.layers.Dense(128, activation=\"relu\"),\n",
    "              keras.layers.Dropout(0.5),\n",
    "              keras.layers.Dense(64, activation=\"relu\"),\n",
    "              keras.layers.Dropout(0.5),\n",
    "              keras.layers.Dense(10, activation=\"softmax\")\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "AhvUWE6P5MVG",
    "outputId": "ca5fb218-eead-411e-d2f9-ed38d643cfae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        3200      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,413,834\n",
      "Trainable params: 1,413,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdnlK0Rw5PzG"
   },
   "outputs": [],
   "source": [
    "cnn_model.compile( \n",
    "    optimizer=\"sgd\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Zd_JADIy7dx"
   },
   "source": [
    "### Training and Evaluation on MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "BsfRvkPo7bzz",
    "outputId": "ae1b4e31-2258-4e19-e3f7-42ad083275fe",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 34s 616us/step - loss: 1.2252 - accuracy: 0.5747 - val_loss: 0.2180 - val_accuracy: 0.9340\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 26s 474us/step - loss: 0.3131 - accuracy: 0.9099 - val_loss: 0.1056 - val_accuracy: 0.9686\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 26s 475us/step - loss: 0.2033 - accuracy: 0.9455 - val_loss: 0.0742 - val_accuracy: 0.9796\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 26s 474us/step - loss: 0.1520 - accuracy: 0.9612 - val_loss: 0.0618 - val_accuracy: 0.9828\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 26s 473us/step - loss: 0.1235 - accuracy: 0.9670 - val_loss: 0.0583 - val_accuracy: 0.9860\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 26s 474us/step - loss: 0.1078 - accuracy: 0.9725 - val_loss: 0.0544 - val_accuracy: 0.9872\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 26s 475us/step - loss: 0.0917 - accuracy: 0.9768 - val_loss: 0.0543 - val_accuracy: 0.9874\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 26s 476us/step - loss: 0.0826 - accuracy: 0.9793 - val_loss: 0.0444 - val_accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 26s 476us/step - loss: 0.0740 - accuracy: 0.9815 - val_loss: 0.0413 - val_accuracy: 0.9896\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 26s 475us/step - loss: 0.0698 - accuracy: 0.9827 - val_loss: 0.0482 - val_accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "cnn_history = cnn_model.fit(preprocessing_image_for_cnn(Xm_train), ym_train, epochs=10, \n",
    "                            validation_data=(preprocessing_image_for_cnn(Xm_valid), ym_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "YO7oHZUCPN2o",
    "outputId": "0edba63d-3d5f-400a-afb4-bd6a746dd6fb",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(cnn_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "NWYdSkn1PSVN",
    "outputId": "0ebc85cc-ae55-4be0-834a-82909cd955f3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 239us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.592603708124141, 0.9894999861717224]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(preprocessing_image_for_cnn(Xm_test), ym_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjfaQv5u0ytj"
   },
   "source": [
    "### Training and Evaluation on Fashion MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "0RqQWxHT2Zyu",
    "outputId": "e19dc046-d2fa-47bc-b7f3-e735c32a6a3d",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 26s 465us/step - loss: 0.8318 - accuracy: 0.7317 - val_loss: 0.4225 - val_accuracy: 0.8490\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 26s 465us/step - loss: 0.5435 - accuracy: 0.8221 - val_loss: 0.3562 - val_accuracy: 0.8714\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 26s 464us/step - loss: 0.4732 - accuracy: 0.8476 - val_loss: 0.3335 - val_accuracy: 0.8812\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 26s 465us/step - loss: 0.4265 - accuracy: 0.8600 - val_loss: 0.3332 - val_accuracy: 0.8822\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 26s 466us/step - loss: 0.3938 - accuracy: 0.8706 - val_loss: 0.2963 - val_accuracy: 0.8932\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 26s 465us/step - loss: 0.3695 - accuracy: 0.8777 - val_loss: 0.2929 - val_accuracy: 0.8954\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 26s 467us/step - loss: 0.3508 - accuracy: 0.8854 - val_loss: 0.2788 - val_accuracy: 0.8984\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 26s 467us/step - loss: 0.3334 - accuracy: 0.8900 - val_loss: 0.2764 - val_accuracy: 0.9012\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 26s 467us/step - loss: 0.3188 - accuracy: 0.8943 - val_loss: 0.2692 - val_accuracy: 0.9024\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 26s 466us/step - loss: 0.3050 - accuracy: 0.8986 - val_loss: 0.2663 - val_accuracy: 0.9096\n"
     ]
    }
   ],
   "source": [
    "cnn_fashion_history = cnn_model.fit(preprocessing_image_for_cnn(Xf_train), yf_train, epochs=10, \n",
    "                            validation_data=(preprocessing_image_for_cnn(Xf_valid), yf_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "voANpAD4P5Ot",
    "outputId": "dccd797a-f938-4420-e473-aaf4c5d0a155",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXxU9b3/8dd3tuw7EAgQCAKyI8iioAh1Aa8o1WoVrVWuy89bta1Updraa3cXumj1arF1qwviVnGvVCMVUUFAEQKIQCDsJCEhZJlk5vv7YyaTmSwQIGSyvJ+PxzzmzDnfc+abA+TN53s2Y61FREREoscR7Q6IiIh0dgpjERGRKFMYi4iIRJnCWEREJMoUxiIiIlGmMBYREYmyw4axMeZxY8weY8xXTSw3xpgHjTEbjTFfGmNGt3w3RUREOq7mVMZPAtMOsfxcYEDwdT3wyLF3S0REpPM4bBhbaxcDRYdoMgN42gZ8AqQaY3q0VAdFREQ6upY4ZtwT2Bb2uSA4T0RERJrB1QLbMI3Ma/Qem8aY6wkMZRMXF3dy7969W+DrA/x+Pw6HzkdrDdrXrUP7uXVoP7cO7WfYsGHDPmtt18aWtUQYFwDhqdoL2NFYQ2vtPGAewJgxY+zy5ctb4OsDcnNzmTx5cottT5qmfd06tJ9bh/Zz69B+BmNMflPLWuK/KQuB7wfPqj4FKLHW7myB7YqIiHQKh62MjTHPA5OBLsaYAuB/ATeAtfZR4C3gv4CNQDkw63h1VkREpCM6bBhba2ceZrkFbmyxHomIiHQynftouoiISBugMBYREYkyhbGIiEiUKYxFRESiTGEsIiISZQpjERGRKFMYi4iIRJnCWEREJMoUxiIiIlGmMBYREYkyhbGIiEiUKYxFRESiTGEsIiISZQpjERGRKFMYi4iIRJnCWEREJMoUxiIiIlGmMBYREYkyV7Q7ICIi0ibUeKH6IHjLobocfF7IHNoqX60wFhGR9sHaQEB6DwbC0lseGZ6h+QcjpxttWxY2HVzmr4n8vthU+Gl+q/xoCmMRkc7C2uDL3/SLQ7WpP9/WW6+pdSwp+7+CDd5jCM9ggFrfkf3MrjjwJIAnHty17/GQ3DPwHjE/IbJtTNLx+FNovJut9k0iItHg9wcqHn914N0XPl1NXPl22JMXbFMDfh/4qsM+h7181YHloXlhn0Pr+Oq2f0TbC1//ENvz1QQC6WiCMYpGAaxqYqE7vmEwehIgLq0uPD0Jhw/P+m3d8eBo+tQoay3U1GC9Xmx1NX6vF4LvtroarCX2eOyMRiiMRToLawO/2K2v7pe89QV/2debH7GspvntGgRNdb0wqg6GYWPT1ZHBEx5gDabrb7em6e84TAiNB/jsOOxv4wSnGxwucDjBUTvtAqerbtrhDi6vXeYGd1ygKgtfFr4t4whs3zgaeZngq5FlmHrt6q/X2Lbqr3cE3xdc1/otX3yxmuHDx2BxY40ba134rRNrndjq6sDLW42t9gbeg4FovV5sRe3n4LLqCqy3FFvtbRCgdevV20bte715WNvkH6EjOZkTP/v0OPzlaEhhLNJarA0Ms1Xsh8r9h3kvYeS+3bA5uenwPFRINtYuypVRBFM/YJoz3UhIOd11Ied0hU3XXz8Yho1sd+36rxkydHjDwGsyPOu9nOFhGh6YplV3qfX7Gw2bxub5vV5slffQAdjouo1UkN7qwwee308MsIG/t8jPatxujMcTeNVONzLPER8fnOeOaOdosG7j23HExrRIf5tDYSxyJKyFqgPNCNNG3itLGp4gEs44IDYlcNJIbAoOfzVgA7/sXbF1v/CNMzD0FpoOq5ZCQdIa7Zz1psMCKRRejQSlw3XIocPWtmd/LkOGTT7i9SLCr8KL9Vbgr6oKCzUvtqoK6/UGQysYgKGwCrxHrOMNrlMdto63OrSd2pe/ul4Ier3gO8JjqYfjDgSYw+0GjxuHu/HwcyTHNRJk7kDAeermb962jf6DBjUdou5660V8XzBA3e5Av1r5PzqtQWEsnY+1UFV65GEarFgPeQKJcQYCNS41EKpxqZDaJ/JzU++epIiQWpmby+TJk4///uhArNeLv7w88KqoCLwfrP0ceLe1y8sDy5O3bGb7m29FhF0gQBsJyVAYVkN1dct02uGoCyiPp65qC3/FxuBITgoGUr1ljQbhoarARqrK+svdbkwL/4dpTW4u6fr73CSFsUSqHUqtLA0EVui9JPBedYDs/K9h8XLqzrq09U4aaexEkmC7+m2a/EwT22jsM00sr53nC1Sz4RXqoYZsjTMyJOPSID3n8GEamxoYQu2A/2tvabampkFY2oryuiANC8u6cA0G6cF6YRsWvkcSkMbtxsTH4zGGiqQkTEwwDINh50xMwsTE1AVcKChj6oWlG0dM2Dy3p25b4e1q2wQrP0ftPJd+DYvCuGOxNnAJQGVJvTAtiQzVBkFbr81hji32A9jc1FJDg5NB6s+j9oSP+ieHNPa5OW2asc34DEg/oZkVaqIClcCZprayMhh6FYGwDE77K8qxFRVhn4PzagO0flCWH6xbVl4eGFZtLqcTR0ICjrg4HPHxoZczIx13717Bz/WWJ8TjiIvDhNon4IgPWx4XGFoFyNUIhLQBCuO2wlqorqgXmE0EZ22V2libw12DZxwQkwyxyRCTEhhSTe0NMUOD85Ij32NTgu2C82ISWfzRUiadcUbjwSmtyvp8+Csq64IyGIKRQXmI4Kxo6nMFtqLikGeaNmBMKOxMfFwwAONxpqTg7tGjLiwTgm1C4ZkQfI8MWxMXhyMhIVDB6u+WdHAK49bgq4aSbVC0GYq3QHHwff+24LBpMEwPdXIPBIM0qS4cY1MguRd0ayREY5KDJwLVm+dJOObQ9Ds94Gq9sww7Guv34y8rw1d6AP+BUnwlpfgOlOIvPYCvtDQwr/QAyd98Q8E/XztkcNqqqiP7cpcrEIrBlwlWic7EJBzdugUCMC4+GJxxTX+Ob7gNExOj0BQ5SgrjllJZEgjY+oFbtBlKCiIrVmcMpPWF1GzoMrCREA1WrPUDVsOnbYK1FltVha+kNjhLgyF6IGzeAXylJaGAjQzbA4euOI3BkZSEx+mkKi0tFHrO9DTccT2bHZSNBqfH03o7SkSaTWHcXH4/HNjRdOBWFEW2j8+AtBzoNRZGfDcQvmk5gROBEru3qUs7OiNbU4PvwAH8pWHB2VSYHogMVn9paeDayUMw8fE4k5JwJifhSE7B3S0T54ABOJKSg/OScSYl40xJDs1zJifjSE4ODM06HDqWKdKJKIzDVVcEQ3ZLw8Atzgdf2JCgcQaOtablwJAZgZCtDdy0voFKVo476/VSs38/vgavksjPYcHqLynBX15+6A27XDiTk3EmBYMzORl3VhbO5JRAmCYF5tWGbWBeEs6UFJyJiapAReSIdK4wthYO7ousaMOny3ZFtvckQXpf6DoIBk6LDNyUXoGbMUiLsNbiP3gwEJzFjYVrI6/i4kOGqomJwZmaGnilpODO7k1sMEQdyUmRwZqSXBemSUmYuDgd/xSRVtPxwrjGGzhZKiJwt9S9vGWR7ZOyAiHb/8y6YeTawI1P1zHao2BravCVlDQjTPfjK9kfrGxLDnmNqCM5GWdaMFi7ZBDT/4S6oG3i5YiLa8WfWkTk6HWMMP56ESNX/RJW7Q+eLBV2nWztyVLpOdD3tMjATe0D7tZ6Jkf75q+owLtlC978rcR98gl7165tcljYX1ra5HaM2x0RmJ6+OcTVD9K0ep+Tk3VjBBHp0DrGbzh/DU5fJfQdDyMurTtuq5Oljoi1lprdu/Fu2kTV5s14N23Gu3kzVVs2U7NjZ6hdMrAPcCQmRgZrdvYhK1VXWiomPl7DvyIi9XSMMD5xGit2xurM02aqrXKrNm3Cu3lLIHA3b8K7JR8bdgzWkZCAp18/4seMISYnB09OPzx9+/DZhg2cfu65oTsYiYjIsekYYSwNWGup2bUrELTBCjcQupup2VlX5WIM7p498eTkkDB2LJ6cHDx9c/D0y8HVtWujVax/1y4FsYhIC+owYVxUU3T4Rh2Qv7w8UOVu3hyocjdtomrL5qar3LFhVW5ODp4+2ThiddxcRCSaOkQYL1i/gN9v/z1jS8fSO7l3tLvT4hqvcjdRtXlL41Vuv7AqN6cfnpy+TVa5IiISfR0ijKf0nsJ9n97H3OVzeeBbD0S7O0ctosoNO3nKu3lL4Kb9QY7ERDw5OYEqt1+/wLByTg6evn1wxOie0SIi7U2HCOOu8V05J+UcXt/2Op/s/IRTepwS7S4dlq+0lNI336Rq4zeqckVEOrkOEcYAU5KnsKJmBfd+di8vnv8iLkfb/NH8Xi/Fzz7HvkcfxV9SEqpyE8ZFnjzl6aMqV0Sks2ibiXUU3MbNrWNu5ZbcW3h5w8tcOujSaHcpgvX7KX3zTfb+6c9U79hBwmmn0fWWHxM7ZIiqXBGRTq7DhDHAmdlnMrb7WB5a9RDTcqaREpMS7S4BcPDjj9k9dy5Va/OIGTKY7N/8moQJE6LdLRERaSOadWsqY8w0Y8x6Y8xGY8xPG1mebYz5wBiz0hjzpTHmv1q+q83qJ3PGzqHUW8qjXzwajS5EqFy3jq3XXsfW/74G//4Ssu6/j5yXXlIQi4hIhMNWxsYYJ/AwcDZQACwzxiy01q4Na/ZzYIG19hFjzBDgLaDvcejvYZ2YfiLfGfAd5q+bzyUnXkK/lH6t3ofqHTvY+8CDlCxciCM5mW5z5pB2xeU49Fg9ERFpRHMq43HARmvtJmutF5gPzKjXxhK4ZTFACrCj5bp45G4adRNxrjjuX3Z/q36vr6SE3fffzzfTzqX07bfJuOa/6f+vd8mYdbWCWEREmmSstYduYMzFwDRr7bXBz1cC4621N4W16QH8C0gDEoCzrLWfN7Kt64HrATIzM0+eP39+S/0clJWVkZiYGPr8fun7vFr8Kjd0u4GhcUNb7HsaVV1NfO6HJLz9Nqaigsrx4ym74Hz86enH93ujpP6+luND+7l1aD+3Du1nmDJlyufW2jGNLWvOCVyNnepbP8FnAk9aa/9gjDkV+IcxZpi14c8yBGvtPGAewJgxY2xLPtghNzc34kERE30TWblwJe9UvsP1U6/H7Wj5eylbv5/SN95gz5//TM2OnSScfjrdbv0JsSee2OLf1ZbU39dyfGg/tw7t59ah/XxozRmmLgDC7zHZi4bD0NcACwCstUuBWKBLS3TwaLmdbm4bextbSrcwf13LVeC1ypYsYfPFF7Pj9jm4UtPIfuJxsh+b1+GDWEREWl5zwngZMMAYk2OM8QCXAQvrtdkKnAlgjBlMIIz3tmRHj8bpPU9nYtZEHln1CEWVLfMgicq8PLZecy3brrkWf0kpWfffT9+XXiTh1FNbZPsiItL5HDaMrbU1wE3Au0AegbOm1xhjfmWMuSDY7CfAdcaYL4Dngavt4Q5GtwJjDLePvZ3ymnIeXvnwMW2revt2dsyZw+aLvkPlV1/R7adz6Pf2W6ScPx3jaNYVYiIiIo1q1k0/rLVvEbhcKXzeL8Km1wITW7ZrLaNfaj8uG3QZz697nu+e+F1OTD+yYWRfSQn7/jqP4meeASDj2mvIuO46nMnJh1lTRESkeTpFSfc/I/+HJE8S9y27j+YW7P6qKgr//jgbzz6HoieeIPm88zjh3Xfo9pOfKIhFRKRFdYowTolJ4caTbuSzXZ/x/tb3D9nW+v2UvPYa35x7Lnvuv5+4k0aS889Xyfr973D36NFKPRYRkc6kU4QxwCUDL6F/an/mLp+L1+dttE3ZR0vY/J2L2THnp4EzpJ98gux5OkNaRESOr04Txi6Hi9vH3k5BWQH/WPuPiGWVa9ey9b//m23XXou/tJSsuXMDZ0if0vafiywiIu1fh3pq0+GcmnUqk3tPZt6X85jRfwYpRVXseeABShe+jjMlhcw7fkrqzJm6daWIiLSqThXGALeNuY3L51/A4jn/zZAPtoDDQcZ115Fx3bU6MUtERKKiU4Wxv6qKhBff4/8etTjLv8Z/3hQG3HqXTswSEZGo6hRhbH0+Sl5/nb0PPEjNzp0knTaBnw1fh2tgGU917x7t7omISCfXoU/gstZS9p+P2Pydi9n50ztwpaeT/eQT5Pzt73zn3Nms3LOSd7a8E+1uiohIJ9dhw7hizZrAGdLXXYe/rCxwhvSLC0JnSH+7/7cZnD6YP37+RypqKqLcWxER6cw6XBh7C7az/bbb2fKdi6nKW0fmnXfQ7603SZl+XsQ9pJ0OJ3PGzWHXwV08uebJ6HVYREQ6vQ5zzNiUlbH7nnspfvbZwBnS118fOEM6KanJdU7OPJlz+pzD46sf58L+F9I9QcePRUSk9XWIyrj03X/R5a5fUPTUUySff37gHtKzbzlkENeaPWY2FsufPv9TK/RURESkoQ4Rxp7s3lT3P4Gcf/6TrN/9FvcRnCHdM7EnVw29irc2v8WqPauOYy9FREQa1yHCOHbwYPbfeCOxJw48qvWvGXYN3eK6ce9n9+K3/hbunYiIyKF1iDA+VvHueH588o/5qvArXv/m9Wh3R0REOhmFcdB5/c5jRJcRPLDiAcqry6PdHRER6UQUxkEO42DOuDnsrdjL31b/LdrdERGRTkRhHGZE1xFM7zedp9Y8RcGBgmh3R0REOgmFcT0/Hv1jnA4nf/z8j9HuioiIdBIK43oyEzK5Ztg1vJf/Hst2LYt2d0REpBNQGDfiqqFXkZWQxb2f3YvP74t2d0REpINTGDci1hXLLWNuYX3xel7d+Gq0uyMiIh2cwrgJU/tMZXS30fxl5V844D0Q7e6IiEgHpjBugjGGn477KcWVxfz1i79GuzsiItKBKYwPYXDGYC4ccCHPrnuWLSVbot0dERHpoBTGh3HzqJuJccYwd/ncaHdFREQ6KIXxYXSJ68L/G/H/+LDgQz7e/nG0uyMiIh2QwrgZrhh8Bb2TenPfsvuo8ddEuzsiItLBKIybweP0cOuYW/mm5BsWrF8Q7e6IiEgHozBupim9p3BKj1N4eNXD7K/cH+3uiIhIB6IwbiZjDLePvZ2y6jL+74v/i3Z3RESkA1EYH4EBaQO4ZOAlLFi/gI3FG6PdHRER6SAUxkfoppNuIsGdwH3L7sNaG+3uiIhIB6AwPkKpsan84KQfsHTnUj4s+DDa3RERkQ5AYXwUvnvid+mX0o+5y+dS7auOdndERKSdUxgfBbfDzW1jbyO/NJ/n1j0X7e6IiEg7pzA+Sqf1PI1JvSbx6BePUlhRGO3uiIhIO6YwPga3jrmVyppK/rLyL9HuioiItGMK42OQk5LDzMEzeeXrV1hXtC7a3RERkXZKYXyMbhh5A6kxqdzz2T261ElERI6KwvgYJXuSuWnUTXy++3Pey38v2t0REZF2SGHcAr4z4DsMTBvIHz//I1W+qmh3R0RE2hmFcQtwOpzMGTuH7WXbeXrN09HujoiItDMK4xYyrsc4zso+i8dWP8ae8j3R7o6IiLQjzQpjY8w0Y8x6Y8xGY8xPm2jzXWPMWmPMGmNMp7wTxuwxs6nx1/DAigei3RUREWlHDhvGxhgn8DBwLjAEmGmMGVKvzQDgDmCitXYo8OPj0Nc2r3dSb74/5Pss/GYhq/eujnZ3RESknWhOZTwO2Git3WSt9QLzgRn12lwHPGytLQaw1nbacdrrRlxHl7gu3LNMlzqJiEjzNCeMewLbwj4XBOeFGwgMNMYsMcZ8YoyZ1lIdbG8S3An8aPSP+HLvl7y5+c1od0dERNoBVzPamEbm1S/5XMAAYDLQC/iPMWaYtXZ/xIaMuR64HiAzM5Pc3Nwj7W+TysrKWnR7xyLZJpPtyebej+/FvcVNjCMm2l1qUW1pX3dk2s+tQ/u5dWg/H1pzwrgA6B32uRewo5E2n1hrq4HNxpj1BMJ5WXgja+08YB7AmDFj7OTJk4+y2w3l5ubSkts7Vml70vj+299nY/pGbjzpxmh3p0W1tX3dUWk/tw7t59ah/XxozRmmXgYMMMbkGGM8wGXAwnpt/glMATDGdCEwbL2pJTva3ozqNopzc87lia+eYEdZ/f+7iIiI1DlsGFtra4CbgHeBPGCBtXaNMeZXxpgLgs3eBQqNMWuBD4DbrLWd/rmCs0+ejcHwp8//FO2uiIhIG9as64yttW9Zawdaa0+w1v42OO8X1tqFwWlrrZ1trR1irR1urZ1/PDvdXnRP6M6sYbN4Z8s7rNi9ItrdERGRNkp34DrOZg2bRWZ8Jvd8dg9+6492d0REpA1SGB9nca44Zp88m7yiPF7b+Fq0uyMiIm2QwrgVnJtzLid1PYkHVjxAmbcs2t0REZE2RmHcCowxzBk3h8LKQh5b/Vi0uyMiIm2MwriVDOsyjBknzOAfa//BttJth19BREQ6DYVxK/rR6B/hdriZu3xutLsiIiJtiMK4FXWN78p1I67j/W3v8+nOT6PdHRERaSMUxq3syiFX0jOxJ/cuu5caf020uyMiIm2AwriVxThjuHXMrXxd/DUvb3g52t0REZE2QGEcBWdmn8nY7mN5aNVDLC5YrJuBiIh0cgrjKDDGcOe4O/E4Pdz47xuZ/up0nl7zNKXe0mh3TUREokBhHCX90/rzzkXvcP+k++ka15X7l9/PWS+exa+W/ooNxRui3T0REWlFzXmesRwnbqebaTnTmJYzjbzCPOavn8/Cbxby4oYXGdt9LDMHzWRK7ym4HPpjEhHpyFQZtxGDMwbzywm/ZNHFi5h98mx2lO1gdu5spr08jce+fIzCik7/REoRkQ5LYdzGpMamMmvYLN688E0enPIg/VL68eDKBzn7pbP52Uc/46t9X0W7iyIi0sI0/tlGOR1OpmRPYUr2FDaVbGL+uvm8tvE1Fn6zkBFdRnDZoMuY2ncqHqcn2l0VEZFjpMq4HeiX0o87x9/Jvy/5N3eMu4NSbyl3fnQnZ790Nn9Z+Rd2HdwV7S6KiMgxUBi3I4meRC4ffDmvffs1/nr2XxnRZQSPffkY016exk9yf8LyXcux1ka7myIicoQ0TN0OOYyDCVkTmJA1gYIDBSxYv4CXv36Zf+X/i4FpA5k5aCbn9TuPOFdctLsqIiLNoMq4neuV1IvZY2az6JJF/HLCLzEYfrn0l5z54pnMXTaXbQf0uEYRkbZOlXEHEeeK46IBF3Fh/wtZuWclz617jmfynuHptU8zqdckZg6ayalZp+Iw+v+XiEhbozDuYIwxjM4czejM0ew+uJsXN7zIixte5MNFH9I3uS+XDbqMGSfMINGTGO2uiohIkMqkDiwzIZObRt3Eexe/xz2n30NyTDL3fHYPZ754Jr/55Dds2r8p2l0UERFUGXcKHqeH8/qdx3n9zmPNvjU8t+45Xv36VV5Y/wLje4xn5qCZTO41GafDGe2uioh0SqqMO5mhXYby29N+y3uXvMePRv+I/NJ8fvzBj/mvV/6Lv6/+O/sr90e7iyIinY7CuJNKj03n2uHX8vZFb/OnyX+iV1Iv/rziz5z10lncteQu8grzot1FEZFOQ8PUnZzL4eKsPmdxVp+z+Lr4a+avm8/rm17nnxv/yUldT+LywZdzVvZZuJ3uaHdVRKTDUmUsIQPSBnDXqXex6JJF3D72dooqi7h98e2c8/I5PLLqEfaW7412F0VEOiRVxtJAsieZK4dcyRWDr2DJ9iU8v+55/u+L/2Pel/M4q89ZZB3MYrR3NMme5Gh3VUSkQ1AYS5McxsHpvU7n9F6ns7V0K/PXB54cVeot5an5TzGi6wgmZk3ktJ6nMThjsG4oIiJylBTG0izZydncPvZ2Zp88m6f/9TQHMw+yZPsSHlr1EA+teoj02HQmZE1gYs+JTMiaQHpserS7LCLSbiiM5Yi4HC76xfZj8qjJ3DzqZgorClm6cylLti/h4x0f88amNzAYhmQMYWLPQNU8vMtwXA79VRMRaYp+Q8oxyYjLYHq/6UzvNx2/9ZNXlMeS7UtYsn0Jf1/9d+Z9OY8kdxKnZJ3CaT1PY0LWBLondI92t0VE2hSFsbQYh3EwNGMoQzOGcv2I6yn1lvLpzk/5aPtHfLT9I97Lfw+A/qn9Oa3naUzsOZHR3UbjcXqi3HMRkehSGMtxk+xJ5uw+Z3N2n7Ox1rJx/0aWbF/CRzs+4tm8Z3lyzZPEueIY131cYEg76zR6J/eOdrdFRFqdwlhahTGGAWkDGJA2gKuHXU15dTnLdi0LVc0fFnwIQHZSduhY85jMMcS746PccxGR409hLFER747njN5ncEbvMwDYWrqVj7Z/xJIdS3j161d5ft3zuB1uTs48OTCknTWRE1JPwBgT5Z6LiLQ8hbG0CdnJ2VyefDmXD76cKl8VK3avCJwItmMJc5fPZS5z6Z7QPXRd8/ge40nyJEW72yIiLUJhLG1OjDOGU7NO5dSsU7mVW9l1cFegat6+hHe3vMvLX7+M0zgZ2XVk6ESwQemDdNMREWm3FMbS5nVP6M7FAy/m4oEXU+2v5su9XwZOBNv+EQ+ufJAHVz5Iemw6E7MmMrHnRE7NOlU3HRGRdkVhLO1K7XHkkzNP5oejf8i+in0s3bGUj7Z/xH+2/4fXN72OwTA0Y2joRLBhXYbppiMi0qZ1iN9Q1lqstdHuhkRBl7gunH/C+Zx/wvn4/D7yivJCQ9qPrX6Mv375V5I8SQzvMpzB6YMZkjGEwRmD6ZXYSyeDiUib0SHC+ONvCrl7aSXb4/KZcVIWSbF69m5n5HQ4GdZlGMO6DOOGkTdQUlXCJzs/YemOpawpXMNTa56ixtYAkORJYkj6kFA4D8kYQu+k3jruLCJR0SHC2Oe3+C38/J9f8bu38rhgZBYzx2UzoleKqp9OLCUmhal9pzK171QAqnxVbCzeyJrCNeQV5ZFXmMczec9Q7a8GINGdyKD0QaFwHpI+hD7JfXA6nNH8MUSkE+gQYTxpYFd+NSGW1BNO4vnPtvLaqh3MX7aNoVnJzByXrWpZgMBZ2kO7DGVol6GhedW+ar4p+Ya1hWtZW7iWvMI8FqxfQJWvCoA4VxyD0gcFKujgMHdOSo6OQYtIi2rWbxRjzDTgAcAJ/M1ae08T7S4GXgTGWmuXt1gvm8EYw6jsNEZlp/Hz6UN4beV2nv10q/9MQsoAACAASURBVKplOSS3082g9EEMSh/ERQMuAqDGX8Omkk3kFeYFArooj1e+foWKmgoAYp2xDEwfyOD0wQzNGMrgjMGckHoCbof+wyciR+ewYWyMcQIPA2cDBcAyY8xCa+3aeu2SgB8Cnx6Pjh6J5Fg3V57al++d0ocvCkp47tP8ULU8pEcyl49XtSxNczlcDEwbyMC0gczoPwMAn99Hfml+xBD3G5ve4IX1LwCBs7wHpg2MOAY9IHWAHoIhIs3SnMp4HLDRWrsJwBgzH5gBrK3X7tfAfcCtLdrDY2CM4aTeqZzUOzVQLa/awXPBavm3bwaq5cvHq1qWw3M6nPRL7Ue/1H6cf8L5APitn20HtoWGt9cWruWdLe/w4oYXgUCoD0gdEAjn9EBID0wbSKwrNpo/ioi0Qc0J457AtrDPBcD48AbGmFFAb2vtG8aYNhPG4ZJj3Vx5Sh++Nz6bLwpKeP7TrSz8YgcvLA9UyzPHZ/NtVctyBBzGQZ/kPvRJ7sO5OecCgcvsCsoKIoa439/6Pq98/QoAThMI9drjz0MyhnBi2ol6IIZIJ2cOd32uMeYSYKq19trg5yuBcdbam4OfHcD7wNXW2i3GmFzg1saOGRtjrgeuB8jMzDx5/vz5LfaDlJWVkZiYeETrlFdbPtlZwwfbath2wI/HCaf0cDG5t4ucZIeq5SYczb7uzKy1FPuK2ebdVveq2sYB/wEADIZMdya9Pb3p5elFtiebnp6e+Mp92s+tQH+fW4f2M0yZMuVza+2YxpY1J4xPBe621k4Nfr4DwFr7++DnFOAboCy4SnegCLjgUCdxjRkzxi5f3nLneOXm5jJ58uSjWtdaG1EtV1T7QtXyjJOySFa1HOFY9rUEWGvZW7E3Yoh7bdFa9pTvCbVJc6YxsNtA+iT1CVXg2cnZ9Ershdupv5MtRX+fW4f2Mxhjmgzj5gxTLwMGGGNygO3AZcDltQuttSVAl7Avy6WJyritijy2PJh/Bo8t3/XPr/hd8NjyzPHZjNSxZWkhxhi6xXejW3w3JveeHJq/r2IfeYV55BXl8cmGT6ioruCdLe9Q6i0NtXEaJ1mJWaGA7pPchz5JgaDukdBD10WLtEOHDWNrbY0x5ibgXQKXNj1urV1jjPkVsNxau/B4d7I1JYUdW/6yoITnP2t4bFnVshwvXeK6cHqv0zm91+kMLBoYqiT2V+4n/0A++aV1r62lW1mxewXlNeWh9d0ON72TekdU0n2T+5KdlE23+G76z6RIG9Ws64yttW8Bb9Wb94sm2k4+9m5FnzGGkb1TGdk7lZ+dNzh0JraqZYmG1NhUUmNTGdl1ZMR8ay37KvbVhfSBQEjnl+azZPsSvH5vqG2cK47spOyGQZ2cTVpMmv4ei0SRbiPUDEmxbr53Sh+uaKRaHhx23bKqZWltxhi6xnela3xXxnSPPBTlt352HdwVUU3nl+azvng97299P3Sfbgjcq7t2qLs2oGvfkzxJrf1jiXQ6CuMjUL9aXvhFZLV8/sgeXD6+j6plaRMcxkFWYhZZiVmcmnVqxLJqfzU7ynY0COpVe1bx9ua3sdSd2Jkemx6opJOy6ZvSN1RdZydnE+eKa+0fS6RDUhgfpaRYN1eM78Pl47JZvb2E54JnYi9YXhColsf1ZsaonqqWpU1yO9yh4er6qnxVbCvdFjpGvbV0K1tKt/Dxjo957ZvXItp2i+8WUUlnJWbRPb473RO6kxGXoadgiTSTwvgYGWMY0SuVEb3qVcuvreF3b63j/JE9mDkum5N6p6palnYhxhlD/7T+9E/r32DZweqDgWPSB/LJL8ln64FAUC/KX8T+qv0RbV0OF5nxmWTGZ9I9oXvdK75uOjVG/y5EQGHcomqr5SvG9+HLgv2hJ0ipWpaOIsGdwOCMwQzOGNxgWUlVCTvKdrC7fDe7Du4KvMoD71/s/YJ/5f+LGn9NxDoxzphQQGcmBEK7fngnuZMU2NLhKYyPk7pqeQivrdqualk6vJSYFFJiUhoNagicUFZUWVQX1PUC+9Odn7K3Yi9+649YL94V32hlXRve3eO763ai0u4pjI+zxBhXqFpeXVDCc5/lh6rlAd0SGZqVTHZGAn3S4+mTEU92RjxdE2MU0tLhOIyDLnFd6BLXhWFdhjXapsZfw76KfY2G9a6Du1hftJ7CysIG6yV7khsdBg+vuvUELWnLFMataHivFH7fawQ/O28IC1ft4K3VO1m2pZiFX+zAH3ZX0niPk+z0eLJDAV0X1j1T43A5dVKMdEwuhysUok3x+rwRQ+ERw+LBIfGSqpIG66XHpjca1jsqd9D/QH+6xnclxhlzPH88kSYpjKMgMcbF5eOzuXx8NgDeGj8FxeXkF5WztbCc/MJythYdZPO+g3y4YS9VNXXDdk6HoWdqHH0yAuHcJz2B7OB0dno88R79kUrH5nF66J3Um95JvZtsU15d3uDY9e6Du0PXXX+661MOVh8Mtf/zK38GIDUmNXSb0sz4TLrFd6NrfNfQdLf4brpBihwX+s3dBnhcDvp1TaRf14ZPNPH7LXsOVLGl8GAgqIsOBsO6nNe/2ElJRXVE+65JMfRJDwx390lPCA1990mPJz3Bo18i0inEu+PJSckhJyWnyTZl3jJ2HdzFe5+8R/f+3dldvpu95XvZU76H3eW7ySvMo6iyKOKaawhcFtYtvhtd47o2CO7a6a7xXfXcajkiCuM2zuEwdE+JpXtKLKf0y2iwvKS8OiKg8wsD00u/KeSVFdsj2ibGuMKGvsPCOj2erNQ4nA4FtXQeiZ5E+nv6UxBXwOQBkxttU+2vZl/5PvZU7GFP+Z5QUNdObyjewH+2/4eKmooG6yZ7khsEdf1Xemy6rsUWQGHc7qXEuxkRHzhzu77Kal9g+Ds09B0I6/W7D/DvvD14fXXD326noVda2HHq9Hj6ZCTQNyOe3unxxLr1JCDpfNwONz0Se9AjsUeTbay1lFWXhYI6vLoOD+3CysIGZ4q7HC66xnVtMBQeqrCD1bfOFu/4FMYdWKzbSf9uSfTv1vDewj6/ZVdpJfnB4e8twePU+YXlrMgv5kBV5PWg3ZNjyc6Ip1daHIV7qni36EsgUEnXjnzX1tV1n5ta3rACP/w6keuGttCM9RzG0L9bIqOz0+iVFqehemlRxhiSPEkkeZI4IfWEJtvV+GsorChsUGHvrdjL7vLdbNy/kY93fBxxLLtWkjspIqi7xnclPTadjNgM0uOC77HppMak6hGa7ZTCuJOqPRGsZ2ocE+r9/rDWUlxeHQjqovDK+iCffFNIeaWPtSV7gm1Da4WtHznHBmfY+svrzQ//cNh1g3OsbbBq2DYCEz6/DZ2t3jUphtHZqYzOTmN0nzSG90xR1S+twuVwkZmQSWZC5iHbHaw+2GSFvad8D9/s/IaiiqKIB33UchgHqTGpZMRl1IV1bDoZcRkR07XvOnu87VAYSwPGGNITPKQneBiVndZgeW5ubug5u+1Bjc/Pul0HWLm1mBVb97NiazHvrtkNBIbnh/RIZlQwnEdnp9IzVdWzRE+CO4F+Kf3ol9KvyTZ+6+eA9wCFFYUUVgZeRRVFgffKotD06n2rKawojHjmdf3vaiyk6wd5emw6yZ5k/bs4jhTG0uG5nA6G9UxhWM8Urgw+vGhfWRUrg8G8Ir+YF5Zt48mPtwDQLSkmWDkHKuhhqp6ljXEYR+iOZ/1oOrRrVdRURIR0UWURhRWR7/ml+azcs5LiyuIGZ5BDoLKvPzTeVJCnxabhdui2v0dCYSydUpfEGM4eksnZQwJDhrXVc204r9i6n3fW7AKC1XNWSsTwdlZKrKoEaTfiXHH0TOxJz8Seh21b469hf9X+urCuV3XXzv9m/zcUVhRS7a9udDspMSkRYV1RVEHeF3mkx6STHpdOWkwa6bHpgao7JrnTn1WuMBYhsnr+/ql9Adh7oCpiaPv5z7byxJItAGQmB6vnYAU9NEvVs3QMLocrdNvSw6k9kzw8pGunw8N7fdF6dh/czeJVixvdjtM4SYlJCYVzbXWdFptGRmxGYDomjfS4dNJjOmZ4K4xFmtA1KYZzhnbnnKGBWzNW+/ys2xmsnoOvt78KVM8ep4OhPZMjArpHSlw0uy9y3IWfSd7Ys7HD5ebmMvH0iRRXFVNcWRwK7sam84oCN1w54D3Q6LacxklqTCppsWkR4V1/Oi02rd2Et8JYpJncTgfDe6UwvFcKV03oC8CeA5WhY88r8/fzzCf5/P2jzQD0SIlldHYao7JTGd0njaFZycS4VD1L5+V2ukOXZzVHta86FN6FlYUUVzYe5EcS3qFKOyy861fiSZ6kVg9vhbHIMeiWFMvUod2ZGlY95+0sDR13XrG1mDdX7wQC1fOw2uq5T6CC7p6iWyaKNOVow7t+WNcP8LyiPIoqijhQfejw7pHQg+enP9+SP1KTFMYiLcjtdISeZX31xMC8PaWVrNi6P3j8uZh/fJLP34LVc1ZKLKOCwTw6O3Ds2eNq28NpIm1VS4e3z/qOc4/rKIxFjrNuybFMG9adacMC1bO3Jlg9154cll/Mm18Gq2eXg+E9UxjVO5XSPV42OjfhdjpwOQ1uR+Dd5XTgdpi6+U4HLkdwvtPgcgTeD7dcZ4NLZ3ek4X08KYxFWpnH5WBk71RG9k5lVrB63l1aWXfmdn4xT3+Sj7fGDxvyjls/AgHdMORrQ7s2zGvD2+WoC3d3E+2TYl1kJMSQkeihS2LgPT3BQ3q8R8/hFjkEhbFIG5CZHMu0YT2YNizwQAKf37Log1xOnXgaNT5Ljc9Ptd9SXeOnxu+n2mep8Vmq/f6ml4e1q52u9vkDbYPzanw2om1ouT+wzcB31E1XVPvC1vNT47eh6Wqfn9LKGnz+hjeMMAZS49xkJMaQkeAhI9ETCu2MxBi6BO/4lpEYQ5dED8mxbhx6iph0IgpjkTbI6TDEOA3Jse3rLkZ+v6W0spp9ZV4Ky6ooPOgNvMqqKCzzUniwin1lXtbvOkDRwUKKyxu/YYTLUXdL1toKOxTewdDOSPTQJTgv3uPUsLu0awpjEWkxDochNd5DaryH/t0SD9u+2uenuNwbCOpgWIe/7wtOb9tWTmGZl7Kqhg9HAIhxOcJC29NoBd4lMSYU8LpBi7Q1CmMRiRq300G3pFi6JTXvEq/Kal9dpX2wNsQD0/vK6gJ8/a4D7DvoDRx3b0RSjCs0RF5ZVsGTmz/D5TA4HYFj4w6HCfsceHdGfA6cFNdUu/A2DdcNHKt3mMB3RX6uW+5yhLVxhm3fGDwuB3Fup4byOxCFsYi0G7FuZ+jRn4djraWsqqZexR0I731h0/troOiglxqfxW8tNX6Lzx84ju7zWXy29rMNfa5t09jx8dYU63YQ73ER53aSEOMkzuMi3u0k3uMkzhN4j/e4AtPu2nmuesudxLldddPBNk4FfatSGItIh2SMISnWTVKsm75dEppsF3gk6GlH9R02GNT1A7vGHxbswRPkatvV+Ora+iM++0MBH9pWbbvQ58CJdl6fn3KvjwpvTfDdR7nXR3l1YN6u0uq6ed4aKqp9VPuO7D8OHpcjENBuJ/ExwQB31wv42vB2NxLwnsh1Civ87CmtxOUMjAa4nXUjEQp+hbGIyFEzJjikHO2ONEN1KMADAV0eHtb1wjwi4L0+Kqrr2u8r81LuLQ8srw7Ma+pwQAMf/rvR2cYEL7WrHdp31k3XDtm7nI6wYfzgsuBypyNwmZ0zeP29s/4ypwmb56j7rvD54cuC77FuR+gKh+OtPfwdEhGRY+R2OkiJc5AS1/Jn6Nf4/FRU1wX4wfCAD4b5l1/lccKAgfj8gUvhaqv+wMhA4HK6hsv8YW3qLserCZuurPZT4/fhC18WXC+wPRuxzOcPXBJomzFQkBLnVhiLiEj74HI6SHI6SDrEpXhpJRuZfMqhn+zUmvzBUA7/T0FtwIcfRmgtCmMREel0HA5DjKPtXOLWpsK4urqagoICKisrj3jdlJQU8vKO360DO6PY2Fh69eqF292+bjwhItLetKkwLigoICkpib59+x7x3XQOHDhAUlLScepZ52OtpbCwkIKCAnJycqLdHRGRDq1N3bm9srKSjIwM3dauDTDGkJGRcVSjFCIicmTaVBgDCuI2RH8WIiKto82FsYiISGejMD4GiYlN3wh/y5YtDBs2rBV7IyIi7ZXCWEREJMra1NnU4X75+hrW7ihtdnufz4fTeehrxoZkJfO/5w9tcvmcOXPo06cPP/jBDwC4++67McawePFiiouLqa6u5je/+Q0zZsxodr8gcGLa//zP/7B8+XJcLhd//OMfmTJlCmvWrGHWrFl4vV78fj8vv/wyWVlZfPe736WgoACfz8ddd93FpZdeekTfJyIi7UubDeNouOyyy/jxj38cCuMFCxbwzjvvcMstt5CcnMy+ffs45ZRTuOCCC47o5KaHH34YgNWrV7Nu3TrOOeccNmzYwKOPPsqPfvQjrrjiCrxeLz6fj7feeousrCzefPNNAEpKSlr+BxURkTalzYbxoSrYxrTEdcajRo1iz5497Nixg71795KWlkaPHj245ZZbWLx4MQ6Hg+3bt7N79266d+/e7O1+9NFH3HzzzQAMGjSIPn36sGHDBk499VR++9vfUlBQwEUXXcSAAQMYPnw4t956K3PmzGH69Omcfvrpx/QziYhI26djxvVcfPHFvPTSS7zwwgtcdtllPPvss+zdu5fPP/+cVatWkZmZecTX3tom7m96+eWXs3DhQuLi4pg6dSrvv/8+AwcO5PPPP2f48OHccccd/OpXv2qJH0tERNqwNlsZR8tll13Gddddx759+/jwww9ZsGAB3bp1w+1288EHH5Cfn3/E25w0aRLPPvss3/rWt9iwYQNbt27lxBNPZNOmTfTr148f/vCHbNq0iS+//JJBgwaRnp7O9773PRITE3nyySdb/ocUEZE2pVlhbIyZBjwAOIG/WWvvqbd8NnAtUAPsBf7bWnvkqdUGDB06lAMHDtCzZ0969OjBFVdcwfnnn8+YMWM46aSTGDRo0BFv8wc/+AE33HADw4cPx+Vy8eSTTxITE8MLL7zAM888g9vtpnv37vziF79g2bJl3HbbbTgcDtxuN4888shx+ClFRKQtOWwYG2OcwMPA2UABsMwYs9Bauzas2UpgjLW23BjzP8B9QLs9BXj16tWh6S5durB06dJG25WVlTW5jb59+/LVV18BgQcuNFbh3nHHHdxxxx0R86ZOncrUqVOPotciItJeNeeY8Thgo7V2k7XWC8wHIq7tsdZ+YK0tD378BOjVst0UERHpuJozTN0T2Bb2uQAYf4j21wBvN7bAGHM9cD1AZmYmubm5EctTUlI4cOBAM7rUkM/nO+p1j8WaNWu4/vrrI+Z5PB4++OCDVu/L8VBZWdngz6msrKzBPGl52s+tQ/u5dWg/H1pzwrixC2obPT3YGPM9YAxwRmPLrbXzgHkAY8aMsZMnT45YnpeXd9SXJ0XrEYqnnHIKX375Zat/b2uJjY1l1KhREfNyc3Op/2cnLU/7uXVoP7cO7edDa04YFwC9wz73AnbUb2SMOQv4GXCGtbaqZbonIiLS8TXnmPEyYIAxJscY4wEuAxaGNzDGjAL+Clxgrd3T8t0UERHpuA4bxtbaGuAm4F0gD1hgrV1jjPmVMeaCYLP7gUTgRWPMKmPMwiY2JyIiIvU06zpja+1bwFv15v0ibPqsFu6XiIhIp6HbYR6DQz3PWEREpLkUxh1ATU1NtLsgIiLHoO3em/rtn8Ku1YdvFxTnqwHnYX6c7sPh3HuaXNySzzMuKytjxowZja739NNPM3fuXIwxjBgxgn/84x/s3r2bG264gU2bNgHwyCOPkJWVxfTp00N38po7dy5lZWXcfffdTJ48mQkTJrBkyRIuuOACBg4cyG9+8xu8Xi8ZGRk8++yzZGZmUlZWxs0338zy5csxxvC///u/7N+/n6+++oo//elPADz22GPk5eXxxz/+8bA/l4iItLy2G8ZR0JLPM46NjeXVV19tsN7atWv57W9/y5IlS+jSpQtFRUUA/PCHP+SMM87g1VdfxefzUVZWRnFx8SG/Y//+/Xz44YcAFBcX88knn2CM4W9/+xv33Xcff/jDH/j1r39NSkpK6BafxcXFeDweRowYwX333Yfb7eaJJ57gr3/967HuPhEROUptN4wPUcE2pqKNPc/YWsudd97ZYL3333+fiy++mC5dugCQnp4OwPvvv8/TTz8NgNPpJCUl5bBhfOmldbf/Ligo4NJLL2Xnzp14vV5ycnIAWLRoEfPnzw+1S0tLA+Bb3/oWb7zxBoMHD6a6uprhw4cf4d4SEZGW0nbDOEpqn2e8a9euBs8zdrvd9O3bt1nPM25qPWvtYavqWi6XC7/fH/pc/3sTEhJC0zfffDOzZ8/mggsuIDc3l7vvvhugye+79tpr+d3vfsegQYOYNWtWs/ojIiLHh07gqueyyy5j/vz5vPTSS1x88cWUlJQc1fOMm1rvzDPPZMGCBRQWFgKEhqnPPPPM0OMSfT4fpaWlZGZmsmfPHgoLC6mqquKNN9445Pf17NkTgKeeeio0/5xzzuGhhx4Kfa6ttsePH8+2bdt47rnnmDlzZnN3j4iIHAcK43oae57x8uXLGTNmDM8++2yzn2fc1HpDhw7lZz/7GWeccQYjR45k9uzZADzwwAN88MEHDB8+nJNPPpk1a9bgdrv5xS9+wfjx45k+ffohv/vuu+/mkksu4fTTTw8NgQP8/Oc/p7i4mGHDhjFy5MiIB1h897vfZeLEiaGhaxERiQ5jbaPPfDjuxowZY5cvXx4xLy8vj8GDBx/V9qL1oIj2bPr06dxyyy2ceeaZTbZp7M9EN3xvHdrPrUP7uXVoP4Mx5nNr7ZjGlqky7oT279/PwIEDiYuLO2QQi4hI69AJXMdo9erVXHnllRHzYmJi+PTTT6PUo8NLTU1lw4YN0e6GiIgEKYyP0fDhw1m1alW0uyEiIu2YhqlFRESiTGEsIiISZQpjERGRKFMY16PHIoqISGtTGIuIiESZwrgJ1lpuu+02hg0bxvDhw3nhhRcA2LlzJ5MmTeKkk05i2LBh/Oc//8Hn83H11VeH2tY+mlBERKQ52uylTfd+di/ritY1u73P58PpdB6yzaD0QcwZN6dZ23vllVdYtWoVX3zxBfv27WPs2LFMmjSJ5557jqlTp/Kzn/0Mn89HeXk5q1atYvv27aHnDu/fv7/Z/RYREVFl3ISPPvqImTNn4nQ6yczM5IwzzmDZsmWMHTuWJ554grvvvpvVq1eTlJREv3792LRpEzfffDPvvPMOycnJ0e6+iIi0I222Mm5uBVurpe9N3dQ9uydNmsTixYt58803ufLKK7ntttv4/ve/zxdffMG7777Lww8/zIIFC3j88cdbrC8iItKxqTJuwqRJk3jhhRfw+Xzs3buXxYsXM27cOPLz8+nWrRvXXXcd11xzDStWrGDfvn34/X6+853v8Otf/5oVK1ZEu/siItKOtNnKONouvPBCli5dysiRIzHGcN9999G9e3eeeuop7r//ftxuN4mJiTz99NNs376dWbNm4ff7Afj9738f5d6LiEh7ojCup6ysDABjDPfffz/3339/xPKrrrqKq666qsF6qoZFRORoaZhaREQkyhTGIiIiUaYwFhERiTKFsYiISJQpjEVERKJMYSwiIhJlCmMREZEoUxhHSU1NTbS7ICIibYTCuBHf/va3Ofnkkxk6dCjz5s0D4J133mH06NGMHDmSM888EwjcIGTWrFkMHz6cESNG8PLLLwOQmJgY2tZLL73E1VdfDcDVV1/N7NmzmTJlCnPmzOGzzz5jwoQJjBo1igkTJrB+/Xog8ASqW2+9NbTdv/zlL/z73//mwgsvDG33vffe46KLLmqN3SEiIsdZm70D167f/Y6qvOY/QrHG56PoMI9QjBk8iO533nnYbT3++OOkp6dTUVHB2LFjmTFjBtdddx2LFy8mJyeHoqIiAH7961+TkpLC6tWrASguLj7stjds2MCiRYtwOp2UlpayePFiXC4XixYt4s477+Tll19m3rx5bN68mZUrV+JyuSgqKiItLY0bb7yRvXv30rVrV5544glmzZrVjD0jIiJtXZsN42h68MEHefXVVwHYtm0b8+bNY9KkSeTk5ACQnp4OwKJFi5g/f35ovbS0tMNu+5JLLgk9d7mkpISrrrqKr7/+GmMM1dXVoe3ecMMNuFyuiO+78soreeaZZ5g1axZLly7l6aefbqGfWEREoqnNhnFzKthwLfUIxdzcXBYtWsTSpUuJj49n8uTJjBw5MjSEHM5aizGmwfzweZWVlRHLEhISQtN33XUXU6ZM4dVXX2XLli1Mnjz5kNudNWsW559/PrGxsVxyySWhsBYRkfZNx4zrKSkpIS0tjfj4eNatW8cnn3xCVVUVH374IZs3bwYIDVOfc845PPTQQ6F1a4epMzMzycvLw+/3hyrspr6rZ8+eADz55JOh+eeccw6PPvpo6CSv2u/LysoiKyuL3/zmN6Hj0CIi0v4pjOuZNm0aNTU1jBgxgrvuuotTTjmFrl27Mm/ePC666CJGjhzJpZdeCsDPf/5ziouLGTZsGCNHjuSDDz4A4J577mH69Ol861vfokePHk1+1+23384dd9zBxIkT8fl8ofnXXnst2dnZjBgxgpEjR/Lcc8+Fll1xxRX07t2bIUOGHKc9ICIirc1Ya6PyxWPGjLHLly+PmJeXl8fgwYOPanstNUzd1t10002MGjWKa665plW+r7E/k9zc3NCQuhw/2s+tQ/u5dWg/gzHmc2vtmMaW6aBjO3LyySeTkJDAH/7wh2h3RUREWpDCuB35/PPPo90FERE5DnTMWEREJMraXBhH6xi2NKQ/CxGR1tGmwjg2NpbCwkKFQBtgraWwsJDY2Nhod0VEpMNrU8eMe/XqRUFBAXv3efrBWgAABDRJREFU7j3idSsrKxUcLSw2NpZevXpFuxsiIh1es8LYGDMNeABwAn+z1t5Tb3kM8DRwMlAIXGqt3XKknXG73aFbTh6p3NxcRo0adVTrioiIRNNhh6mNMU7gYeBcYAgw0xhT/44T1wDF1tr+wJ+Ae1u6oyIiIh1Vc44ZjwM2Wms3WWu9wHxgRr02M4CngtMvAWeaxm6uLCIiIg00J4x7AtvCPhcE5zXaxlpbA5QAGS3RQRERkY6uOceMG6tw65/u3Jw2GGOuB64PfiwzxjR8FNLR6wLsa8HtSdO0r1uH9nPr0H5uHdrP0KepBc0J4wKgd9jnXsCOJtoUGGNcQApQVH9D1tp5wLxmfOcRM8Ysb+qen9KytK9bh/Zz69B+bh3az4fWnGHqZcAAY0yOMcYDXAYsrNdmIXBVcPpi4H2ri4VFRESa5bCVsbW2xhhzE/AugUubHrfWrjHG/ApYbq1dCPwd+IcxZiOBiviy49lpERGRjqRZ1xlba98C3qo37xdh05XAJS3btSN2XIa/pVHa161D+7l1aD+3Du3nQ4ja84xFREQkoE3dm1pERKQz6hBhbIyZZoxZb4zZaIz5abT70xEZY3obYz4wxuQZY9YYY34U7T51ZMYYpzFmpTHmjWj3paMyxqQaY14yxqwL/r0+Ndp96qiMMbcEf298ZYx53hijBwnU0+7DuJm365RjVwP8xFo7GDgFuFH7+bj6EZAX7U50cA8A71hrBwEj0f4+LowxPYEfAmOstcMInAisk3zrafdhTPNu1ynHyFq701q7Ijh9gMAvrvp3YpMWYIzpBZwH/C3afemojDHJwCQCV4JgrfVaa/dHt1cdmguIC96HIp6G96ro9DpCGDfndp3SgowxfYFRwKfR7UmH9WfgdsAf7Y50YP2AvcATwcMBfzPGJES7Ux2RtXY7MBfYCuwESqy1/4pur9qejhDGzboVp7QMY0wi8DLwY2ttabT709EYY6YDe6y1n0e7Lx2cCxgNPGKtHQUcBHS+yXFgjEkjMFqZA2QBCcaY70W3V21PRwjj5tyuU1qAMcZNIIiftda+Eu3+dFATgQuMMVsIHHL5ljHmmeh2qUMqAAqstf+/vTs2iSCKojD839QaDMxsQTRc2zCwAAvQIuzA0GyxBHMTFQTNFDQRLMHgGOwzWoQFF+7u8H/hi24wzJn3mDnze7ozZxHOWr9j4C3JV5Jv4AY4bJ5p40whjFep69Q/jV9iXgEvSS6755mqJOdJdpPssbiWb5O4i1izJJ/AR1Xtj6UZ8Nw40pS9AwdVtTPuIzN8WW7JSg1cm+yvus7msaboCDgBnqrqcaxdjHY2aRudAdfjIf4VOG2eZ5KS3FXVHLhn8VXGA7ZxLbGBS5KkZlM4ppYkaasZxpIkNTOMJUlqZhhLktTMMJYkqZlhLElSM8NYkqRmhrEkSc1+AJPSu3K2RwOQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(cnn_fashion_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HeU-U-oxQBhK",
    "outputId": "c71a7bf8-32f1-4920-b43b-74892bbffe60",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 188us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[35.19765847899066, 0.8973000049591064]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(preprocessing_image_for_cnn(Xf_test), yf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rV4QKqQXnMAq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_cnn_1(k_initializer='random_uniform', b_initializer='random_uniform', activation='relu',\n",
    "                optimizer=\"sgd\",loss=\"sparse_categorical_crossentropy\", padding=\"same\",\n",
    "                k_regularizer=None, b_regularizer=None):\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(64, 7, activation=activation, padding=padding, input_shape=[28, 28, 1],\n",
    "                            kernel_initializer=k_initializer, bias_initializer=b_initializer),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(128, 3, activation=activation, padding=padding,\n",
    "                            kernel_initializer=k_initializer, bias_initializer=b_initializer),\n",
    "        keras.layers.Conv2D(128, 3, activation=activation, padding=padding,\n",
    "                            kernel_initializer=k_initializer, bias_initializer=b_initializer),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(256, 3, activation=activation, padding=padding, \n",
    "                            kernel_initializer=k_initializer, bias_initializer=b_initializer),\n",
    "        keras.layers.Conv2D(256, 3, activation=activation, padding=padding, \n",
    "                            kernel_initializer=k_initializer, bias_initializer=b_initializer),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation=activation, kernel_initializer=k_initializer, bias_initializer=b_initializer),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(64, activation=activation, kernel_initializer=k_initializer, bias_initializer=b_initializer),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=k_initializer, bias_initializer=b_initializer)\n",
    "                  ])\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(param_distribs):\n",
    "    keras_clas = keras.wrappers.scikit_learn.KerasClassifier(build_cnn_1)\n",
    "    grid_search_cv = GridSearchCV(keras_clas, param_distribs, cv=3, error_score=np.nan)\n",
    "    grid_search_cv.fit(preprocessing_image_for_cnn(Xf_train), yf_train, epochs=5,\n",
    "                       validation_data=(preprocessing_image_for_cnn(Xf_valid), yf_valid),\n",
    "                       callbacks=[keras.callbacks.EarlyStopping(patience=3)])\n",
    "    return grid_search_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. Initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 26s 713us/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 453us/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3028 - val_accuracy: 0.0980\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 454us/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3029 - val_accuracy: 0.0980\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 453us/step - loss: 2.3026 - accuracy: 0.1007 - val_loss: 2.3028 - val_accuracy: 0.0980\n",
      "18334/18334 [==============================] - 3s 172us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 488us/step - loss: 2.3027 - accuracy: 0.0971 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 452us/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 453us/step - loss: 2.3027 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 456us/step - loss: 2.3027 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "18333/18333 [==============================] - 3s 172us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 466us/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3029 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.3026 - accuracy: 0.1013 - val_loss: 2.3031 - val_accuracy: 0.0914\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 455us/step - loss: 2.3026 - accuracy: 0.0990 - val_loss: 2.3030 - val_accuracy: 0.0986\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3030 - val_accuracy: 0.0986\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 465us/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 454us/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3028 - val_accuracy: 0.0914\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3028 - val_accuracy: 0.0914\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 456us/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3028 - val_accuracy: 0.0980\n",
      "18334/18334 [==============================] - 3s 153us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 469us/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 455us/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "18333/18333 [==============================] - 3s 153us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 2.3027 - accuracy: 0.0980 - val_loss: 2.3028 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 454us/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3028 - val_accuracy: 0.0986\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 2.3026 - accuracy: 0.1010 - val_loss: 2.3030 - val_accuracy: 0.0914\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3030 - val_accuracy: 0.0986\n",
      "18333/18333 [==============================] - 3s 152us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 465us/step - loss: 1.2378 - accuracy: 0.5254 - val_loss: 0.6790 - val_accuracy: 0.7296\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 458us/step - loss: 0.7577 - accuracy: 0.7157 - val_loss: 0.5439 - val_accuracy: 0.8070\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 461us/step - loss: 0.6456 - accuracy: 0.7621 - val_loss: 0.4688 - val_accuracy: 0.8240\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 0.5841 - accuracy: 0.7874 - val_loss: 0.4438 - val_accuracy: 0.8346\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 0.5405 - accuracy: 0.8079 - val_loss: 0.4016 - val_accuracy: 0.8556\n",
      "18334/18334 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 480us/step - loss: 1.2572 - accuracy: 0.5138 - val_loss: 0.7093 - val_accuracy: 0.7196\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 18s 480us/step - loss: 0.7945 - accuracy: 0.6992 - val_loss: 0.5583 - val_accuracy: 0.7788\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 475us/step - loss: 0.6760 - accuracy: 0.7463 - val_loss: 0.4956 - val_accuracy: 0.8054\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 18s 480us/step - loss: 0.6135 - accuracy: 0.7713 - val_loss: 0.4435 - val_accuracy: 0.8242\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 18s 483us/step - loss: 0.5643 - accuracy: 0.7922 - val_loss: 0.4362 - val_accuracy: 0.8404\n",
      "18333/18333 [==============================] - 3s 147us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 487us/step - loss: 1.2482 - accuracy: 0.5166 - val_loss: 0.7298 - val_accuracy: 0.7392\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.7772 - accuracy: 0.7059 - val_loss: 0.5563 - val_accuracy: 0.7888\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.6681 - accuracy: 0.7539 - val_loss: 0.4802 - val_accuracy: 0.8234\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.6023 - accuracy: 0.7811 - val_loss: 0.4418 - val_accuracy: 0.8348\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.5542 - accuracy: 0.8050 - val_loss: 0.4088 - val_accuracy: 0.8510\n",
      "18333/18333 [==============================] - 3s 153us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 466us/step - loss: 2.3080 - accuracy: 0.1009 - val_loss: 2.3050 - val_accuracy: 0.1002\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 2.3043 - accuracy: 0.0974 - val_loss: 2.3027 - val_accuracy: 0.1112\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 455us/step - loss: 2.3029 - accuracy: 0.1014 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 2.3028 - accuracy: 0.1011 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 2.3027 - accuracy: 0.1021 - val_loss: 2.3027 - val_accuracy: 0.0914\n",
      "18334/18334 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 470us/step - loss: 2.3080 - accuracy: 0.0985 - val_loss: 2.3041 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.3044 - accuracy: 0.0991 - val_loss: 2.3034 - val_accuracy: 0.1012\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.3030 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0986\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 454us/step - loss: 2.3027 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 468us/step - loss: 2.3076 - accuracy: 0.0984 - val_loss: 2.3059 - val_accuracy: 0.0914\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 455us/step - loss: 2.3041 - accuracy: 0.0994 - val_loss: 2.3029 - val_accuracy: 0.0980\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 2.3028 - accuracy: 0.1000 - val_loss: 2.3031 - val_accuracy: 0.0986\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3028 - val_accuracy: 0.0986\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3029 - val_accuracy: 0.0980\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 469us/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3029 - val_accuracy: 0.0980\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 2.3027 - accuracy: 0.1018 - val_loss: 2.3029 - val_accuracy: 0.0914\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3028 - val_accuracy: 0.0980\n",
      "18334/18334 [==============================] - 3s 157us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 463us/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 455us/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 475us/step - loss: 2.3026 - accuracy: 0.0979 - val_loss: 2.3030 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3030 - val_accuracy: 0.0986\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 2.3026 - accuracy: 0.1007 - val_loss: 2.3030 - val_accuracy: 0.0986\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 456us/step - loss: 2.3026 - accuracy: 0.1003 - val_loss: 2.3030 - val_accuracy: 0.0986\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3029 - val_accuracy: 0.0986\n",
      "18333/18333 [==============================] - 3s 153us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 464us/step - loss: 1.5252 - accuracy: 0.4005 - val_loss: 0.7814 - val_accuracy: 0.6892\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 0.9082 - accuracy: 0.6521 - val_loss: 0.6633 - val_accuracy: 0.7320\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 458us/step - loss: 0.7624 - accuracy: 0.7144 - val_loss: 0.5557 - val_accuracy: 0.7818\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 467us/step - loss: 0.6728 - accuracy: 0.7475 - val_loss: 0.5124 - val_accuracy: 0.7940\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 18s 482us/step - loss: 0.6225 - accuracy: 0.7670 - val_loss: 0.4560 - val_accuracy: 0.8298\n",
      "18334/18334 [==============================] - 3s 146us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 483us/step - loss: 1.9096 - accuracy: 0.2590 - val_loss: 0.8386 - val_accuracy: 0.6826\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 473us/step - loss: 0.9496 - accuracy: 0.6314 - val_loss: 0.6468 - val_accuracy: 0.7514\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 18s 478us/step - loss: 0.7966 - accuracy: 0.6974 - val_loss: 0.5533 - val_accuracy: 0.7888\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 477us/step - loss: 0.6977 - accuracy: 0.7370 - val_loss: 0.5007 - val_accuracy: 0.8052\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 0.6282 - accuracy: 0.7651 - val_loss: 0.4690 - val_accuracy: 0.8192\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 468us/step - loss: 2.3443 - accuracy: 0.1012 - val_loss: 2.3040 - val_accuracy: 0.0980\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.3128 - accuracy: 0.1025 - val_loss: 2.3039 - val_accuracy: 0.0986\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.3114 - accuracy: 0.1000 - val_loss: 2.3085 - val_accuracy: 0.0986\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.3116 - accuracy: 0.0986 - val_loss: 2.3058 - val_accuracy: 0.0980\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.3111 - accuracy: 0.1027 - val_loss: 2.3075 - val_accuracy: 0.1024\n",
      "18333/18333 [==============================] - 3s 153us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 465us/step - loss: 2.3030 - accuracy: 0.1018 - val_loss: 2.3031 - val_accuracy: 0.0980\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3030 - val_accuracy: 0.0980\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 458us/step - loss: 2.3027 - accuracy: 0.1003 - val_loss: 2.3029 - val_accuracy: 0.0914\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "18334/18334 [==============================] - 3s 153us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 470us/step - loss: 2.3029 - accuracy: 0.0989 - val_loss: 2.3025 - val_accuracy: 0.1002\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1008\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 467us/step - loss: 2.3030 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3030 - val_accuracy: 0.0986\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 2.3026 - accuracy: 0.0990 - val_loss: 2.3029 - val_accuracy: 0.0986\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3030 - val_accuracy: 0.0986\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 466us/step - loss: 2.3028 - accuracy: 0.0997 - val_loss: 2.3029 - val_accuracy: 0.0914\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.0980\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3028 - val_accuracy: 0.0914\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 455us/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3028 - val_accuracy: 0.0980\n",
      "18334/18334 [==============================] - 3s 153us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 2.3029 - accuracy: 0.0988 - val_loss: 2.3028 - val_accuracy: 0.1024\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 455us/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 454us/step - loss: 2.3027 - accuracy: 0.1007 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.3027 - accuracy: 0.1004 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3027 - val_accuracy: 0.1008\n",
      "18333/18333 [==============================] - 3s 153us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 465us/step - loss: 2.3031 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.1002\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3029 - val_accuracy: 0.1024\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3031 - val_accuracy: 0.0986\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 465us/step - loss: 1.2514 - accuracy: 0.5155 - val_loss: 0.7377 - val_accuracy: 0.7050\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 0.7767 - accuracy: 0.7097 - val_loss: 0.5418 - val_accuracy: 0.7984\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 0.6560 - accuracy: 0.7575 - val_loss: 0.5134 - val_accuracy: 0.7974\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 18s 481us/step - loss: 0.5889 - accuracy: 0.7836 - val_loss: 0.4397 - val_accuracy: 0.8336\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 469us/step - loss: 0.5429 - accuracy: 0.8060 - val_loss: 0.4285 - val_accuracy: 0.8402\n",
      "18334/18334 [==============================] - 3s 148us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 484us/step - loss: 1.2488 - accuracy: 0.5246 - val_loss: 0.6673 - val_accuracy: 0.7452\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 476us/step - loss: 0.7725 - accuracy: 0.7081 - val_loss: 0.5536 - val_accuracy: 0.7868\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 18s 481us/step - loss: 0.6584 - accuracy: 0.7562 - val_loss: 0.4699 - val_accuracy: 0.8250\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 476us/step - loss: 0.5991 - accuracy: 0.7791 - val_loss: 0.4379 - val_accuracy: 0.8394\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 455us/step - loss: 0.5443 - accuracy: 0.8018 - val_loss: 0.3918 - val_accuracy: 0.8612\n",
      "18333/18333 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 465us/step - loss: 1.2841 - accuracy: 0.5142 - val_loss: 0.6643 - val_accuracy: 0.7530\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.7596 - accuracy: 0.7121 - val_loss: 0.5501 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 455us/step - loss: 0.6540 - accuracy: 0.7547 - val_loss: 0.4784 - val_accuracy: 0.8168\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.5927 - accuracy: 0.7802 - val_loss: 0.4756 - val_accuracy: 0.8162\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 0.5508 - accuracy: 0.7982 - val_loss: 0.4316 - val_accuracy: 0.8390\n",
      "18333/18333 [==============================] - 3s 153us/step\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 26s 473us/step - loss: 1.0984 - accuracy: 0.5805 - val_loss: 0.6176 - val_accuracy: 0.7666\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 25s 449us/step - loss: 0.6857 - accuracy: 0.7438 - val_loss: 0.4876 - val_accuracy: 0.8080\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 25s 453us/step - loss: 0.5767 - accuracy: 0.7915 - val_loss: 0.4133 - val_accuracy: 0.8470\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 25s 451us/step - loss: 0.5137 - accuracy: 0.8198 - val_loss: 0.3767 - val_accuracy: 0.8596\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 25s 451us/step - loss: 0.4724 - accuracy: 0.8368 - val_loss: 0.3488 - val_accuracy: 0.8710\n",
      "-------------------------------\n",
      "Best Parameters: \n",
      "{'b_initializer': <keras.initializers.Zeros object at 0x7f9ed9d99d50>, 'k_initializer': <keras.initializers.RandomNormal object at 0x7f9ed9d99b90>}\n",
      "-------------------------------\n",
      "Evaluation on Test Set:\n",
      "10000/10000 [==============================] - 2s 187us/step\n",
      "0.8450999855995178\n"
     ]
    }
   ],
   "source": [
    "inits = [keras.initializers.Zeros(), \n",
    "         keras.initializers.Ones(), \n",
    "         keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)]\n",
    "param_distribs= {'k_initializer': inits, 'b_initializer': inits}\n",
    "\n",
    "grid_search_cv = gridSearch(param_distribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_b_initializer</th>\n",
       "      <th>param_k_initializer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.146117</td>\n",
       "      <td>4.094358</td>\n",
       "      <td>3.043326</td>\n",
       "      <td>0.151773</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f9ed9d9...</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f9ed9d9...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Zeros ob...</td>\n",
       "      <td>0.097033</td>\n",
       "      <td>0.096874</td>\n",
       "      <td>0.098947</td>\n",
       "      <td>0.097618</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.962179</td>\n",
       "      <td>0.033560</td>\n",
       "      <td>2.797408</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f9ed9d9...</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f9ed9d99...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Zeros ob...</td>\n",
       "      <td>0.097033</td>\n",
       "      <td>0.096874</td>\n",
       "      <td>0.097038</td>\n",
       "      <td>0.096982</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.375292</td>\n",
       "      <td>1.535231</td>\n",
       "      <td>2.775373</td>\n",
       "      <td>0.061390</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f9ed9d9...</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Zeros ob...</td>\n",
       "      <td>0.843624</td>\n",
       "      <td>0.838979</td>\n",
       "      <td>0.846615</td>\n",
       "      <td>0.843073</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.895720</td>\n",
       "      <td>0.065386</td>\n",
       "      <td>2.827007</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f9ed9d99...</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f9ed9d9...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Ones obj...</td>\n",
       "      <td>0.100087</td>\n",
       "      <td>0.096874</td>\n",
       "      <td>0.099111</td>\n",
       "      <td>0.098691</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.593447</td>\n",
       "      <td>8.003321</td>\n",
       "      <td>2.836142</td>\n",
       "      <td>0.028097</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f9ed9d99...</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f9ed9d99...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Ones obj...</td>\n",
       "      <td>0.097033</td>\n",
       "      <td>0.096874</td>\n",
       "      <td>0.097038</td>\n",
       "      <td>0.096982</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86.175680</td>\n",
       "      <td>1.052846</td>\n",
       "      <td>2.766570</td>\n",
       "      <td>0.065984</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f9ed9d99...</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.Ones obj...</td>\n",
       "      <td>0.813843</td>\n",
       "      <td>0.809469</td>\n",
       "      <td>0.097693</td>\n",
       "      <td>0.573673</td>\n",
       "      <td>0.336569</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73.938153</td>\n",
       "      <td>7.761553</td>\n",
       "      <td>2.818321</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>&lt;keras.initializers.Zeros object at 0x7f9ed9d9...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.RandomNo...</td>\n",
       "      <td>0.099051</td>\n",
       "      <td>0.096874</td>\n",
       "      <td>0.097038</td>\n",
       "      <td>0.097655</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>79.161461</td>\n",
       "      <td>7.822637</td>\n",
       "      <td>2.811261</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>&lt;keras.initializers.Ones object at 0x7f9ed9d99...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.RandomNo...</td>\n",
       "      <td>0.097033</td>\n",
       "      <td>0.096874</td>\n",
       "      <td>0.097038</td>\n",
       "      <td>0.096982</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>86.194941</td>\n",
       "      <td>1.099869</td>\n",
       "      <td>2.793692</td>\n",
       "      <td>0.057916</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>&lt;keras.initializers.RandomNormal object at 0x7...</td>\n",
       "      <td>{'b_initializer': &lt;keras.initializers.RandomNo...</td>\n",
       "      <td>0.828624</td>\n",
       "      <td>0.854852</td>\n",
       "      <td>0.831179</td>\n",
       "      <td>0.838218</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      71.146117      4.094358         3.043326        0.151773   \n",
       "1      67.962179      0.033560         2.797408        0.005126   \n",
       "2      86.375292      1.535231         2.775373        0.061390   \n",
       "3      84.895720      0.065386         2.827007        0.004484   \n",
       "4      79.593447      8.003321         2.836142        0.028097   \n",
       "5      86.175680      1.052846         2.766570        0.065984   \n",
       "6      73.938153      7.761553         2.818321        0.006145   \n",
       "7      79.161461      7.822637         2.811261        0.009292   \n",
       "8      86.194941      1.099869         2.793692        0.057916   \n",
       "\n",
       "                                 param_b_initializer  \\\n",
       "0  <keras.initializers.Zeros object at 0x7f9ed9d9...   \n",
       "1  <keras.initializers.Zeros object at 0x7f9ed9d9...   \n",
       "2  <keras.initializers.Zeros object at 0x7f9ed9d9...   \n",
       "3  <keras.initializers.Ones object at 0x7f9ed9d99...   \n",
       "4  <keras.initializers.Ones object at 0x7f9ed9d99...   \n",
       "5  <keras.initializers.Ones object at 0x7f9ed9d99...   \n",
       "6  <keras.initializers.RandomNormal object at 0x7...   \n",
       "7  <keras.initializers.RandomNormal object at 0x7...   \n",
       "8  <keras.initializers.RandomNormal object at 0x7...   \n",
       "\n",
       "                                 param_k_initializer  \\\n",
       "0  <keras.initializers.Zeros object at 0x7f9ed9d9...   \n",
       "1  <keras.initializers.Ones object at 0x7f9ed9d99...   \n",
       "2  <keras.initializers.RandomNormal object at 0x7...   \n",
       "3  <keras.initializers.Zeros object at 0x7f9ed9d9...   \n",
       "4  <keras.initializers.Ones object at 0x7f9ed9d99...   \n",
       "5  <keras.initializers.RandomNormal object at 0x7...   \n",
       "6  <keras.initializers.Zeros object at 0x7f9ed9d9...   \n",
       "7  <keras.initializers.Ones object at 0x7f9ed9d99...   \n",
       "8  <keras.initializers.RandomNormal object at 0x7...   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'b_initializer': <keras.initializers.Zeros ob...           0.097033   \n",
       "1  {'b_initializer': <keras.initializers.Zeros ob...           0.097033   \n",
       "2  {'b_initializer': <keras.initializers.Zeros ob...           0.843624   \n",
       "3  {'b_initializer': <keras.initializers.Ones obj...           0.100087   \n",
       "4  {'b_initializer': <keras.initializers.Ones obj...           0.097033   \n",
       "5  {'b_initializer': <keras.initializers.Ones obj...           0.813843   \n",
       "6  {'b_initializer': <keras.initializers.RandomNo...           0.099051   \n",
       "7  {'b_initializer': <keras.initializers.RandomNo...           0.097033   \n",
       "8  {'b_initializer': <keras.initializers.RandomNo...           0.828624   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.096874           0.098947         0.097618        0.000942   \n",
       "1           0.096874           0.097038         0.096982        0.000076   \n",
       "2           0.838979           0.846615         0.843073        0.003142   \n",
       "3           0.096874           0.099111         0.098691        0.001345   \n",
       "4           0.096874           0.097038         0.096982        0.000076   \n",
       "5           0.809469           0.097693         0.573673        0.336569   \n",
       "6           0.096874           0.097038         0.097655        0.000990   \n",
       "7           0.096874           0.097038         0.096982        0.000076   \n",
       "8           0.854852           0.831179         0.838218        0.011808   \n",
       "\n",
       "   rank_test_score  \n",
       "0                6  \n",
       "1                7  \n",
       "2                1  \n",
       "3                4  \n",
       "4                7  \n",
       "5                3  \n",
       "6                5  \n",
       "7                7  \n",
       "8                2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inits_df = pd.DataFrame(grid_search_cv.cv_results_)\n",
    "inits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b_initializer': <keras.initializers.Zeros at 0x7f9ed9d99d50>,\n",
       " 'k_initializer': <keras.initializers.RandomNormal at 0x7f9ed9d99b90>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 156us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8450999855995178"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_.score(preprocessing_image_for_cnn(Xf_test), yf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2. Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 473us/step - loss: 2.3089 - accuracy: 0.0993 - val_loss: 2.3032 - val_accuracy: 0.1024\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 458us/step - loss: 2.3065 - accuracy: 0.0991 - val_loss: 2.3037 - val_accuracy: 0.0976\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 465us/step - loss: 2.3057 - accuracy: 0.0987 - val_loss: 2.3040 - val_accuracy: 0.0914\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 464us/step - loss: 2.3058 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1012\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 2.3047 - accuracy: 0.1019 - val_loss: 2.3033 - val_accuracy: 0.0980\n",
      "18334/18334 [==============================] - 3s 166us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 483us/step - loss: 2.3090 - accuracy: 0.0991 - val_loss: 2.3040 - val_accuracy: 0.1112\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 467us/step - loss: 2.3067 - accuracy: 0.0993 - val_loss: 2.3052 - val_accuracy: 0.0914\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 465us/step - loss: 2.3060 - accuracy: 0.0997 - val_loss: 2.3048 - val_accuracy: 0.1008\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.3054 - accuracy: 0.0991 - val_loss: 2.3030 - val_accuracy: 0.0986\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 2.3056 - accuracy: 0.0992 - val_loss: 2.3030 - val_accuracy: 0.0914\n",
      "18333/18333 [==============================] - 3s 147us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 479us/step - loss: 2.3087 - accuracy: 0.1009 - val_loss: 2.3023 - val_accuracy: 0.1112\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 18s 486us/step - loss: 2.3063 - accuracy: 0.1003 - val_loss: 2.3041 - val_accuracy: 0.1002\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 18s 481us/step - loss: 2.3060 - accuracy: 0.1007 - val_loss: 2.3035 - val_accuracy: 0.0914\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 18s 482us/step - loss: 2.3053 - accuracy: 0.1025 - val_loss: 2.3043 - val_accuracy: 0.1002\n",
      "18333/18333 [==============================] - 3s 147us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 18s 490us/step - loss: 2.3021 - accuracy: 0.1051 - val_loss: 2.3016 - val_accuracy: 0.1142\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 2.2957 - accuracy: 0.1353 - val_loss: 2.2633 - val_accuracy: 0.1980\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 461us/step - loss: 1.3905 - accuracy: 0.4482 - val_loss: 0.8923 - val_accuracy: 0.6548\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 0.9372 - accuracy: 0.6463 - val_loss: 0.7247 - val_accuracy: 0.7306\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 0.8207 - accuracy: 0.6947 - val_loss: 0.6521 - val_accuracy: 0.7616\n",
      "18334/18334 [==============================] - 3s 156us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 469us/step - loss: 2.3021 - accuracy: 0.1036 - val_loss: 2.3007 - val_accuracy: 0.1008\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 2.2927 - accuracy: 0.1350 - val_loss: 2.2161 - val_accuracy: 0.2724\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 1.3297 - accuracy: 0.4656 - val_loss: 0.8378 - val_accuracy: 0.6918\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 0.9269 - accuracy: 0.6448 - val_loss: 0.7205 - val_accuracy: 0.7206\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 456us/step - loss: 0.8307 - accuracy: 0.6865 - val_loss: 0.6567 - val_accuracy: 0.7524\n",
      "18333/18333 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 489us/step - loss: 2.3017 - accuracy: 0.1049 - val_loss: 2.2996 - val_accuracy: 0.0914\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 2.0886 - accuracy: 0.2068 - val_loss: 1.1101 - val_accuracy: 0.5376\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 1.0850 - accuracy: 0.5738 - val_loss: 0.8786 - val_accuracy: 0.6688\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.8757 - accuracy: 0.6703 - val_loss: 0.7562 - val_accuracy: 0.7002\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 0.7892 - accuracy: 0.7064 - val_loss: 0.6135 - val_accuracy: 0.7760\n",
      "18333/18333 [==============================] - 3s 155us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 466us/step - loss: 1.6660 - accuracy: 0.3928 - val_loss: 1.0075 - val_accuracy: 0.6046\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 456us/step - loss: 0.8755 - accuracy: 0.6709 - val_loss: 0.6480 - val_accuracy: 0.7558\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 0.6601 - accuracy: 0.7522 - val_loss: 0.5493 - val_accuracy: 0.7874\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 0.5752 - accuracy: 0.7859 - val_loss: 0.4675 - val_accuracy: 0.8222\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 458us/step - loss: 0.5222 - accuracy: 0.8134 - val_loss: 0.4377 - val_accuracy: 0.8414\n",
      "18334/18334 [==============================] - 3s 156us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 468us/step - loss: 1.7064 - accuracy: 0.3799 - val_loss: 1.0253 - val_accuracy: 0.5990\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.8971 - accuracy: 0.6654 - val_loss: 0.6579 - val_accuracy: 0.7616\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.6702 - accuracy: 0.7514 - val_loss: 0.5265 - val_accuracy: 0.8014\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 0.5762 - accuracy: 0.7886 - val_loss: 0.4807 - val_accuracy: 0.8234\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.5227 - accuracy: 0.8129 - val_loss: 0.4156 - val_accuracy: 0.8494\n",
      "18333/18333 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 1.7319 - accuracy: 0.3812 - val_loss: 1.0348 - val_accuracy: 0.5924\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 468us/step - loss: 0.8989 - accuracy: 0.6629 - val_loss: 0.6495 - val_accuracy: 0.7604\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.6630 - accuracy: 0.7547 - val_loss: 0.5310 - val_accuracy: 0.8018\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 0.5724 - accuracy: 0.7891 - val_loss: 0.4660 - val_accuracy: 0.8188\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 18s 479us/step - loss: 0.5157 - accuracy: 0.8158 - val_loss: 0.4147 - val_accuracy: 0.8472\n",
      "18333/18333 [==============================] - 3s 161us/step\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 25s 459us/step - loss: 1.4636 - accuracy: 0.4505 - val_loss: 0.8466 - val_accuracy: 0.7072\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 25s 451us/step - loss: 0.7368 - accuracy: 0.7251 - val_loss: 0.5479 - val_accuracy: 0.7910\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 25s 451us/step - loss: 0.5764 - accuracy: 0.7866 - val_loss: 0.4505 - val_accuracy: 0.8284\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 25s 451us/step - loss: 0.4971 - accuracy: 0.8233 - val_loss: 0.4032 - val_accuracy: 0.8520\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 25s 451us/step - loss: 0.4466 - accuracy: 0.8451 - val_loss: 0.3608 - val_accuracy: 0.8710\n"
     ]
    }
   ],
   "source": [
    "activs = ['sigmoid', 'relu', 'tanh']\n",
    "param_distribs= {'activation': activs}\n",
    "\n",
    "grid_search_cv = gridSearch(param_distribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81.384520</td>\n",
       "      <td>7.115098</td>\n",
       "      <td>2.816519</td>\n",
       "      <td>0.159537</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'activation': 'sigmoid'}</td>\n",
       "      <td>0.097033</td>\n",
       "      <td>0.101893</td>\n",
       "      <td>0.099765</td>\n",
       "      <td>0.099564</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.855708</td>\n",
       "      <td>0.279259</td>\n",
       "      <td>2.848913</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>relu</td>\n",
       "      <td>{'activation': 'relu'}</td>\n",
       "      <td>0.747955</td>\n",
       "      <td>0.750668</td>\n",
       "      <td>0.771232</td>\n",
       "      <td>0.756618</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.448889</td>\n",
       "      <td>0.460295</td>\n",
       "      <td>2.878455</td>\n",
       "      <td>0.048298</td>\n",
       "      <td>tanh</td>\n",
       "      <td>{'activation': 'tanh'}</td>\n",
       "      <td>0.832279</td>\n",
       "      <td>0.847434</td>\n",
       "      <td>0.841324</td>\n",
       "      <td>0.840345</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      81.384520      7.115098         2.816519        0.159537   \n",
       "1      85.855708      0.279259         2.848913        0.011724   \n",
       "2      85.448889      0.460295         2.878455        0.048298   \n",
       "\n",
       "  param_activation                     params  split0_test_score  \\\n",
       "0          sigmoid  {'activation': 'sigmoid'}           0.097033   \n",
       "1             relu     {'activation': 'relu'}           0.747955   \n",
       "2             tanh     {'activation': 'tanh'}           0.832279   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.101893           0.099765         0.099564        0.001989   \n",
       "1           0.750668           0.771232         0.756618        0.010393   \n",
       "2           0.847434           0.841324         0.840345        0.006226   \n",
       "\n",
       "   rank_test_score  \n",
       "0                3  \n",
       "1                2  \n",
       "2                1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activs_df = pd.DataFrame(grid_search_cv.cv_results_)\n",
    "activs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 150us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8003000020980835"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = grid_search_cv.best_estimator_\n",
    "est.score(preprocessing_image_for_cnn(Xf_test), yf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3. Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 21s 580us/step - loss: 2.3030 - accuracy: 0.1010 - val_loss: 2.3036 - val_accuracy: 0.0914\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 21s 559us/step - loss: 2.3027 - accuracy: 0.1015 - val_loss: 2.3034 - val_accuracy: 0.0914\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 20s 556us/step - loss: 2.3025 - accuracy: 0.1044 - val_loss: 2.3031 - val_accuracy: 0.0914\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 21s 576us/step - loss: 2.3024 - accuracy: 0.1038 - val_loss: 2.3029 - val_accuracy: 0.0914\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 20s 540us/step - loss: 2.3023 - accuracy: 0.1071 - val_loss: 2.3027 - val_accuracy: 0.0914\n",
      "18334/18334 [==============================] - 4s 234us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 16s 432us/step - loss: 2.3028 - accuracy: 0.1031 - val_loss: 2.3034 - val_accuracy: 0.1012\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 18s 489us/step - loss: 2.3026 - accuracy: 0.1019 - val_loss: 2.3032 - val_accuracy: 0.1012\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 18s 492us/step - loss: 2.3025 - accuracy: 0.1015 - val_loss: 2.3029 - val_accuracy: 0.1012\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 20s 551us/step - loss: 2.3023 - accuracy: 0.1039 - val_loss: 2.3027 - val_accuracy: 0.1012\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 19s 527us/step - loss: 2.3022 - accuracy: 0.1042 - val_loss: 2.3025 - val_accuracy: 0.1012\n",
      "18333/18333 [==============================] - 4s 239us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 21s 570us/step - loss: 2.3028 - accuracy: 0.1018 - val_loss: 2.3026 - val_accuracy: 0.1024\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 21s 577us/step - loss: 2.3025 - accuracy: 0.1018 - val_loss: 2.3024 - val_accuracy: 0.1024\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 21s 580us/step - loss: 2.3024 - accuracy: 0.1012 - val_loss: 2.3021 - val_accuracy: 0.1024\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 19s 529us/step - loss: 2.3020 - accuracy: 0.1048 - val_loss: 2.3019 - val_accuracy: 0.1024\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 18s 479us/step - loss: 2.3018 - accuracy: 0.1072 - val_loss: 2.3016 - val_accuracy: 0.1024\n",
      "18333/18333 [==============================] - 4s 235us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 19s 531us/step - loss: 0.8633 - accuracy: 0.6786 - val_loss: 0.4206 - val_accuracy: 0.8486\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 20s 533us/step - loss: 0.4653 - accuracy: 0.8457 - val_loss: 0.3400 - val_accuracy: 0.8824\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 20s 532us/step - loss: 0.4276 - accuracy: 0.8650 - val_loss: 0.3577 - val_accuracy: 0.8768\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 19s 524us/step - loss: 0.4434 - accuracy: 0.8644 - val_loss: 0.3834 - val_accuracy: 0.8726\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 19s 517us/step - loss: 0.4543 - accuracy: 0.8632 - val_loss: 0.4160 - val_accuracy: 0.8592\n",
      "18334/18334 [==============================] - 4s 236us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 22s 598us/step - loss: 0.8424 - accuracy: 0.6920 - val_loss: 0.3962 - val_accuracy: 0.8466\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 22s 603us/step - loss: 0.4636 - accuracy: 0.8453 - val_loss: 0.3394 - val_accuracy: 0.8792\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 20s 553us/step - loss: 0.4428 - accuracy: 0.8578 - val_loss: 0.4051 - val_accuracy: 0.8700\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 21s 560us/step - loss: 0.4744 - accuracy: 0.8527 - val_loss: 0.4050 - val_accuracy: 0.8608\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 18s 502us/step - loss: 0.4877 - accuracy: 0.8488 - val_loss: 0.5975 - val_accuracy: 0.8242\n",
      "18333/18333 [==============================] - 4s 238us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 22s 587us/step - loss: 0.8220 - accuracy: 0.6922 - val_loss: 0.3888 - val_accuracy: 0.8578\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 22s 595us/step - loss: 0.4490 - accuracy: 0.8492 - val_loss: 0.3622 - val_accuracy: 0.8736\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 21s 562us/step - loss: 0.4259 - accuracy: 0.8604 - val_loss: 0.3836 - val_accuracy: 0.8534\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 20s 556us/step - loss: 0.4383 - accuracy: 0.8598 - val_loss: 0.4061 - val_accuracy: 0.8662\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 18s 500us/step - loss: 0.4553 - accuracy: 0.8613 - val_loss: 0.3887 - val_accuracy: 0.8762\n",
      "18333/18333 [==============================] - 3s 178us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 19s 515us/step - loss: 1.1539 - accuracy: 0.5780 - val_loss: 0.6800 - val_accuracy: 0.7586\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 21s 564us/step - loss: 0.8570 - accuracy: 0.6891 - val_loss: 0.6227 - val_accuracy: 0.7718\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 16s 446us/step - loss: 0.7971 - accuracy: 0.7113 - val_loss: 0.5885 - val_accuracy: 0.7802\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 461us/step - loss: 0.7513 - accuracy: 0.7276 - val_loss: 0.5875 - val_accuracy: 0.7822\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 19s 517us/step - loss: 0.7155 - accuracy: 0.7393 - val_loss: 0.5498 - val_accuracy: 0.7910\n",
      "18334/18334 [==============================] - 4s 234us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 20s 559us/step - loss: 1.1732 - accuracy: 0.5605 - val_loss: 0.6872 - val_accuracy: 0.7386\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 22s 591us/step - loss: 0.8664 - accuracy: 0.6819 - val_loss: 0.6344 - val_accuracy: 0.7634\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 21s 586us/step - loss: 0.7930 - accuracy: 0.7066 - val_loss: 0.5947 - val_accuracy: 0.7784\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 21s 584us/step - loss: 0.7493 - accuracy: 0.7246 - val_loss: 0.5743 - val_accuracy: 0.7858\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 21s 584us/step - loss: 0.7184 - accuracy: 0.7341 - val_loss: 0.5518 - val_accuracy: 0.8000\n",
      "18333/18333 [==============================] - 4s 235us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 21s 576us/step - loss: 1.1633 - accuracy: 0.5635 - val_loss: 0.6917 - val_accuracy: 0.7522\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 21s 566us/step - loss: 0.8640 - accuracy: 0.6845 - val_loss: 0.6342 - val_accuracy: 0.7662\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 22s 594us/step - loss: 0.7962 - accuracy: 0.7058 - val_loss: 0.5891 - val_accuracy: 0.7772\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 21s 581us/step - loss: 0.7551 - accuracy: 0.7241 - val_loss: 0.5728 - val_accuracy: 0.7834\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 22s 587us/step - loss: 0.7203 - accuracy: 0.7356 - val_loss: 0.5549 - val_accuracy: 0.7908\n",
      "18333/18333 [==============================] - 4s 202us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 20s 535us/step - loss: 0.8380 - accuracy: 0.6832 - val_loss: 0.4437 - val_accuracy: 0.8310\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 20s 548us/step - loss: 0.4969 - accuracy: 0.8261 - val_loss: 0.3447 - val_accuracy: 0.8716\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 19s 532us/step - loss: 0.4127 - accuracy: 0.8593 - val_loss: 0.3022 - val_accuracy: 0.8912\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 20s 539us/step - loss: 0.3676 - accuracy: 0.8730 - val_loss: 0.2911 - val_accuracy: 0.8958\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 21s 567us/step - loss: 0.3300 - accuracy: 0.8850 - val_loss: 0.2809 - val_accuracy: 0.9008\n",
      "18334/18334 [==============================] - 4s 235us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 22s 592us/step - loss: 0.9690 - accuracy: 0.6201 - val_loss: 0.5542 - val_accuracy: 0.7814\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 22s 587us/step - loss: 0.6083 - accuracy: 0.7803 - val_loss: 0.3967 - val_accuracy: 0.8564\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 21s 585us/step - loss: 0.5103 - accuracy: 0.8222 - val_loss: 0.3674 - val_accuracy: 0.8688\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 21s 565us/step - loss: 0.4595 - accuracy: 0.8386 - val_loss: 0.3434 - val_accuracy: 0.8718\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 21s 566us/step - loss: 0.4162 - accuracy: 0.8556 - val_loss: 0.3464 - val_accuracy: 0.8686\n",
      "18333/18333 [==============================] - 4s 235us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 20s 536us/step - loss: 0.9977 - accuracy: 0.6102 - val_loss: 0.5451 - val_accuracy: 0.7918\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 18s 486us/step - loss: 0.6016 - accuracy: 0.7821 - val_loss: 0.4163 - val_accuracy: 0.8466\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 18s 491us/step - loss: 0.5032 - accuracy: 0.8240 - val_loss: 0.3702 - val_accuracy: 0.8662\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 18s 500us/step - loss: 0.4503 - accuracy: 0.8445 - val_loss: 0.3648 - val_accuracy: 0.8660\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 19s 511us/step - loss: 0.4061 - accuracy: 0.8587 - val_loss: 0.3259 - val_accuracy: 0.8812\n",
      "18333/18333 [==============================] - 4s 231us/step\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 30s 551us/step - loss: 0.9080 - accuracy: 0.6540 - val_loss: 0.4806 - val_accuracy: 0.8052\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 30s 537us/step - loss: 0.5740 - accuracy: 0.7849 - val_loss: 0.3974 - val_accuracy: 0.8308\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 31s 562us/step - loss: 0.4990 - accuracy: 0.8190 - val_loss: 0.3650 - val_accuracy: 0.8682\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 30s 551us/step - loss: 0.4458 - accuracy: 0.8406 - val_loss: 0.3235 - val_accuracy: 0.8794\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 28s 511us/step - loss: 0.4143 - accuracy: 0.8545 - val_loss: 0.3054 - val_accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "optims = [keras.optimizers.SGD(learning_rate=0.001),\n",
    "          keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
    "          keras.optimizers.Adagrad(learning_rate=0.001),\n",
    "          keras.optimizers.Adam(learning_rate=0.001)]\n",
    "\n",
    "param_distribs= {'optimizer': optims}\n",
    "\n",
    "grid_search_cv = gridSearch(param_distribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_optimizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.647550</td>\n",
       "      <td>5.004391</td>\n",
       "      <td>4.335077</td>\n",
       "      <td>0.036053</td>\n",
       "      <td>&lt;keras.optimizers.SGD object at 0x7f82670b91d0&gt;</td>\n",
       "      <td>{'optimizer': &lt;keras.optimizers.SGD object at ...</td>\n",
       "      <td>0.100087</td>\n",
       "      <td>0.099547</td>\n",
       "      <td>0.097693</td>\n",
       "      <td>0.099109</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.437914</td>\n",
       "      <td>2.989342</td>\n",
       "      <td>3.994335</td>\n",
       "      <td>0.515481</td>\n",
       "      <td>&lt;keras.optimizers.RMSprop object at 0x7f81dfee...</td>\n",
       "      <td>{'optimizer': &lt;keras.optimizers.RMSprop object...</td>\n",
       "      <td>0.854260</td>\n",
       "      <td>0.830797</td>\n",
       "      <td>0.867507</td>\n",
       "      <td>0.850855</td>\n",
       "      <td>0.015179</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.129603</td>\n",
       "      <td>6.980343</td>\n",
       "      <td>4.106051</td>\n",
       "      <td>0.278512</td>\n",
       "      <td>&lt;keras.optimizers.Adagrad object at 0x7f82670b...</td>\n",
       "      <td>{'optimizer': &lt;keras.optimizers.Adagrad object...</td>\n",
       "      <td>0.778499</td>\n",
       "      <td>0.795451</td>\n",
       "      <td>0.782251</td>\n",
       "      <td>0.785400</td>\n",
       "      <td>0.007270</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.121864</td>\n",
       "      <td>5.558073</td>\n",
       "      <td>4.291155</td>\n",
       "      <td>0.028987</td>\n",
       "      <td>&lt;keras.optimizers.Adam object at 0x7f82670b9ed0&gt;</td>\n",
       "      <td>{'optimizer': &lt;keras.optimizers.Adam object at...</td>\n",
       "      <td>0.893858</td>\n",
       "      <td>0.872743</td>\n",
       "      <td>0.877925</td>\n",
       "      <td>0.881509</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      98.647550      5.004391         4.335077        0.036053   \n",
       "1     101.437914      2.989342         3.994335        0.515481   \n",
       "2     102.129603      6.980343         4.106051        0.278512   \n",
       "3     100.121864      5.558073         4.291155        0.028987   \n",
       "\n",
       "                                     param_optimizer  \\\n",
       "0    <keras.optimizers.SGD object at 0x7f82670b91d0>   \n",
       "1  <keras.optimizers.RMSprop object at 0x7f81dfee...   \n",
       "2  <keras.optimizers.Adagrad object at 0x7f82670b...   \n",
       "3   <keras.optimizers.Adam object at 0x7f82670b9ed0>   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'optimizer': <keras.optimizers.SGD object at ...           0.100087   \n",
       "1  {'optimizer': <keras.optimizers.RMSprop object...           0.854260   \n",
       "2  {'optimizer': <keras.optimizers.Adagrad object...           0.778499   \n",
       "3  {'optimizer': <keras.optimizers.Adam object at...           0.893858   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.099547           0.097693         0.099109        0.001026   \n",
       "1           0.830797           0.867507         0.850855        0.015179   \n",
       "2           0.795451           0.782251         0.785400        0.007270   \n",
       "3           0.872743           0.877925         0.881509        0.008985   \n",
       "\n",
       "   rank_test_score  \n",
       "0                4  \n",
       "1                2  \n",
       "2                3  \n",
       "3                1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optims_df = pd.DataFrame(grid_search_cv.cv_results_)\n",
    "optims_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': <keras.optimizers.Adam at 0x7f82670b9ed0>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 281us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8733999729156494"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = grid_search_cv.best_estimator_\n",
    "est.score(preprocessing_image_for_cnn(Xf_test), yf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4. Regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 467us/step - loss: 2.3022 - accuracy: 0.1054 - val_loss: 2.3012 - val_accuracy: 0.0980\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 2.2927 - accuracy: 0.1414 - val_loss: 2.2310 - val_accuracy: 0.2380\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 461us/step - loss: 1.3504 - accuracy: 0.4603 - val_loss: 0.8853 - val_accuracy: 0.6516\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 0.9276 - accuracy: 0.6477 - val_loss: 0.7120 - val_accuracy: 0.7336\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 463us/step - loss: 0.8263 - accuracy: 0.6931 - val_loss: 0.6801 - val_accuracy: 0.7564\n",
      "18334/18334 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 467us/step - loss: 2.3025 - accuracy: 0.1049 - val_loss: 2.3012 - val_accuracy: 0.1026\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 2.2977 - accuracy: 0.1247 - val_loss: 2.2786 - val_accuracy: 0.1016\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.4978 - accuracy: 0.4078 - val_loss: 0.9233 - val_accuracy: 0.6120\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 0.9502 - accuracy: 0.6343 - val_loss: 0.7145 - val_accuracy: 0.7284\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 0.8371 - accuracy: 0.6867 - val_loss: 0.6847 - val_accuracy: 0.7596\n",
      "18333/18333 [==============================] - 3s 156us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 469us/step - loss: 2.3022 - accuracy: 0.1018 - val_loss: 2.3015 - val_accuracy: 0.1820\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 18s 492us/step - loss: 2.2984 - accuracy: 0.1386 - val_loss: 2.2880 - val_accuracy: 0.1558\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 18s 487us/step - loss: 1.6079 - accuracy: 0.3669 - val_loss: 0.9662 - val_accuracy: 0.5988\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 477us/step - loss: 0.9695 - accuracy: 0.6242 - val_loss: 0.7338 - val_accuracy: 0.7040\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 18s 479us/step - loss: 0.8472 - accuracy: 0.6810 - val_loss: 0.6772 - val_accuracy: 0.7546\n",
      "18333/18333 [==============================] - 3s 148us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 18s 489us/step - loss: 2.3009 - accuracy: 0.1126 - val_loss: 2.2952 - val_accuracy: 0.2402\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 18s 485us/step - loss: 1.7236 - accuracy: 0.3368 - val_loss: 0.9494 - val_accuracy: 0.6154\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 0.9760 - accuracy: 0.6246 - val_loss: 0.7570 - val_accuracy: 0.7174\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 0.8408 - accuracy: 0.6825 - val_loss: 0.6667 - val_accuracy: 0.7484\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 458us/step - loss: 0.7634 - accuracy: 0.7200 - val_loss: 0.6067 - val_accuracy: 0.7756\n",
      "18334/18334 [==============================] - 3s 156us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 481us/step - loss: 2.3023 - accuracy: 0.1043 - val_loss: 2.3014 - val_accuracy: 0.0914\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 2.2969 - accuracy: 0.1517 - val_loss: 2.2772 - val_accuracy: 0.2638\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 1.5033 - accuracy: 0.4050 - val_loss: 0.9207 - val_accuracy: 0.6166\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 463us/step - loss: 0.9646 - accuracy: 0.6296 - val_loss: 0.7445 - val_accuracy: 0.7154\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 456us/step - loss: 0.8477 - accuracy: 0.6831 - val_loss: 0.6566 - val_accuracy: 0.7546\n",
      "18333/18333 [==============================] - 3s 156us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 465us/step - loss: 2.3021 - accuracy: 0.1079 - val_loss: 2.3015 - val_accuracy: 0.0914\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 2.2953 - accuracy: 0.1573 - val_loss: 2.2580 - val_accuracy: 0.2258\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 1.3814 - accuracy: 0.4505 - val_loss: 0.8827 - val_accuracy: 0.6772\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 463us/step - loss: 0.9494 - accuracy: 0.6354 - val_loss: 0.7128 - val_accuracy: 0.7232\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 466us/step - loss: 0.8402 - accuracy: 0.6828 - val_loss: 0.6869 - val_accuracy: 0.7228\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 467us/step - loss: 2.3023 - accuracy: 0.1073 - val_loss: 2.3016 - val_accuracy: 0.1336\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 2.2926 - accuracy: 0.1220 - val_loss: 2.2142 - val_accuracy: 0.1652\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 456us/step - loss: 1.3351 - accuracy: 0.4631 - val_loss: 0.8300 - val_accuracy: 0.7072\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 0.9293 - accuracy: 0.6489 - val_loss: 0.7421 - val_accuracy: 0.7240\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 0.8250 - accuracy: 0.6909 - val_loss: 0.6411 - val_accuracy: 0.7670\n",
      "18334/18334 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 467us/step - loss: 2.3025 - accuracy: 0.1079 - val_loss: 2.3016 - val_accuracy: 0.2222\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 2.2993 - accuracy: 0.1496 - val_loss: 2.2932 - val_accuracy: 0.2910\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 1.8150 - accuracy: 0.3151 - val_loss: 1.0326 - val_accuracy: 0.5418\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 1.0299 - accuracy: 0.6014 - val_loss: 0.8308 - val_accuracy: 0.6622\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 0.8638 - accuracy: 0.6702 - val_loss: 0.6706 - val_accuracy: 0.7602\n",
      "18333/18333 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 2.3026 - accuracy: 0.1016 - val_loss: 2.3022 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3001 - val_accuracy: 0.0986\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 452us/step - loss: 2.2587 - accuracy: 0.1718 - val_loss: 1.5855 - val_accuracy: 0.3686\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 1.2105 - accuracy: 0.5103 - val_loss: 0.8203 - val_accuracy: 0.6774\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 456us/step - loss: 0.9152 - accuracy: 0.6493 - val_loss: 0.6994 - val_accuracy: 0.7304\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 464us/step - loss: 2.3016 - accuracy: 0.1084 - val_loss: 2.2988 - val_accuracy: 0.1134\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 2.0114 - accuracy: 0.2219 - val_loss: 1.0794 - val_accuracy: 0.5724\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 1.0843 - accuracy: 0.5717 - val_loss: 0.8685 - val_accuracy: 0.6938\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 458us/step - loss: 0.8880 - accuracy: 0.6672 - val_loss: 0.7006 - val_accuracy: 0.7216\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 0.8032 - accuracy: 0.7033 - val_loss: 0.6382 - val_accuracy: 0.7626\n",
      "18334/18334 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 467us/step - loss: 2.3022 - accuracy: 0.1013 - val_loss: 2.3008 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 2.2927 - accuracy: 0.1476 - val_loss: 2.2166 - val_accuracy: 0.3280\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 1.3261 - accuracy: 0.4698 - val_loss: 0.8537 - val_accuracy: 0.6788\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 476us/step - loss: 0.9345 - accuracy: 0.6441 - val_loss: 0.7235 - val_accuracy: 0.7214\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 18s 478us/step - loss: 0.8293 - accuracy: 0.6866 - val_loss: 0.6884 - val_accuracy: 0.7556\n",
      "18333/18333 [==============================] - 3s 146us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 492us/step - loss: 2.3019 - accuracy: 0.1097 - val_loss: 2.3005 - val_accuracy: 0.1388\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 18s 481us/step - loss: 2.1440 - accuracy: 0.2060 - val_loss: 1.2578 - val_accuracy: 0.4374\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 18s 478us/step - loss: 1.1210 - accuracy: 0.5560 - val_loss: 0.7722 - val_accuracy: 0.7022\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 472us/step - loss: 0.8912 - accuracy: 0.6614 - val_loss: 0.6901 - val_accuracy: 0.7390\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 0.8042 - accuracy: 0.7033 - val_loss: 0.6118 - val_accuracy: 0.7728\n",
      "18333/18333 [==============================] - 3s 156us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 466us/step - loss: 2.3017 - accuracy: 0.1202 - val_loss: 2.2995 - val_accuracy: 0.2034\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 2.0779 - accuracy: 0.2138 - val_loss: 1.1586 - val_accuracy: 0.5264\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 1.0883 - accuracy: 0.5689 - val_loss: 0.7653 - val_accuracy: 0.6988\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 0.8861 - accuracy: 0.6665 - val_loss: 0.7130 - val_accuracy: 0.7270\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 0.8010 - accuracy: 0.7043 - val_loss: 0.6242 - val_accuracy: 0.7598\n",
      "18334/18334 [==============================] - 3s 153us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 465us/step - loss: 2.3018 - accuracy: 0.1066 - val_loss: 2.2996 - val_accuracy: 0.1008\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.2277 - accuracy: 0.1851 - val_loss: 1.3475 - val_accuracy: 0.4166\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.1492 - accuracy: 0.5339 - val_loss: 0.8130 - val_accuracy: 0.7134\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.8877 - accuracy: 0.6662 - val_loss: 0.6719 - val_accuracy: 0.7484\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.7939 - accuracy: 0.7058 - val_loss: 0.6291 - val_accuracy: 0.7568\n",
      "18333/18333 [==============================] - 3s 156us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 2.3021 - accuracy: 0.1031 - val_loss: 2.3011 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 2.2949 - accuracy: 0.1556 - val_loss: 2.2630 - val_accuracy: 0.2012\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.4121 - accuracy: 0.4399 - val_loss: 0.8872 - val_accuracy: 0.6798\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 455us/step - loss: 0.9503 - accuracy: 0.6315 - val_loss: 0.7273 - val_accuracy: 0.7112\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 455us/step - loss: 0.8453 - accuracy: 0.6818 - val_loss: 0.6725 - val_accuracy: 0.7456\n",
      "18333/18333 [==============================] - 3s 153us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 471us/step - loss: 2.3020 - accuracy: 0.1077 - val_loss: 2.3003 - val_accuracy: 0.0980\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 464us/step - loss: 2.0890 - accuracy: 0.1982 - val_loss: 1.1317 - val_accuracy: 0.4926\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 1.0939 - accuracy: 0.5659 - val_loss: 0.8068 - val_accuracy: 0.6958\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 463us/step - loss: 0.8953 - accuracy: 0.6628 - val_loss: 0.7183 - val_accuracy: 0.7372\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 464us/step - loss: 0.8041 - accuracy: 0.7031 - val_loss: 0.6412 - val_accuracy: 0.7592\n",
      "18334/18334 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 474us/step - loss: 2.3021 - accuracy: 0.1079 - val_loss: 2.3011 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.2964 - accuracy: 0.1305 - val_loss: 2.2690 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 1.4525 - accuracy: 0.4236 - val_loss: 0.8589 - val_accuracy: 0.6450\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 0.9439 - accuracy: 0.6374 - val_loss: 0.7204 - val_accuracy: 0.7402\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 0.8280 - accuracy: 0.6914 - val_loss: 0.6394 - val_accuracy: 0.7642\n",
      "18333/18333 [==============================] - 3s 156us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 468us/step - loss: 2.3018 - accuracy: 0.1064 - val_loss: 2.2999 - val_accuracy: 0.0980\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 2.0482 - accuracy: 0.2196 - val_loss: 1.1476 - val_accuracy: 0.5170\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 1.0748 - accuracy: 0.5744 - val_loss: 0.7733 - val_accuracy: 0.7000\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 463us/step - loss: 0.8819 - accuracy: 0.6649 - val_loss: 0.6788 - val_accuracy: 0.7492\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 0.7962 - accuracy: 0.7041 - val_loss: 0.6104 - val_accuracy: 0.7736\n",
      "18333/18333 [==============================] - 3s 158us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 466us/step - loss: 2.3021 - accuracy: 0.1027 - val_loss: 2.3008 - val_accuracy: 0.0982\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 467us/step - loss: 2.2067 - accuracy: 0.1630 - val_loss: 1.3518 - val_accuracy: 0.4238\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 1.1603 - accuracy: 0.5350 - val_loss: 0.8511 - val_accuracy: 0.6596\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 0.9083 - accuracy: 0.6575 - val_loss: 0.6976 - val_accuracy: 0.7368\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 467us/step - loss: 0.8065 - accuracy: 0.6988 - val_loss: 0.6296 - val_accuracy: 0.7714\n",
      "18334/18334 [==============================] - 3s 146us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 487us/step - loss: 2.3021 - accuracy: 0.1054 - val_loss: 2.3009 - val_accuracy: 0.1008\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 18s 479us/step - loss: 2.2571 - accuracy: 0.1293 - val_loss: 1.6501 - val_accuracy: 0.3612\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 18s 479us/step - loss: 1.2388 - accuracy: 0.4971 - val_loss: 0.9048 - val_accuracy: 0.6208\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 18s 481us/step - loss: 0.9313 - accuracy: 0.6462 - val_loss: 0.7331 - val_accuracy: 0.7356\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 18s 486us/step - loss: 0.8328 - accuracy: 0.6895 - val_loss: 0.6494 - val_accuracy: 0.7542\n",
      "18333/18333 [==============================] - 3s 146us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 465us/step - loss: 2.3019 - accuracy: 0.1069 - val_loss: 2.3002 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 2.1740 - accuracy: 0.1814 - val_loss: 1.2479 - val_accuracy: 0.4340\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 1.1671 - accuracy: 0.5250 - val_loss: 0.8538 - val_accuracy: 0.6818\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.9248 - accuracy: 0.6446 - val_loss: 0.7135 - val_accuracy: 0.7462\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 0.8263 - accuracy: 0.6916 - val_loss: 0.6521 - val_accuracy: 0.7520\n",
      "18333/18333 [==============================] - 3s 155us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 470us/step - loss: 2.3024 - accuracy: 0.1028 - val_loss: 2.3012 - val_accuracy: 0.1002\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 2.2963 - accuracy: 0.1387 - val_loss: 2.2668 - val_accuracy: 0.1976\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 1.3977 - accuracy: 0.4456 - val_loss: 0.8841 - val_accuracy: 0.6602\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 458us/step - loss: 0.9511 - accuracy: 0.6416 - val_loss: 0.7265 - val_accuracy: 0.7298\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 0.8411 - accuracy: 0.6914 - val_loss: 0.6529 - val_accuracy: 0.7558\n",
      "18334/18334 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 468us/step - loss: 2.3022 - accuracy: 0.1043 - val_loss: 2.3010 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 2.2963 - accuracy: 0.1496 - val_loss: 2.2717 - val_accuracy: 0.2620\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 1.4116 - accuracy: 0.4431 - val_loss: 0.9102 - val_accuracy: 0.6508\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.9361 - accuracy: 0.6390 - val_loss: 0.7447 - val_accuracy: 0.7152\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 0.8328 - accuracy: 0.6840 - val_loss: 0.6578 - val_accuracy: 0.7582\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 477us/step - loss: 2.3021 - accuracy: 0.1028 - val_loss: 2.3008 - val_accuracy: 0.1278\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 454us/step - loss: 2.2647 - accuracy: 0.1509 - val_loss: 1.6663 - val_accuracy: 0.4294\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.1917 - accuracy: 0.5224 - val_loss: 0.8102 - val_accuracy: 0.7020\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 454us/step - loss: 0.9116 - accuracy: 0.6541 - val_loss: 0.7306 - val_accuracy: 0.7300\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.8182 - accuracy: 0.6953 - val_loss: 0.6375 - val_accuracy: 0.7564\n",
      "18333/18333 [==============================] - 3s 158us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 466us/step - loss: 2.3013 - accuracy: 0.1158 - val_loss: 2.2969 - val_accuracy: 0.1224\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 456us/step - loss: 1.7681 - accuracy: 0.3083 - val_loss: 1.0304 - val_accuracy: 0.5976\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 461us/step - loss: 1.0009 - accuracy: 0.6114 - val_loss: 0.7721 - val_accuracy: 0.7010\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 0.8528 - accuracy: 0.6837 - val_loss: 0.6925 - val_accuracy: 0.7444\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 0.7714 - accuracy: 0.7173 - val_loss: 0.6238 - val_accuracy: 0.7708\n",
      "18334/18334 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 2.3011 - accuracy: 0.1126 - val_loss: 2.2974 - val_accuracy: 0.1008\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 1.9107 - accuracy: 0.2803 - val_loss: 1.0905 - val_accuracy: 0.5424\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.0382 - accuracy: 0.5947 - val_loss: 0.7643 - val_accuracy: 0.7154\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 0.8672 - accuracy: 0.6753 - val_loss: 0.6758 - val_accuracy: 0.7456\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.7815 - accuracy: 0.7100 - val_loss: 0.6249 - val_accuracy: 0.7672\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 468us/step - loss: 2.3018 - accuracy: 0.1138 - val_loss: 2.2999 - val_accuracy: 0.1766\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.0405 - accuracy: 0.2290 - val_loss: 1.1228 - val_accuracy: 0.5652\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.0777 - accuracy: 0.5713 - val_loss: 0.7746 - val_accuracy: 0.7114\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 0.8795 - accuracy: 0.6627 - val_loss: 0.7030 - val_accuracy: 0.7354\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.8030 - accuracy: 0.7009 - val_loss: 0.6281 - val_accuracy: 0.7634\n",
      "18333/18333 [==============================] - 3s 155us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 467us/step - loss: 2.3020 - accuracy: 0.1048 - val_loss: 2.3008 - val_accuracy: 0.1212\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 472us/step - loss: 2.2261 - accuracy: 0.1448 - val_loss: 1.3181 - val_accuracy: 0.4750\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 18s 485us/step - loss: 1.1530 - accuracy: 0.5383 - val_loss: 0.7875 - val_accuracy: 0.7002\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 475us/step - loss: 0.8986 - accuracy: 0.6628 - val_loss: 0.7363 - val_accuracy: 0.7350\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 18s 479us/step - loss: 0.8060 - accuracy: 0.7034 - val_loss: 0.6456 - val_accuracy: 0.7568\n",
      "18334/18334 [==============================] - 3s 149us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 492us/step - loss: 2.3014 - accuracy: 0.1105 - val_loss: 2.2977 - val_accuracy: 0.1264\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 473us/step - loss: 1.8371 - accuracy: 0.2867 - val_loss: 1.0326 - val_accuracy: 0.6160\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 1.0254 - accuracy: 0.6025 - val_loss: 0.7725 - val_accuracy: 0.7268\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 0.8668 - accuracy: 0.6749 - val_loss: 0.6828 - val_accuracy: 0.7322\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.7958 - accuracy: 0.7046 - val_loss: 0.6218 - val_accuracy: 0.7594\n",
      "18333/18333 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 475us/step - loss: 2.3022 - accuracy: 0.1048 - val_loss: 2.3016 - val_accuracy: 0.1922\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 2.2989 - accuracy: 0.1377 - val_loss: 2.2891 - val_accuracy: 0.2576\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 1.5852 - accuracy: 0.3887 - val_loss: 0.9478 - val_accuracy: 0.6518\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 0.9655 - accuracy: 0.6306 - val_loss: 0.7265 - val_accuracy: 0.7328\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 0.8389 - accuracy: 0.6839 - val_loss: 0.6719 - val_accuracy: 0.7402\n",
      "18333/18333 [==============================] - 3s 155us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 470us/step - loss: 2.3022 - accuracy: 0.1087 - val_loss: 2.3011 - val_accuracy: 0.1162\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 461us/step - loss: 2.2828 - accuracy: 0.1583 - val_loss: 2.0165 - val_accuracy: 0.2088\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 463us/step - loss: 1.2514 - accuracy: 0.4911 - val_loss: 0.8474 - val_accuracy: 0.6808\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 461us/step - loss: 0.9174 - accuracy: 0.6528 - val_loss: 0.7300 - val_accuracy: 0.7012\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 463us/step - loss: 0.8210 - accuracy: 0.6969 - val_loss: 0.6950 - val_accuracy: 0.7546\n",
      "18334/18334 [==============================] - 3s 156us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 471us/step - loss: 2.3020 - accuracy: 0.1062 - val_loss: 2.3000 - val_accuracy: 0.1008\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 2.1424 - accuracy: 0.2006 - val_loss: 1.1618 - val_accuracy: 0.5306\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.1272 - accuracy: 0.5455 - val_loss: 0.8032 - val_accuracy: 0.7094\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 463us/step - loss: 0.8990 - accuracy: 0.6594 - val_loss: 0.7382 - val_accuracy: 0.7298\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 465us/step - loss: 0.8140 - accuracy: 0.6969 - val_loss: 0.6717 - val_accuracy: 0.7386\n",
      "18333/18333 [==============================] - 3s 153us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 467us/step - loss: 2.3019 - accuracy: 0.1138 - val_loss: 2.3006 - val_accuracy: 0.0914\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 2.1107 - accuracy: 0.1898 - val_loss: 1.1514 - val_accuracy: 0.5766\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.1005 - accuracy: 0.5613 - val_loss: 0.7672 - val_accuracy: 0.7062\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 0.8935 - accuracy: 0.6582 - val_loss: 0.6834 - val_accuracy: 0.7444\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 0.8046 - accuracy: 0.6977 - val_loss: 0.6736 - val_accuracy: 0.7518\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 469us/step - loss: 2.3012 - accuracy: 0.1226 - val_loss: 2.2975 - val_accuracy: 0.3558\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 461us/step - loss: 1.8593 - accuracy: 0.3021 - val_loss: 0.9543 - val_accuracy: 0.6154\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 0.9944 - accuracy: 0.6152 - val_loss: 0.8237 - val_accuracy: 0.6986\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 0.8547 - accuracy: 0.6802 - val_loss: 0.7164 - val_accuracy: 0.7236\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 0.7865 - accuracy: 0.7116 - val_loss: 0.6178 - val_accuracy: 0.7712\n",
      "18334/18334 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 469us/step - loss: 2.3023 - accuracy: 0.1076 - val_loss: 2.3014 - val_accuracy: 0.1574\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 2.2978 - accuracy: 0.1451 - val_loss: 2.2818 - val_accuracy: 0.2630\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.4998 - accuracy: 0.4155 - val_loss: 0.8670 - val_accuracy: 0.6640\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.9518 - accuracy: 0.6374 - val_loss: 0.7371 - val_accuracy: 0.7222\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 456us/step - loss: 0.8354 - accuracy: 0.6900 - val_loss: 0.6489 - val_accuracy: 0.7654\n",
      "18333/18333 [==============================] - 3s 153us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 466us/step - loss: 2.3022 - accuracy: 0.1052 - val_loss: 2.3013 - val_accuracy: 0.1974\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 2.2967 - accuracy: 0.1477 - val_loss: 2.2761 - val_accuracy: 0.3372\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 468us/step - loss: 1.4519 - accuracy: 0.4314 - val_loss: 0.8787 - val_accuracy: 0.6692\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 18s 483us/step - loss: 0.9336 - accuracy: 0.6404 - val_loss: 0.7489 - val_accuracy: 0.7152\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 18s 483us/step - loss: 0.8245 - accuracy: 0.6882 - val_loss: 0.6723 - val_accuracy: 0.7608\n",
      "18333/18333 [==============================] - 3s 146us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 18s 484us/step - loss: 2.3020 - accuracy: 0.1043 - val_loss: 2.3008 - val_accuracy: 0.0976\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 18s 481us/step - loss: 2.2425 - accuracy: 0.1613 - val_loss: 1.4947 - val_accuracy: 0.4408\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 477us/step - loss: 1.1826 - accuracy: 0.5234 - val_loss: 0.8529 - val_accuracy: 0.6684\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 467us/step - loss: 0.9053 - accuracy: 0.6586 - val_loss: 0.7011 - val_accuracy: 0.7334\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 0.8122 - accuracy: 0.6976 - val_loss: 0.6495 - val_accuracy: 0.7554\n",
      "18334/18334 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 467us/step - loss: 2.3020 - accuracy: 0.1083 - val_loss: 2.3004 - val_accuracy: 0.1008\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 451us/step - loss: 2.2812 - accuracy: 0.1590 - val_loss: 1.8942 - val_accuracy: 0.3318\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 455us/step - loss: 1.2416 - accuracy: 0.4969 - val_loss: 0.8032 - val_accuracy: 0.6990\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 0.9300 - accuracy: 0.6426 - val_loss: 0.7103 - val_accuracy: 0.7338\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 0.8267 - accuracy: 0.6891 - val_loss: 0.6586 - val_accuracy: 0.7488\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 2.3015 - accuracy: 0.1076 - val_loss: 2.2989 - val_accuracy: 0.1222\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 1.9427 - accuracy: 0.2411 - val_loss: 1.1350 - val_accuracy: 0.5588\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 1.0739 - accuracy: 0.5755 - val_loss: 0.7681 - val_accuracy: 0.7014\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.8778 - accuracy: 0.6651 - val_loss: 0.6893 - val_accuracy: 0.7354\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.7966 - accuracy: 0.7000 - val_loss: 0.6354 - val_accuracy: 0.7590\n",
      "18333/18333 [==============================] - 3s 153us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 2.3024 - accuracy: 0.1021 - val_loss: 2.3018 - val_accuracy: 0.0980\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 2.2998 - accuracy: 0.1314 - val_loss: 2.2942 - val_accuracy: 0.1864\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 459us/step - loss: 1.7818 - accuracy: 0.3259 - val_loss: 1.0883 - val_accuracy: 0.5394\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 457us/step - loss: 1.0253 - accuracy: 0.5993 - val_loss: 0.7734 - val_accuracy: 0.6878\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 458us/step - loss: 0.8664 - accuracy: 0.6740 - val_loss: 0.6802 - val_accuracy: 0.7542\n",
      "18334/18334 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 468us/step - loss: 2.3022 - accuracy: 0.1056 - val_loss: 2.3013 - val_accuracy: 0.0976\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 455us/step - loss: 2.2959 - accuracy: 0.1519 - val_loss: 2.2711 - val_accuracy: 0.3000\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 1.4163 - accuracy: 0.4387 - val_loss: 0.8977 - val_accuracy: 0.6450\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 0.9416 - accuracy: 0.6361 - val_loss: 0.7646 - val_accuracy: 0.7030\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 0.8371 - accuracy: 0.6848 - val_loss: 0.6743 - val_accuracy: 0.7344\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 468us/step - loss: 2.3016 - accuracy: 0.1118 - val_loss: 2.2986 - val_accuracy: 0.1416\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.9524 - accuracy: 0.2576 - val_loss: 1.0929 - val_accuracy: 0.5044\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 1.0817 - accuracy: 0.5727 - val_loss: 0.7847 - val_accuracy: 0.6818\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.8890 - accuracy: 0.6611 - val_loss: 0.7044 - val_accuracy: 0.7500\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 0.8044 - accuracy: 0.6994 - val_loss: 0.6447 - val_accuracy: 0.7516\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 468us/step - loss: 2.3016 - accuracy: 0.1050 - val_loss: 2.2998 - val_accuracy: 0.2256\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 458us/step - loss: 2.1039 - accuracy: 0.2227 - val_loss: 1.1129 - val_accuracy: 0.5398\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 456us/step - loss: 1.0921 - accuracy: 0.5676 - val_loss: 0.7942 - val_accuracy: 0.6998\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 0.8909 - accuracy: 0.6635 - val_loss: 0.6937 - val_accuracy: 0.7518\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 458us/step - loss: 0.8004 - accuracy: 0.7064 - val_loss: 0.6373 - val_accuracy: 0.7606\n",
      "18334/18334 [==============================] - 3s 154us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 466us/step - loss: 2.3024 - accuracy: 0.1027 - val_loss: 2.3017 - val_accuracy: 0.0976\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 2.2983 - accuracy: 0.1227 - val_loss: 2.2843 - val_accuracy: 0.1454\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 1.5217 - accuracy: 0.3989 - val_loss: 0.9374 - val_accuracy: 0.6446\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 0.9620 - accuracy: 0.6287 - val_loss: 0.7299 - val_accuracy: 0.7304\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 466us/step - loss: 0.8383 - accuracy: 0.6837 - val_loss: 0.7004 - val_accuracy: 0.7352\n",
      "18333/18333 [==============================] - 3s 148us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 18s 495us/step - loss: 2.3021 - accuracy: 0.1070 - val_loss: 2.3011 - val_accuracy: 0.1956\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 18s 486us/step - loss: 2.2809 - accuracy: 0.1613 - val_loss: 1.9390 - val_accuracy: 0.2270\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 18s 485us/step - loss: 1.2573 - accuracy: 0.4892 - val_loss: 0.8383 - val_accuracy: 0.6754\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 477us/step - loss: 0.9288 - accuracy: 0.6430 - val_loss: 0.7312 - val_accuracy: 0.7268\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 18s 483us/step - loss: 0.8298 - accuracy: 0.6892 - val_loss: 0.6461 - val_accuracy: 0.7586\n",
      "18333/18333 [==============================] - 3s 155us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36666/36666 [==============================] - 17s 467us/step - loss: 2.3022 - accuracy: 0.1073 - val_loss: 2.3013 - val_accuracy: 0.0980\n",
      "Epoch 2/5\n",
      "36666/36666 [==============================] - 17s 464us/step - loss: 2.2934 - accuracy: 0.1341 - val_loss: 2.2255 - val_accuracy: 0.1898\n",
      "Epoch 3/5\n",
      "36666/36666 [==============================] - 17s 460us/step - loss: 1.3087 - accuracy: 0.4779 - val_loss: 0.8523 - val_accuracy: 0.6394\n",
      "Epoch 4/5\n",
      "36666/36666 [==============================] - 17s 463us/step - loss: 0.9168 - accuracy: 0.6496 - val_loss: 0.7180 - val_accuracy: 0.7354\n",
      "Epoch 5/5\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 0.8156 - accuracy: 0.6969 - val_loss: 0.6473 - val_accuracy: 0.7632\n",
      "18334/18334 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 469us/step - loss: 2.3005 - accuracy: 0.1157 - val_loss: 2.2928 - val_accuracy: 0.0968\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 1.6241 - accuracy: 0.3591 - val_loss: 0.9841 - val_accuracy: 0.6146\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 0.9880 - accuracy: 0.6237 - val_loss: 0.7823 - val_accuracy: 0.6660\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 0.8565 - accuracy: 0.6776 - val_loss: 0.7041 - val_accuracy: 0.7494\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 458us/step - loss: 0.7862 - accuracy: 0.7083 - val_loss: 0.6610 - val_accuracy: 0.7560\n",
      "18333/18333 [==============================] - 3s 155us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "36667/36667 [==============================] - 17s 465us/step - loss: 2.3016 - accuracy: 0.1162 - val_loss: 2.2993 - val_accuracy: 0.0986\n",
      "Epoch 2/5\n",
      "36667/36667 [==============================] - 17s 457us/step - loss: 1.9895 - accuracy: 0.2300 - val_loss: 1.1682 - val_accuracy: 0.5014\n",
      "Epoch 3/5\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.0507 - accuracy: 0.5867 - val_loss: 0.7692 - val_accuracy: 0.7078\n",
      "Epoch 4/5\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 0.8767 - accuracy: 0.6672 - val_loss: 0.6979 - val_accuracy: 0.7198\n",
      "Epoch 5/5\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 0.7904 - accuracy: 0.7057 - val_loss: 0.6463 - val_accuracy: 0.7636\n",
      "18333/18333 [==============================] - 3s 154us/step\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 25s 458us/step - loss: 2.3002 - accuracy: 0.1213 - val_loss: 2.2892 - val_accuracy: 0.1902\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 25s 452us/step - loss: 1.4347 - accuracy: 0.4373 - val_loss: 0.8126 - val_accuracy: 0.7180\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 25s 453us/step - loss: 0.8734 - accuracy: 0.6699 - val_loss: 0.6502 - val_accuracy: 0.7646\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 25s 454us/step - loss: 0.7423 - accuracy: 0.7260 - val_loss: 0.5735 - val_accuracy: 0.7876\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 25s 452us/step - loss: 0.6559 - accuracy: 0.7589 - val_loss: 0.5133 - val_accuracy: 0.8090\n"
     ]
    }
   ],
   "source": [
    "reguls = [keras.regularizers.l1(0.1),\n",
    "          keras.regularizers.l2(0.1),\n",
    "          keras.regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "          None]\n",
    "\n",
    "param_distribs= {'k_regularizer': reguls, 'b_regularizer': reguls}\n",
    "\n",
    "grid_search_cv = gridSearch(param_distribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_b_regularizer</th>\n",
       "      <th>param_k_regularizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.945315</td>\n",
       "      <td>1.415069</td>\n",
       "      <td>2.806189</td>\n",
       "      <td>0.067548</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.746918</td>\n",
       "      <td>0.749359</td>\n",
       "      <td>0.749632</td>\n",
       "      <td>0.748636</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.299483</td>\n",
       "      <td>0.538223</td>\n",
       "      <td>2.879767</td>\n",
       "      <td>0.046586</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.761809</td>\n",
       "      <td>0.745432</td>\n",
       "      <td>0.714122</td>\n",
       "      <td>0.740455</td>\n",
       "      <td>0.019784</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.983120</td>\n",
       "      <td>0.272393</td>\n",
       "      <td>2.832187</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.750627</td>\n",
       "      <td>0.752195</td>\n",
       "      <td>0.726668</td>\n",
       "      <td>0.743164</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86.467123</td>\n",
       "      <td>1.286640</td>\n",
       "      <td>2.791273</td>\n",
       "      <td>0.079044</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.746155</td>\n",
       "      <td>0.747723</td>\n",
       "      <td>0.762723</td>\n",
       "      <td>0.752200</td>\n",
       "      <td>0.007468</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85.014216</td>\n",
       "      <td>0.162053</td>\n",
       "      <td>2.827686</td>\n",
       "      <td>0.024586</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.745009</td>\n",
       "      <td>0.751541</td>\n",
       "      <td>0.743632</td>\n",
       "      <td>0.746727</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86.078514</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>2.868180</td>\n",
       "      <td>0.023208</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.746973</td>\n",
       "      <td>0.755414</td>\n",
       "      <td>0.763214</td>\n",
       "      <td>0.755200</td>\n",
       "      <td>0.006632</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>86.696264</td>\n",
       "      <td>1.741499</td>\n",
       "      <td>2.737960</td>\n",
       "      <td>0.076512</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.754718</td>\n",
       "      <td>0.749086</td>\n",
       "      <td>0.747395</td>\n",
       "      <td>0.750400</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>85.288492</td>\n",
       "      <td>0.109034</td>\n",
       "      <td>2.852799</td>\n",
       "      <td>0.033701</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.740428</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.752250</td>\n",
       "      <td>0.748200</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>85.073678</td>\n",
       "      <td>0.071879</td>\n",
       "      <td>2.839336</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.758855</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>87.131565</td>\n",
       "      <td>0.726458</td>\n",
       "      <td>2.806279</td>\n",
       "      <td>0.049881</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.737537</td>\n",
       "      <td>0.748486</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>0.739636</td>\n",
       "      <td>0.006539</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>85.790324</td>\n",
       "      <td>0.129975</td>\n",
       "      <td>2.838182</td>\n",
       "      <td>0.023844</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.743918</td>\n",
       "      <td>0.732613</td>\n",
       "      <td>0.751541</td>\n",
       "      <td>0.742691</td>\n",
       "      <td>0.007776</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>85.984047</td>\n",
       "      <td>0.931500</td>\n",
       "      <td>2.778179</td>\n",
       "      <td>0.070093</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'b_regularizer': &lt;keras.regularizers.L1L2 obj...</td>\n",
       "      <td>0.760227</td>\n",
       "      <td>0.758196</td>\n",
       "      <td>0.751214</td>\n",
       "      <td>0.756545</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>85.852745</td>\n",
       "      <td>1.212530</td>\n",
       "      <td>2.827821</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': None, 'k_regularizer': &lt;kera...</td>\n",
       "      <td>0.741628</td>\n",
       "      <td>0.738450</td>\n",
       "      <td>0.752632</td>\n",
       "      <td>0.744236</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>85.245498</td>\n",
       "      <td>0.116453</td>\n",
       "      <td>2.829617</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': None, 'k_regularizer': &lt;kera...</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.731850</td>\n",
       "      <td>0.743250</td>\n",
       "      <td>0.737655</td>\n",
       "      <td>0.004656</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>87.054172</td>\n",
       "      <td>2.306236</td>\n",
       "      <td>2.792671</td>\n",
       "      <td>0.060573</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;keras.regularizers.L1L2 object at 0x7f9e6473c...</td>\n",
       "      <td>{'b_regularizer': None, 'k_regularizer': &lt;kera...</td>\n",
       "      <td>0.749155</td>\n",
       "      <td>0.729231</td>\n",
       "      <td>0.752959</td>\n",
       "      <td>0.743782</td>\n",
       "      <td>0.010405</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>85.539653</td>\n",
       "      <td>0.186025</td>\n",
       "      <td>2.837972</td>\n",
       "      <td>0.010301</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'b_regularizer': None, 'k_regularizer': None}</td>\n",
       "      <td>0.749264</td>\n",
       "      <td>0.746959</td>\n",
       "      <td>0.752359</td>\n",
       "      <td>0.749527</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       86.945315      1.415069         2.806189        0.067548   \n",
       "1       86.299483      0.538223         2.879767        0.046586   \n",
       "2       84.983120      0.272393         2.832187        0.006071   \n",
       "3       86.467123      1.286640         2.791273        0.079044   \n",
       "4       85.014216      0.162053         2.827686        0.024586   \n",
       "5       86.078514      0.723618         2.868180        0.023208   \n",
       "6       86.696264      1.741499         2.737960        0.076512   \n",
       "7       85.288492      0.109034         2.852799        0.033701   \n",
       "8       85.073678      0.071879         2.839336        0.009460   \n",
       "9       87.131565      0.726458         2.806279        0.049881   \n",
       "10      85.790324      0.129975         2.838182        0.023844   \n",
       "11      85.984047      0.931500         2.778179        0.070093   \n",
       "12      85.852745      1.212530         2.827821        0.011188   \n",
       "13      85.245498      0.116453         2.829617        0.006690   \n",
       "14      87.054172      2.306236         2.792671        0.060573   \n",
       "15      85.539653      0.186025         2.837972        0.010301   \n",
       "\n",
       "                                  param_b_regularizer  \\\n",
       "0   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "1   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "2   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "3   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "4   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "5   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "6   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "7   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "8   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "9   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "10  <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "11  <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "12                                               None   \n",
       "13                                               None   \n",
       "14                                               None   \n",
       "15                                               None   \n",
       "\n",
       "                                  param_k_regularizer  \\\n",
       "0   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "1   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "2   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "3                                                None   \n",
       "4   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "5   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "6   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "7                                                None   \n",
       "8   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "9   <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "10  <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "11                                               None   \n",
       "12  <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "13  <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "14  <keras.regularizers.L1L2 object at 0x7f9e6473c...   \n",
       "15                                               None   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'b_regularizer': <keras.regularizers.L1L2 obj...           0.746918   \n",
       "1   {'b_regularizer': <keras.regularizers.L1L2 obj...           0.761809   \n",
       "2   {'b_regularizer': <keras.regularizers.L1L2 obj...           0.750627   \n",
       "3   {'b_regularizer': <keras.regularizers.L1L2 obj...           0.746155   \n",
       "4   {'b_regularizer': <keras.regularizers.L1L2 obj...           0.745009   \n",
       "5   {'b_regularizer': <keras.regularizers.L1L2 obj...           0.746973   \n",
       "6   {'b_regularizer': <keras.regularizers.L1L2 obj...           0.754718   \n",
       "7   {'b_regularizer': <keras.regularizers.L1L2 obj...           0.740428   \n",
       "8   {'b_regularizer': <keras.regularizers.L1L2 obj...           0.757009   \n",
       "9   {'b_regularizer': <keras.regularizers.L1L2 obj...           0.737537   \n",
       "10  {'b_regularizer': <keras.regularizers.L1L2 obj...           0.743918   \n",
       "11  {'b_regularizer': <keras.regularizers.L1L2 obj...           0.760227   \n",
       "12  {'b_regularizer': None, 'k_regularizer': <kera...           0.741628   \n",
       "13  {'b_regularizer': None, 'k_regularizer': <kera...           0.737864   \n",
       "14  {'b_regularizer': None, 'k_regularizer': <kera...           0.749155   \n",
       "15     {'b_regularizer': None, 'k_regularizer': None}           0.749264   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.749359           0.749632         0.748636        0.001220   \n",
       "1            0.745432           0.714122         0.740455        0.019784   \n",
       "2            0.752195           0.726668         0.743164        0.011682   \n",
       "3            0.747723           0.762723         0.752200        0.007468   \n",
       "4            0.751541           0.743632         0.746727        0.003450   \n",
       "5            0.755414           0.763214         0.755200        0.006632   \n",
       "6            0.749086           0.747395         0.750400        0.003130   \n",
       "7            0.751923           0.752250         0.748200        0.005498   \n",
       "8            0.759777           0.759777         0.758855        0.001305   \n",
       "9            0.748486           0.732886         0.739636        0.006539   \n",
       "10           0.732613           0.751541         0.742691        0.007776   \n",
       "11           0.758196           0.751214         0.756545        0.003860   \n",
       "12           0.738450           0.752632         0.744236        0.006077   \n",
       "13           0.731850           0.743250         0.737655        0.004656   \n",
       "14           0.729231           0.752959         0.743782        0.010405   \n",
       "15           0.746959           0.752359         0.749527        0.002212   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 7  \n",
       "1                14  \n",
       "2                12  \n",
       "3                 4  \n",
       "4                 9  \n",
       "5                 3  \n",
       "6                 5  \n",
       "7                 8  \n",
       "8                 1  \n",
       "9                15  \n",
       "10               13  \n",
       "11                2  \n",
       "12               10  \n",
       "13               16  \n",
       "14               11  \n",
       "15                6  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reguls_df = pd.DataFrame(grid_search_cv.cv_results_)\n",
    "reguls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b_regularizer': <keras.regularizers.L1L2 at 0x7f9e6473c250>,\n",
       " 'k_regularizer': <keras.regularizers.L1L2 at 0x7f9e6473cbd0>}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 161us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7906000018119812"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = grid_search_cv.best_estimator_\n",
    "est.score(preprocessing_image_for_cnn(Xf_test), yf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now; first, We will change model's hyper parameters and then we will change the structure of the model and observe the effects of this change.\n",
    "\n",
    "1. Initializers\n",
    "2. Activation functions\n",
    "3. Optimizers\n",
    "4. Regularizers\n",
    "\n",
    "Then;\n",
    "\n",
    "5. Number of Hidden Conv layers\n",
    "6. Initial Filter Size\n",
    "7. Number of Hidden Dense layers\n",
    "8. Number of Neurons\n",
    "9. Learning Rate\n",
    "\n",
    "Then using one of libraries for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yD1q7004oTPp"
   },
   "source": [
    "#### Building model with different structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QL_KF8vqoP5t",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def build_cnn_2(initial_filter_size=64, n_nidden_conv=2, n_hidden=1, n_neurons=30, learning_rate=3e-3):\n",
    "    k_initializer = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "    b_initializer =  keras.initializers.Zeros()\n",
    "    activation = \"tanh\"\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(initial_filter_size, 7, activation=activation, padding=\"same\", input_shape=[28, 28, 1],\n",
    "                            kernel_initializer=k_initializer, bias_initializer=b_initializer),\n",
    "        keras.layers.MaxPooling2D(2)])\n",
    "    for conv_layer in range(n_nidden_conv):\n",
    "        initial_filter_size *= 2\n",
    "        for n in range(2):\n",
    "            model.add(keras.layers.Conv2D(initial_filter_size, 3, activation=activation, padding=\"same\",\n",
    "                                      kernel_initializer=k_initializer, bias_initializer=b_initializer))\n",
    "        model.add( keras.layers.MaxPooling2D(2))\n",
    "        \n",
    "    model.add(keras.layers.Flatten())\n",
    "    subtraction = int(n_neurons/n_hidden)\n",
    "        \n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons-layer*subtraction, activation=activation))\n",
    "        model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=k_initializer, bias_initializer=b_initializer))\n",
    "    \n",
    "    # optimizer will be changed with the best one so far\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFEjBq3pGJIb",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 18s 497us/step - loss: 1.4722 - accuracy: 0.4262 - val_loss: 1.0182 - val_accuracy: 0.5948\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 18s 497us/step - loss: 1.1861 - accuracy: 0.5205 - val_loss: 0.9197 - val_accuracy: 0.6266\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 18s 489us/step - loss: 1.1039 - accuracy: 0.5604 - val_loss: 0.8472 - val_accuracy: 0.6856\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 17s 472us/step - loss: 1.0494 - accuracy: 0.5890 - val_loss: 0.7842 - val_accuracy: 0.6942\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 18s 481us/step - loss: 1.0106 - accuracy: 0.6195 - val_loss: 0.7487 - val_accuracy: 0.7080\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 14s 389us/step - loss: 0.9733 - accuracy: 0.6359 - val_loss: 0.7303 - val_accuracy: 0.7188\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 16s 426us/step - loss: 0.9344 - accuracy: 0.6492 - val_loss: 0.7100 - val_accuracy: 0.7262\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 18s 488us/step - loss: 0.9126 - accuracy: 0.6583 - val_loss: 0.6748 - val_accuracy: 0.7414\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 18s 481us/step - loss: 0.8907 - accuracy: 0.6715 - val_loss: 0.6583 - val_accuracy: 0.7470\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 18s 487us/step - loss: 0.8958 - accuracy: 0.6698 - val_loss: 0.6545 - val_accuracy: 0.7682\n",
      "18334/18334 [==============================] - 4s 197us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 18s 500us/step - loss: 1.4208 - accuracy: 0.4400 - val_loss: 0.9923 - val_accuracy: 0.5906\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 18s 497us/step - loss: 1.1262 - accuracy: 0.5352 - val_loss: 0.8868 - val_accuracy: 0.6444\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 18s 499us/step - loss: 1.0610 - accuracy: 0.5610 - val_loss: 0.8559 - val_accuracy: 0.6350\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 19s 506us/step - loss: 1.0231 - accuracy: 0.5801 - val_loss: 0.8095 - val_accuracy: 0.6514\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 19s 505us/step - loss: 0.9957 - accuracy: 0.5873 - val_loss: 0.7799 - val_accuracy: 0.6480\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 18s 497us/step - loss: 0.9863 - accuracy: 0.5886 - val_loss: 0.7682 - val_accuracy: 0.6648\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 18s 500us/step - loss: 0.9770 - accuracy: 0.5935 - val_loss: 0.7617 - val_accuracy: 0.6686\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 18s 488us/step - loss: 0.9422 - accuracy: 0.6134 - val_loss: 0.7323 - val_accuracy: 0.7210\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 18s 501us/step - loss: 0.9358 - accuracy: 0.6332 - val_loss: 0.6787 - val_accuracy: 0.7486\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 19s 508us/step - loss: 0.8942 - accuracy: 0.6564 - val_loss: 0.6587 - val_accuracy: 0.7484\n",
      "18333/18333 [==============================] - 4s 194us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 17s 472us/step - loss: 1.4620 - accuracy: 0.4229 - val_loss: 1.0325 - val_accuracy: 0.5754\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 15s 410us/step - loss: 1.1806 - accuracy: 0.5188 - val_loss: 0.9400 - val_accuracy: 0.6240\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 16s 436us/step - loss: 1.1338 - accuracy: 0.5472 - val_loss: 0.8987 - val_accuracy: 0.6382\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 14s 390us/step - loss: 1.0643 - accuracy: 0.5746 - val_loss: 0.8516 - val_accuracy: 0.6584\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 14s 393us/step - loss: 1.0536 - accuracy: 0.5820 - val_loss: 0.8052 - val_accuracy: 0.6946\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 18s 478us/step - loss: 1.0177 - accuracy: 0.5969 - val_loss: 0.8008 - val_accuracy: 0.6888\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 18s 481us/step - loss: 0.9923 - accuracy: 0.6039 - val_loss: 0.7785 - val_accuracy: 0.6980\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 18s 484us/step - loss: 0.9736 - accuracy: 0.6159 - val_loss: 0.7449 - val_accuracy: 0.7124\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 18s 480us/step - loss: 0.9636 - accuracy: 0.6239 - val_loss: 0.7503 - val_accuracy: 0.7078\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 18s 488us/step - loss: 0.9493 - accuracy: 0.6309 - val_loss: 0.7402 - val_accuracy: 0.7154\n",
      "18333/18333 [==============================] - 3s 191us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 11s 295us/step - loss: 0.5666 - accuracy: 0.8003 - val_loss: 0.3872 - val_accuracy: 0.8610\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 11s 289us/step - loss: 0.4342 - accuracy: 0.8460 - val_loss: 0.3550 - val_accuracy: 0.8716\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 11s 288us/step - loss: 0.4017 - accuracy: 0.8565 - val_loss: 0.3303 - val_accuracy: 0.8804\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 11s 288us/step - loss: 0.3792 - accuracy: 0.8655 - val_loss: 0.3158 - val_accuracy: 0.8866\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 10s 285us/step - loss: 0.3633 - accuracy: 0.8685 - val_loss: 0.3101 - val_accuracy: 0.8898\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 11s 289us/step - loss: 0.3574 - accuracy: 0.8724 - val_loss: 0.3056 - val_accuracy: 0.8928\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 11s 288us/step - loss: 0.3430 - accuracy: 0.8789 - val_loss: 0.2941 - val_accuracy: 0.8940\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 11s 288us/step - loss: 0.3357 - accuracy: 0.8821 - val_loss: 0.2826 - val_accuracy: 0.9010\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 11s 288us/step - loss: 0.3317 - accuracy: 0.8819 - val_loss: 0.2857 - val_accuracy: 0.8992\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 11s 289us/step - loss: 0.3272 - accuracy: 0.8834 - val_loss: 0.2789 - val_accuracy: 0.9000\n",
      "18334/18334 [==============================] - 2s 128us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 10s 283us/step - loss: 0.5873 - accuracy: 0.7872 - val_loss: 0.3932 - val_accuracy: 0.8568\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 10s 281us/step - loss: 0.4530 - accuracy: 0.8388 - val_loss: 0.3528 - val_accuracy: 0.8736\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 10s 281us/step - loss: 0.4158 - accuracy: 0.8516 - val_loss: 0.3310 - val_accuracy: 0.8810\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 10s 281us/step - loss: 0.3957 - accuracy: 0.8576 - val_loss: 0.3173 - val_accuracy: 0.8842\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 10s 280us/step - loss: 0.3831 - accuracy: 0.8629 - val_loss: 0.3088 - val_accuracy: 0.8878\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 10s 266us/step - loss: 0.3608 - accuracy: 0.8703 - val_loss: 0.2944 - val_accuracy: 0.8934\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 8s 232us/step - loss: 0.3545 - accuracy: 0.8726 - val_loss: 0.2987 - val_accuracy: 0.8918\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 9s 232us/step - loss: 0.3491 - accuracy: 0.8740 - val_loss: 0.2910 - val_accuracy: 0.8950\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 10s 281us/step - loss: 0.3441 - accuracy: 0.8767 - val_loss: 0.2903 - val_accuracy: 0.8896\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 10s 282us/step - loss: 0.3320 - accuracy: 0.8823 - val_loss: 0.2847 - val_accuracy: 0.8912\n",
      "18333/18333 [==============================] - 2s 128us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 10s 261us/step - loss: 0.5701 - accuracy: 0.7965 - val_loss: 0.3908 - val_accuracy: 0.8600\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 10s 272us/step - loss: 0.4340 - accuracy: 0.8444 - val_loss: 0.3455 - val_accuracy: 0.8762\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 7s 189us/step - loss: 0.3950 - accuracy: 0.8590 - val_loss: 0.3198 - val_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 11s 293us/step - loss: 0.3758 - accuracy: 0.8661 - val_loss: 0.3094 - val_accuracy: 0.8902\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 11s 293us/step - loss: 0.3617 - accuracy: 0.8699 - val_loss: 0.3095 - val_accuracy: 0.8892\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 11s 292us/step - loss: 0.3468 - accuracy: 0.8769 - val_loss: 0.3082 - val_accuracy: 0.8922\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 11s 293us/step - loss: 0.3412 - accuracy: 0.8780 - val_loss: 0.2963 - val_accuracy: 0.8934\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 11s 290us/step - loss: 0.3317 - accuracy: 0.8823 - val_loss: 0.2846 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 11s 292us/step - loss: 0.3325 - accuracy: 0.8820 - val_loss: 0.2810 - val_accuracy: 0.8986\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 11s 292us/step - loss: 0.3241 - accuracy: 0.8838 - val_loss: 0.2737 - val_accuracy: 0.9026\n",
      "18333/18333 [==============================] - 2s 123us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 12s 335us/step - loss: 0.8269 - accuracy: 0.7246 - val_loss: 0.4712 - val_accuracy: 0.8350\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 12s 335us/step - loss: 0.5443 - accuracy: 0.8186 - val_loss: 0.4014 - val_accuracy: 0.8560\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 12s 332us/step - loss: 0.4868 - accuracy: 0.8370 - val_loss: 0.3704 - val_accuracy: 0.8712\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 12s 335us/step - loss: 0.4500 - accuracy: 0.8513 - val_loss: 0.3532 - val_accuracy: 0.8758\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 12s 340us/step - loss: 0.4330 - accuracy: 0.8582 - val_loss: 0.3500 - val_accuracy: 0.8764\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 12s 338us/step - loss: 0.4185 - accuracy: 0.8632 - val_loss: 0.3246 - val_accuracy: 0.8820\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 12s 327us/step - loss: 0.4003 - accuracy: 0.8685 - val_loss: 0.3290 - val_accuracy: 0.8852\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 5s 141us/step - loss: 0.3967 - accuracy: 0.8688 - val_loss: 0.3324 - val_accuracy: 0.8804\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 5s 139us/step - loss: 0.3903 - accuracy: 0.8730 - val_loss: 0.3306 - val_accuracy: 0.8824\n",
      "18334/18334 [==============================] - 1s 55us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 5s 142us/step - loss: 0.8289 - accuracy: 0.7259 - val_loss: 0.4802 - val_accuracy: 0.8340\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 5s 136us/step - loss: 0.5525 - accuracy: 0.8083 - val_loss: 0.4003 - val_accuracy: 0.8602\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 5s 137us/step - loss: 0.4933 - accuracy: 0.8358 - val_loss: 0.3835 - val_accuracy: 0.8598\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 10s 277us/step - loss: 0.4630 - accuracy: 0.8422 - val_loss: 0.3594 - val_accuracy: 0.8706\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 12s 326us/step - loss: 0.4476 - accuracy: 0.8467 - val_loss: 0.3522 - val_accuracy: 0.8734\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 12s 325us/step - loss: 0.4287 - accuracy: 0.8557 - val_loss: 0.3312 - val_accuracy: 0.8782\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 12s 327us/step - loss: 0.4231 - accuracy: 0.8584 - val_loss: 0.3310 - val_accuracy: 0.8830\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 12s 336us/step - loss: 0.4054 - accuracy: 0.8656 - val_loss: 0.3205 - val_accuracy: 0.8864\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 10s 264us/step - loss: 0.3996 - accuracy: 0.8692 - val_loss: 0.3470 - val_accuracy: 0.8764\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 11s 301us/step - loss: 0.3909 - accuracy: 0.8730 - val_loss: 0.3119 - val_accuracy: 0.8896\n",
      "18333/18333 [==============================] - 1s 69us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 11s 302us/step - loss: 0.8647 - accuracy: 0.7162 - val_loss: 0.4970 - val_accuracy: 0.8302\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 12s 315us/step - loss: 0.5617 - accuracy: 0.8100 - val_loss: 0.4108 - val_accuracy: 0.8560\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 12s 334us/step - loss: 0.5051 - accuracy: 0.8316 - val_loss: 0.3885 - val_accuracy: 0.8684\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 9s 249us/step - loss: 0.4709 - accuracy: 0.8429 - val_loss: 0.3588 - val_accuracy: 0.8722\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 11s 300us/step - loss: 0.4501 - accuracy: 0.8502 - val_loss: 0.3633 - val_accuracy: 0.8742\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 6s 155us/step - loss: 0.4387 - accuracy: 0.8566 - val_loss: 0.3523 - val_accuracy: 0.8748\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 12s 324us/step - loss: 0.4275 - accuracy: 0.8588 - val_loss: 0.3559 - val_accuracy: 0.8768\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 12s 334us/step - loss: 0.4182 - accuracy: 0.8634 - val_loss: 0.3332 - val_accuracy: 0.8828\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 12s 332us/step - loss: 0.4122 - accuracy: 0.8629 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 12s 332us/step - loss: 0.3979 - accuracy: 0.8701 - val_loss: 0.3158 - val_accuracy: 0.8902\n",
      "18333/18333 [==============================] - 2s 124us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 14s 372us/step - loss: 0.6316 - accuracy: 0.7765 - val_loss: 0.4361 - val_accuracy: 0.8370\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 13s 347us/step - loss: 0.4334 - accuracy: 0.8480 - val_loss: 0.3913 - val_accuracy: 0.8550\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 12s 329us/step - loss: 0.3888 - accuracy: 0.8634 - val_loss: 0.3492 - val_accuracy: 0.8718\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 13s 360us/step - loss: 0.3578 - accuracy: 0.8739 - val_loss: 0.3572 - val_accuracy: 0.8732\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 13s 352us/step - loss: 0.3416 - accuracy: 0.8794 - val_loss: 0.3233 - val_accuracy: 0.8820\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 12s 339us/step - loss: 0.3321 - accuracy: 0.8846 - val_loss: 0.3216 - val_accuracy: 0.8854\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 13s 346us/step - loss: 0.3249 - accuracy: 0.8865 - val_loss: 0.3393 - val_accuracy: 0.8756\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 13s 349us/step - loss: 0.3107 - accuracy: 0.8904 - val_loss: 0.3008 - val_accuracy: 0.8938\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 12s 329us/step - loss: 0.3030 - accuracy: 0.8936 - val_loss: 0.3237 - val_accuracy: 0.8804\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 13s 348us/step - loss: 0.2951 - accuracy: 0.8971 - val_loss: 0.3296 - val_accuracy: 0.8820\n",
      "18334/18334 [==============================] - 2s 132us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 13s 364us/step - loss: 0.6333 - accuracy: 0.7760 - val_loss: 0.4608 - val_accuracy: 0.8268\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 13s 348us/step - loss: 0.4319 - accuracy: 0.8442 - val_loss: 0.3458 - val_accuracy: 0.8742\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 13s 361us/step - loss: 0.3844 - accuracy: 0.8628 - val_loss: 0.3468 - val_accuracy: 0.8782\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 13s 360us/step - loss: 0.3636 - accuracy: 0.8723 - val_loss: 0.3338 - val_accuracy: 0.8798\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 13s 351us/step - loss: 0.3433 - accuracy: 0.8806 - val_loss: 0.3146 - val_accuracy: 0.8850\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 11s 310us/step - loss: 0.3295 - accuracy: 0.8852 - val_loss: 0.3178 - val_accuracy: 0.8878\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 11s 292us/step - loss: 0.3190 - accuracy: 0.8872 - val_loss: 0.3286 - val_accuracy: 0.8826\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 13s 360us/step - loss: 0.3171 - accuracy: 0.8900 - val_loss: 0.3115 - val_accuracy: 0.8926\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 13s 367us/step - loss: 0.3066 - accuracy: 0.8929 - val_loss: 0.3072 - val_accuracy: 0.8954\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 14s 371us/step - loss: 0.2966 - accuracy: 0.8973 - val_loss: 0.3044 - val_accuracy: 0.8922\n",
      "18333/18333 [==============================] - 2s 135us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 11s 313us/step - loss: 0.6325 - accuracy: 0.7769 - val_loss: 0.4280 - val_accuracy: 0.8410\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 9s 248us/step - loss: 0.4276 - accuracy: 0.8504 - val_loss: 0.3771 - val_accuracy: 0.8626\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 14s 377us/step - loss: 0.3895 - accuracy: 0.8632 - val_loss: 0.3752 - val_accuracy: 0.8642\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 14s 374us/step - loss: 0.3675 - accuracy: 0.8717 - val_loss: 0.3531 - val_accuracy: 0.8732\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 14s 377us/step - loss: 0.3467 - accuracy: 0.8790 - val_loss: 0.3328 - val_accuracy: 0.8828\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 14s 381us/step - loss: 0.3364 - accuracy: 0.8826 - val_loss: 0.3383 - val_accuracy: 0.8770\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 14s 374us/step - loss: 0.3210 - accuracy: 0.8888 - val_loss: 0.3305 - val_accuracy: 0.8808\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 14s 383us/step - loss: 0.3182 - accuracy: 0.8882 - val_loss: 0.3367 - val_accuracy: 0.8826\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 14s 374us/step - loss: 0.3115 - accuracy: 0.8902 - val_loss: 0.3192 - val_accuracy: 0.8838\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 14s 376us/step - loss: 0.3024 - accuracy: 0.8950 - val_loss: 0.3429 - val_accuracy: 0.8722\n",
      "18333/18333 [==============================] - 2s 135us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 14s 392us/step - loss: 1.0251 - accuracy: 0.6313 - val_loss: 0.6162 - val_accuracy: 0.7776\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 14s 388us/step - loss: 0.7185 - accuracy: 0.7403 - val_loss: 0.6161 - val_accuracy: 0.7504\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 14s 393us/step - loss: 0.6690 - accuracy: 0.7639 - val_loss: 0.5282 - val_accuracy: 0.8072\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 14s 388us/step - loss: 0.6424 - accuracy: 0.7734 - val_loss: 0.5116 - val_accuracy: 0.8156\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 14s 386us/step - loss: 0.6138 - accuracy: 0.7839 - val_loss: 0.5026 - val_accuracy: 0.8196\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 14s 387us/step - loss: 0.6006 - accuracy: 0.7960 - val_loss: 0.4748 - val_accuracy: 0.8396\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 14s 393us/step - loss: 0.5826 - accuracy: 0.8006 - val_loss: 0.4486 - val_accuracy: 0.8464\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 14s 394us/step - loss: 0.5765 - accuracy: 0.8106 - val_loss: 0.4273 - val_accuracy: 0.8620\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 12s 335us/step - loss: 0.5612 - accuracy: 0.8163 - val_loss: 0.4375 - val_accuracy: 0.8540\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 12s 340us/step - loss: 0.5560 - accuracy: 0.8206 - val_loss: 0.4563 - val_accuracy: 0.8458\n",
      "18334/18334 [==============================] - 3s 156us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 14s 392us/step - loss: 1.1163 - accuracy: 0.5706 - val_loss: 0.6635 - val_accuracy: 0.7624\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 14s 382us/step - loss: 0.7731 - accuracy: 0.7184 - val_loss: 0.5585 - val_accuracy: 0.7968\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 14s 387us/step - loss: 0.7057 - accuracy: 0.7438 - val_loss: 0.5410 - val_accuracy: 0.8070\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 14s 380us/step - loss: 0.6725 - accuracy: 0.7589 - val_loss: 0.5130 - val_accuracy: 0.8156\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 12s 334us/step - loss: 0.6536 - accuracy: 0.7670 - val_loss: 0.5453 - val_accuracy: 0.8090\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 11s 313us/step - loss: 0.6310 - accuracy: 0.7814 - val_loss: 0.4867 - val_accuracy: 0.8380\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 14s 374us/step - loss: 0.6126 - accuracy: 0.7940 - val_loss: 0.4816 - val_accuracy: 0.8312\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 14s 387us/step - loss: 0.6015 - accuracy: 0.8000 - val_loss: 0.4581 - val_accuracy: 0.8476\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 14s 389us/step - loss: 0.5911 - accuracy: 0.8029 - val_loss: 0.4521 - val_accuracy: 0.8484\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 14s 383us/step - loss: 0.5770 - accuracy: 0.8128 - val_loss: 0.4559 - val_accuracy: 0.8516\n",
      "18333/18333 [==============================] - 3s 150us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 15s 396us/step - loss: 1.0996 - accuracy: 0.5951 - val_loss: 0.6209 - val_accuracy: 0.7804\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 14s 390us/step - loss: 0.7574 - accuracy: 0.7256 - val_loss: 0.5621 - val_accuracy: 0.8008\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 14s 392us/step - loss: 0.6825 - accuracy: 0.7528 - val_loss: 0.5585 - val_accuracy: 0.7988\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 14s 395us/step - loss: 0.6519 - accuracy: 0.7673 - val_loss: 0.5090 - val_accuracy: 0.8110\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 14s 391us/step - loss: 0.6289 - accuracy: 0.7800 - val_loss: 0.4973 - val_accuracy: 0.8202\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 14s 390us/step - loss: 0.6097 - accuracy: 0.7890 - val_loss: 0.4819 - val_accuracy: 0.8220\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 14s 394us/step - loss: 0.5923 - accuracy: 0.7995 - val_loss: 0.4799 - val_accuracy: 0.8422\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 14s 394us/step - loss: 0.5927 - accuracy: 0.7991 - val_loss: 0.4491 - val_accuracy: 0.8488\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 14s 392us/step - loss: 0.5684 - accuracy: 0.8084 - val_loss: 0.4483 - val_accuracy: 0.8474\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 14s 389us/step - loss: 0.5672 - accuracy: 0.8118 - val_loss: 0.4776 - val_accuracy: 0.8440\n",
      "18333/18333 [==============================] - 3s 159us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 34s 923us/step - loss: 2.3043 - accuracy: 0.1019 - val_loss: 2.3031 - val_accuracy: 0.1002\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 34s 915us/step - loss: 2.3033 - accuracy: 0.0993 - val_loss: 2.3025 - val_accuracy: 0.1112\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 33s 913us/step - loss: 2.3033 - accuracy: 0.1002 - val_loss: 2.3030 - val_accuracy: 0.0976\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 34s 917us/step - loss: 2.3033 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 34s 916us/step - loss: 1.9982 - accuracy: 0.1692 - val_loss: 1.7266 - val_accuracy: 0.1916\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 34s 917us/step - loss: 1.7882 - accuracy: 0.1897 - val_loss: 1.7011 - val_accuracy: 0.2030\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 34s 917us/step - loss: 1.7676 - accuracy: 0.1928 - val_loss: 1.6732 - val_accuracy: 0.2002\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 34s 916us/step - loss: 1.7570 - accuracy: 0.1919 - val_loss: 1.6713 - val_accuracy: 0.2010\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 34s 916us/step - loss: 1.7586 - accuracy: 0.1913 - val_loss: 1.6742 - val_accuracy: 0.1924\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 34s 916us/step - loss: 1.7555 - accuracy: 0.1921 - val_loss: 1.6693 - val_accuracy: 0.1934\n",
      "18334/18334 [==============================] - 4s 228us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 34s 923us/step - loss: 2.3042 - accuracy: 0.0997 - val_loss: 2.3031 - val_accuracy: 0.0986\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 34s 914us/step - loss: 2.3034 - accuracy: 0.1001 - val_loss: 2.3029 - val_accuracy: 0.1002\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 34s 914us/step - loss: 2.3033 - accuracy: 0.1022 - val_loss: 2.3029 - val_accuracy: 0.0914\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 34s 918us/step - loss: 2.3032 - accuracy: 0.1009 - val_loss: 2.3025 - val_accuracy: 0.0986\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 34s 915us/step - loss: 2.3033 - accuracy: 0.0992 - val_loss: 2.3028 - val_accuracy: 0.1012\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 34s 916us/step - loss: 2.3032 - accuracy: 0.1013 - val_loss: 2.3031 - val_accuracy: 0.1024\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 34s 914us/step - loss: 2.3032 - accuracy: 0.0984 - val_loss: 2.3021 - val_accuracy: 0.1008\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 34s 915us/step - loss: 2.3032 - accuracy: 0.1012 - val_loss: 2.3031 - val_accuracy: 0.1024\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 34s 915us/step - loss: 2.3032 - accuracy: 0.0997 - val_loss: 2.3030 - val_accuracy: 0.1002\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 34s 917us/step - loss: 2.3033 - accuracy: 0.0979 - val_loss: 2.3028 - val_accuracy: 0.1008\n",
      "18333/18333 [==============================] - 5s 300us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 34s 923us/step - loss: 1.9934 - accuracy: 0.1735 - val_loss: 1.7487 - val_accuracy: 0.2160\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 34s 915us/step - loss: 1.7907 - accuracy: 0.1926 - val_loss: 1.6865 - val_accuracy: 0.2042\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 34s 920us/step - loss: 1.7699 - accuracy: 0.1935 - val_loss: 1.6919 - val_accuracy: 0.2018\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 34s 919us/step - loss: 1.7658 - accuracy: 0.1930 - val_loss: 1.6652 - val_accuracy: 0.2122\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 34s 915us/step - loss: 1.7526 - accuracy: 0.1977 - val_loss: 1.6723 - val_accuracy: 0.2080\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 34s 916us/step - loss: 1.7454 - accuracy: 0.2084 - val_loss: 1.5831 - val_accuracy: 0.2936\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 34s 915us/step - loss: 1.7117 - accuracy: 0.2240 - val_loss: 1.5405 - val_accuracy: 0.2784\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 34s 915us/step - loss: 1.6909 - accuracy: 0.2261 - val_loss: 1.5438 - val_accuracy: 0.2772\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 34s 915us/step - loss: 1.6869 - accuracy: 0.2235 - val_loss: 1.5234 - val_accuracy: 0.2890\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 34s 918us/step - loss: 1.6737 - accuracy: 0.2293 - val_loss: 1.5229 - val_accuracy: 0.2840\n",
      "18333/18333 [==============================] - 5s 298us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 16s 447us/step - loss: 0.8421 - accuracy: 0.7312 - val_loss: 0.5187 - val_accuracy: 0.8270\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 16s 444us/step - loss: 0.6528 - accuracy: 0.7709 - val_loss: 0.4721 - val_accuracy: 0.8372\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 16s 443us/step - loss: 0.6131 - accuracy: 0.7869 - val_loss: 0.4716 - val_accuracy: 0.8324\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 16s 443us/step - loss: 0.5809 - accuracy: 0.7974 - val_loss: 0.4406 - val_accuracy: 0.8502\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 16s 443us/step - loss: 0.5795 - accuracy: 0.7985 - val_loss: 0.4317 - val_accuracy: 0.8482\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 16s 442us/step - loss: 0.5587 - accuracy: 0.8064 - val_loss: 0.4319 - val_accuracy: 0.8458\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 14s 390us/step - loss: 0.5516 - accuracy: 0.8076 - val_loss: 0.4138 - val_accuracy: 0.8482\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 13s 361us/step - loss: 0.5319 - accuracy: 0.8172 - val_loss: 0.4057 - val_accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 16s 444us/step - loss: 0.5463 - accuracy: 0.8104 - val_loss: 0.3976 - val_accuracy: 0.8544\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 16s 445us/step - loss: 0.5312 - accuracy: 0.8162 - val_loss: 0.3971 - val_accuracy: 0.8606\n",
      "18334/18334 [==============================] - 3s 187us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 15s 416us/step - loss: 0.8711 - accuracy: 0.7164 - val_loss: 0.5549 - val_accuracy: 0.7912\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 15s 415us/step - loss: 0.6713 - accuracy: 0.7605 - val_loss: 0.5057 - val_accuracy: 0.8168\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 15s 413us/step - loss: 0.6261 - accuracy: 0.7778 - val_loss: 0.4744 - val_accuracy: 0.8338\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 15s 412us/step - loss: 0.6109 - accuracy: 0.7877 - val_loss: 0.4615 - val_accuracy: 0.8326\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 15s 411us/step - loss: 0.5897 - accuracy: 0.7936 - val_loss: 0.4482 - val_accuracy: 0.8530\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 15s 414us/step - loss: 0.5816 - accuracy: 0.7977 - val_loss: 0.4316 - val_accuracy: 0.8510\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 15s 413us/step - loss: 0.5690 - accuracy: 0.8004 - val_loss: 0.4325 - val_accuracy: 0.8516\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 14s 371us/step - loss: 0.5530 - accuracy: 0.8080 - val_loss: 0.4012 - val_accuracy: 0.8590\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 14s 377us/step - loss: 0.5511 - accuracy: 0.8091 - val_loss: 0.4062 - val_accuracy: 0.8538\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 15s 416us/step - loss: 0.5448 - accuracy: 0.8085 - val_loss: 0.4049 - val_accuracy: 0.8570\n",
      "18333/18333 [==============================] - 3s 190us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 16s 425us/step - loss: 0.8742 - accuracy: 0.7158 - val_loss: 0.5473 - val_accuracy: 0.8098\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 15s 420us/step - loss: 0.6704 - accuracy: 0.7619 - val_loss: 0.4871 - val_accuracy: 0.8278\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 15s 422us/step - loss: 0.6249 - accuracy: 0.7762 - val_loss: 0.4652 - val_accuracy: 0.8358\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 16s 424us/step - loss: 0.5914 - accuracy: 0.7907 - val_loss: 0.4366 - val_accuracy: 0.8422\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 16s 425us/step - loss: 0.5770 - accuracy: 0.7989 - val_loss: 0.4639 - val_accuracy: 0.8250\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 16s 427us/step - loss: 0.5708 - accuracy: 0.7977 - val_loss: 0.4239 - val_accuracy: 0.8482\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 16s 426us/step - loss: 0.5561 - accuracy: 0.8057 - val_loss: 0.4026 - val_accuracy: 0.8544\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 16s 424us/step - loss: 0.5558 - accuracy: 0.8055 - val_loss: 0.4117 - val_accuracy: 0.8530\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 13s 368us/step - loss: 0.5449 - accuracy: 0.8116 - val_loss: 0.4150 - val_accuracy: 0.8510\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 13s 341us/step - loss: 0.5362 - accuracy: 0.8151 - val_loss: 0.4096 - val_accuracy: 0.8534\n",
      "18333/18333 [==============================] - 3s 190us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 12s 327us/step - loss: 1.6998 - accuracy: 0.3370 - val_loss: 1.2725 - val_accuracy: 0.4762\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 12s 319us/step - loss: 1.4780 - accuracy: 0.3563 - val_loss: 1.1541 - val_accuracy: 0.4958\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 12s 320us/step - loss: 1.4241 - accuracy: 0.3574 - val_loss: 1.1176 - val_accuracy: 0.4962\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 12s 319us/step - loss: 1.4113 - accuracy: 0.3586 - val_loss: 1.1086 - val_accuracy: 0.4988\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 12s 319us/step - loss: 1.3903 - accuracy: 0.3634 - val_loss: 1.0755 - val_accuracy: 0.4682\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 12s 320us/step - loss: 1.3768 - accuracy: 0.3649 - val_loss: 1.0754 - val_accuracy: 0.5060\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 12s 320us/step - loss: 1.3901 - accuracy: 0.3572 - val_loss: 1.0778 - val_accuracy: 0.4696\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 12s 320us/step - loss: 1.3708 - accuracy: 0.3640 - val_loss: 1.0567 - val_accuracy: 0.4976\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 12s 318us/step - loss: 1.3587 - accuracy: 0.3708 - val_loss: 1.0365 - val_accuracy: 0.4910\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 12s 319us/step - loss: 1.3618 - accuracy: 0.3674 - val_loss: 1.0396 - val_accuracy: 0.5020\n",
      "18334/18334 [==============================] - 3s 137us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 11s 286us/step - loss: 1.7900 - accuracy: 0.2491 - val_loss: 1.5386 - val_accuracy: 0.2976\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 9s 242us/step - loss: 1.6238 - accuracy: 0.2731 - val_loss: 1.4022 - val_accuracy: 0.3920\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 9s 233us/step - loss: 1.5328 - accuracy: 0.3095 - val_loss: 1.2972 - val_accuracy: 0.3906\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 11s 297us/step - loss: 1.4903 - accuracy: 0.3213 - val_loss: 1.2580 - val_accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 11s 296us/step - loss: 1.4687 - accuracy: 0.3235 - val_loss: 1.2408 - val_accuracy: 0.4070\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 11s 297us/step - loss: 1.4595 - accuracy: 0.3233 - val_loss: 1.2325 - val_accuracy: 0.3962\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 11s 298us/step - loss: 1.4462 - accuracy: 0.3246 - val_loss: 1.2389 - val_accuracy: 0.4112\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 11s 298us/step - loss: 1.4566 - accuracy: 0.3227 - val_loss: 1.2238 - val_accuracy: 0.3962\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 11s 291us/step - loss: 1.4468 - accuracy: 0.3228 - val_loss: 1.2249 - val_accuracy: 0.4356\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 11s 289us/step - loss: 1.4363 - accuracy: 0.3222 - val_loss: 1.2013 - val_accuracy: 0.4082\n",
      "18333/18333 [==============================] - 2s 135us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 12s 320us/step - loss: 1.7266 - accuracy: 0.3557 - val_loss: 1.1820 - val_accuracy: 0.6428\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 12s 318us/step - loss: 1.4663 - accuracy: 0.3946 - val_loss: 1.0182 - val_accuracy: 0.6468\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 12s 318us/step - loss: 1.4190 - accuracy: 0.4027 - val_loss: 0.9791 - val_accuracy: 0.6440\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 12s 320us/step - loss: 1.3955 - accuracy: 0.4092 - val_loss: 0.9584 - val_accuracy: 0.6666\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 12s 320us/step - loss: 1.3891 - accuracy: 0.4071 - val_loss: 0.9166 - val_accuracy: 0.6762\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 12s 322us/step - loss: 1.3679 - accuracy: 0.4104 - val_loss: 0.9022 - val_accuracy: 0.6558\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 12s 315us/step - loss: 1.3623 - accuracy: 0.4123 - val_loss: 0.8905 - val_accuracy: 0.6780\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 9s 243us/step - loss: 1.3616 - accuracy: 0.4126 - val_loss: 0.8909 - val_accuracy: 0.6724\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 11s 313us/step - loss: 1.3507 - accuracy: 0.4159 - val_loss: 0.8739 - val_accuracy: 0.6602\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 7s 193us/step - loss: 1.3485 - accuracy: 0.4161 - val_loss: 0.8728 - val_accuracy: 0.6744\n",
      "18333/18333 [==============================] - 2s 129us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 22s 597us/step - loss: 2.0319 - accuracy: 0.1594 - val_loss: 1.7393 - val_accuracy: 0.1890\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 22s 604us/step - loss: 1.7658 - accuracy: 0.1972 - val_loss: 1.7329 - val_accuracy: 0.2022\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 21s 580us/step - loss: 1.7555 - accuracy: 0.1977 - val_loss: 1.7128 - val_accuracy: 0.1990\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 21s 568us/step - loss: 1.7401 - accuracy: 0.1941 - val_loss: 1.7145 - val_accuracy: 0.1988\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 21s 577us/step - loss: 1.7442 - accuracy: 0.1968 - val_loss: 1.7144 - val_accuracy: 0.2016\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 20s 536us/step - loss: 1.7481 - accuracy: 0.1975 - val_loss: 1.7132 - val_accuracy: 0.2136\n",
      "18334/18334 [==============================] - 3s 171us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 21s 559us/step - loss: 1.9429 - accuracy: 0.1807 - val_loss: 1.6967 - val_accuracy: 0.1924\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 20s 544us/step - loss: 1.7515 - accuracy: 0.2012 - val_loss: 1.6882 - val_accuracy: 0.1988\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 20s 534us/step - loss: 1.7180 - accuracy: 0.2152 - val_loss: 1.5959 - val_accuracy: 0.2866\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 19s 529us/step - loss: 1.6658 - accuracy: 0.2464 - val_loss: 1.5141 - val_accuracy: 0.3054\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 19s 526us/step - loss: 1.6304 - accuracy: 0.2541 - val_loss: 1.5433 - val_accuracy: 0.2788\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 19s 520us/step - loss: 1.6176 - accuracy: 0.2541 - val_loss: 1.4917 - val_accuracy: 0.2994\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 19s 521us/step - loss: 1.6075 - accuracy: 0.2570 - val_loss: 1.4790 - val_accuracy: 0.2926\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 19s 505us/step - loss: 1.6045 - accuracy: 0.2586 - val_loss: 1.4834 - val_accuracy: 0.2902\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 19s 517us/step - loss: 1.6042 - accuracy: 0.2601 - val_loss: 1.4821 - val_accuracy: 0.2916\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 19s 519us/step - loss: 1.5839 - accuracy: 0.2655 - val_loss: 1.4678 - val_accuracy: 0.2926\n",
      "18333/18333 [==============================] - 4s 235us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 19s 516us/step - loss: 1.9867 - accuracy: 0.1694 - val_loss: 1.7049 - val_accuracy: 0.1998\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 21s 559us/step - loss: 1.7589 - accuracy: 0.2006 - val_loss: 1.6918 - val_accuracy: 0.1986\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 19s 516us/step - loss: 1.7413 - accuracy: 0.2020 - val_loss: 1.6821 - val_accuracy: 0.2262\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 20s 547us/step - loss: 1.7339 - accuracy: 0.2009 - val_loss: 1.6755 - val_accuracy: 0.2076\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 21s 560us/step - loss: 1.7185 - accuracy: 0.2097 - val_loss: 1.6647 - val_accuracy: 0.2138\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 19s 531us/step - loss: 1.6701 - accuracy: 0.2383 - val_loss: 1.5167 - val_accuracy: 0.2914\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 20s 537us/step - loss: 1.6146 - accuracy: 0.2602 - val_loss: 1.4953 - val_accuracy: 0.2848\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 21s 568us/step - loss: 1.5997 - accuracy: 0.2614 - val_loss: 1.4736 - val_accuracy: 0.3058\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 20s 559us/step - loss: 1.5908 - accuracy: 0.2628 - val_loss: 1.4731 - val_accuracy: 0.3050\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 20s 557us/step - loss: 1.5804 - accuracy: 0.2655 - val_loss: 1.4666 - val_accuracy: 0.2902\n",
      "18333/18333 [==============================] - 4s 237us/step\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36666/36666 [==============================] - 17s 473us/step - loss: 1.8642 - accuracy: 0.2740 - val_loss: 1.4358 - val_accuracy: 0.4498\n",
      "Epoch 2/10\n",
      "36666/36666 [==============================] - 17s 469us/step - loss: 1.6420 - accuracy: 0.3094 - val_loss: 1.3087 - val_accuracy: 0.4762\n",
      "Epoch 3/10\n",
      "36666/36666 [==============================] - 17s 468us/step - loss: 1.5972 - accuracy: 0.3084 - val_loss: 1.2919 - val_accuracy: 0.4074\n",
      "Epoch 4/10\n",
      "36666/36666 [==============================] - 17s 468us/step - loss: 1.5598 - accuracy: 0.3093 - val_loss: 1.2386 - val_accuracy: 0.4876\n",
      "Epoch 5/10\n",
      "36666/36666 [==============================] - 17s 463us/step - loss: 1.5357 - accuracy: 0.3172 - val_loss: 1.1835 - val_accuracy: 0.4994\n",
      "Epoch 6/10\n",
      "36666/36666 [==============================] - 17s 465us/step - loss: 1.5520 - accuracy: 0.3104 - val_loss: 1.2185 - val_accuracy: 0.4780\n",
      "Epoch 7/10\n",
      "36666/36666 [==============================] - 15s 406us/step - loss: 1.5395 - accuracy: 0.3180 - val_loss: 1.1877 - val_accuracy: 0.5006\n",
      "Epoch 8/10\n",
      "36666/36666 [==============================] - 17s 462us/step - loss: 1.5152 - accuracy: 0.3236 - val_loss: 1.1595 - val_accuracy: 0.4824\n",
      "Epoch 9/10\n",
      "36666/36666 [==============================] - 14s 377us/step - loss: 1.5102 - accuracy: 0.3228 - val_loss: 1.1630 - val_accuracy: 0.4602\n",
      "Epoch 10/10\n",
      "36666/36666 [==============================] - 17s 473us/step - loss: 1.5119 - accuracy: 0.3202 - val_loss: 1.1539 - val_accuracy: 0.5496\n",
      "18334/18334 [==============================] - 3s 190us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 16s 435us/step - loss: 1.8751 - accuracy: 0.2339 - val_loss: 1.5399 - val_accuracy: 0.3908\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 10s 261us/step - loss: 1.6874 - accuracy: 0.2639 - val_loss: 1.3874 - val_accuracy: 0.4352\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 10s 260us/step - loss: 1.6277 - accuracy: 0.2829 - val_loss: 1.3410 - val_accuracy: 0.3960\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 12s 332us/step - loss: 1.5678 - accuracy: 0.2956 - val_loss: 1.2878 - val_accuracy: 0.4050\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 15s 402us/step - loss: 1.5586 - accuracy: 0.2981 - val_loss: 1.2733 - val_accuracy: 0.4158\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 15s 413us/step - loss: 1.5357 - accuracy: 0.3016 - val_loss: 1.2719 - val_accuracy: 0.4246\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 1.5381 - accuracy: 0.3006 - val_loss: 1.2985 - val_accuracy: 0.3928\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 17s 467us/step - loss: 1.5405 - accuracy: 0.3038 - val_loss: 1.2621 - val_accuracy: 0.4100\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 1.5183 - accuracy: 0.3039 - val_loss: 1.2489 - val_accuracy: 0.4154\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 1.5263 - accuracy: 0.3018 - val_loss: 1.2523 - val_accuracy: 0.3914\n",
      "18333/18333 [==============================] - 4s 191us/step\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "36667/36667 [==============================] - 17s 464us/step - loss: 1.8684 - accuracy: 0.2257 - val_loss: 1.5943 - val_accuracy: 0.2802\n",
      "Epoch 2/10\n",
      "36667/36667 [==============================] - 17s 459us/step - loss: 1.7004 - accuracy: 0.2439 - val_loss: 1.5617 - val_accuracy: 0.3040\n",
      "Epoch 3/10\n",
      "36667/36667 [==============================] - 17s 461us/step - loss: 1.6603 - accuracy: 0.2462 - val_loss: 1.5300 - val_accuracy: 0.2808\n",
      "Epoch 4/10\n",
      "36667/36667 [==============================] - 17s 460us/step - loss: 1.6777 - accuracy: 0.2411 - val_loss: 1.5063 - val_accuracy: 0.2854\n",
      "Epoch 5/10\n",
      "36667/36667 [==============================] - 17s 462us/step - loss: 1.6454 - accuracy: 0.2470 - val_loss: 1.5018 - val_accuracy: 0.2896\n",
      "Epoch 6/10\n",
      "36667/36667 [==============================] - 17s 465us/step - loss: 1.6401 - accuracy: 0.2459 - val_loss: 1.4867 - val_accuracy: 0.2894\n",
      "Epoch 7/10\n",
      "36667/36667 [==============================] - 17s 463us/step - loss: 1.6297 - accuracy: 0.2494 - val_loss: 1.4854 - val_accuracy: 0.2918\n",
      "Epoch 8/10\n",
      "36667/36667 [==============================] - 17s 450us/step - loss: 1.6406 - accuracy: 0.2465 - val_loss: 1.4729 - val_accuracy: 0.3070\n",
      "Epoch 9/10\n",
      "36667/36667 [==============================] - 15s 404us/step - loss: 1.6257 - accuracy: 0.2516 - val_loss: 1.4828 - val_accuracy: 0.2942\n",
      "Epoch 10/10\n",
      "36667/36667 [==============================] - 12s 329us/step - loss: 1.6422 - accuracy: 0.2477 - val_loss: 1.4702 - val_accuracy: 0.2908\n",
      "18333/18333 [==============================] - 3s 178us/step\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 16s 290us/step - loss: 0.5346 - accuracy: 0.8099 - val_loss: 0.3774 - val_accuracy: 0.8664\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 16s 283us/step - loss: 0.4221 - accuracy: 0.8494 - val_loss: 0.3395 - val_accuracy: 0.8742\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 16s 283us/step - loss: 0.3883 - accuracy: 0.8625 - val_loss: 0.3308 - val_accuracy: 0.8770\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 15s 274us/step - loss: 0.3711 - accuracy: 0.8680 - val_loss: 0.3115 - val_accuracy: 0.8896\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 14s 247us/step - loss: 0.3561 - accuracy: 0.8731 - val_loss: 0.2957 - val_accuracy: 0.8924\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 14s 252us/step - loss: 0.3469 - accuracy: 0.8772 - val_loss: 0.2962 - val_accuracy: 0.8916\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 16s 283us/step - loss: 0.3393 - accuracy: 0.8787 - val_loss: 0.2858 - val_accuracy: 0.9030\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 16s 284us/step - loss: 0.3316 - accuracy: 0.8831 - val_loss: 0.2874 - val_accuracy: 0.8994\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 16s 283us/step - loss: 0.3276 - accuracy: 0.8860 - val_loss: 0.2772 - val_accuracy: 0.9026\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 16s 283us/step - loss: 0.3226 - accuracy: 0.8855 - val_loss: 0.2741 - val_accuracy: 0.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f81f3341c90>,\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'initial_filter_size': [16, 32, 64],\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f81f3341cd0>,\n",
       "                                        'n_hidden': [1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4...\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                                        'n_nidden_conv': [1, 2, 3]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "\n",
    "keras_clas = keras.wrappers.scikit_learn.KerasClassifier(build_cnn_2)\n",
    "\n",
    "param_distribs= {\n",
    "    'initial_filter_size': [16, 32, 64],\n",
    "    'n_nidden_conv': [1, 2, 3],\n",
    "    'n_hidden': [1, 2, 3],\n",
    "    'n_neurons':np.arange(1, 100), \n",
    "    'learning_rate':reciprocal(3e-4, 3e-2)\n",
    "    }\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_clas, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(preprocessing_image_for_cnn(Xf_train), yf_train, epochs=10,\n",
    "                  validation_data=(preprocessing_image_for_cnn(Xf_valid), yf_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iilvog8vRhmE",
    "outputId": "70143191-d51d-4224-d1de-e0adbca42146",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_initial_filter_size</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_hidden</th>\n",
       "      <th>param_n_neurons</th>\n",
       "      <th>param_n_nidden_conv</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174.528564</td>\n",
       "      <td>7.476765</td>\n",
       "      <td>3.558786</td>\n",
       "      <td>0.046541</td>\n",
       "      <td>64</td>\n",
       "      <td>0.00309662</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>{'initial_filter_size': 64, 'learning_rate': 0...</td>\n",
       "      <td>0.749918</td>\n",
       "      <td>0.741232</td>\n",
       "      <td>0.709431</td>\n",
       "      <td>0.733527</td>\n",
       "      <td>0.017403</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.593863</td>\n",
       "      <td>2.877537</td>\n",
       "      <td>2.320793</td>\n",
       "      <td>0.045181</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00150603</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>{'initial_filter_size': 32, 'learning_rate': 0...</td>\n",
       "      <td>0.895113</td>\n",
       "      <td>0.895544</td>\n",
       "      <td>0.897780</td>\n",
       "      <td>0.896145</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.441344</td>\n",
       "      <td>6.641100</td>\n",
       "      <td>1.516016</td>\n",
       "      <td>0.547886</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0286736</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>{'initial_filter_size': 16, 'learning_rate': 0...</td>\n",
       "      <td>0.878968</td>\n",
       "      <td>0.891616</td>\n",
       "      <td>0.887634</td>\n",
       "      <td>0.886073</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.495724</td>\n",
       "      <td>1.703665</td>\n",
       "      <td>2.462021</td>\n",
       "      <td>0.026847</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00293031</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>{'initial_filter_size': 16, 'learning_rate': 0...</td>\n",
       "      <td>0.883386</td>\n",
       "      <td>0.891234</td>\n",
       "      <td>0.871489</td>\n",
       "      <td>0.882036</td>\n",
       "      <td>0.008117</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140.590379</td>\n",
       "      <td>3.061455</td>\n",
       "      <td>2.847848</td>\n",
       "      <td>0.070740</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00545897</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>{'initial_filter_size': 32, 'learning_rate': 0...</td>\n",
       "      <td>0.840515</td>\n",
       "      <td>0.852343</td>\n",
       "      <td>0.839088</td>\n",
       "      <td>0.843982</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>336.932208</td>\n",
       "      <td>0.280884</td>\n",
       "      <td>5.049846</td>\n",
       "      <td>0.610363</td>\n",
       "      <td>64</td>\n",
       "      <td>0.00327991</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>{'initial_filter_size': 64, 'learning_rate': 0...</td>\n",
       "      <td>0.199411</td>\n",
       "      <td>0.096874</td>\n",
       "      <td>0.281405</td>\n",
       "      <td>0.192564</td>\n",
       "      <td>0.075489</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>152.809499</td>\n",
       "      <td>3.847469</td>\n",
       "      <td>3.475464</td>\n",
       "      <td>0.028792</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000380521</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>{'initial_filter_size': 64, 'learning_rate': 0...</td>\n",
       "      <td>0.856660</td>\n",
       "      <td>0.858125</td>\n",
       "      <td>0.846943</td>\n",
       "      <td>0.853909</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>110.711710</td>\n",
       "      <td>5.618870</td>\n",
       "      <td>2.453525</td>\n",
       "      <td>0.066396</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000359626</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>{'initial_filter_size': 32, 'learning_rate': 0...</td>\n",
       "      <td>0.495582</td>\n",
       "      <td>0.403426</td>\n",
       "      <td>0.671630</td>\n",
       "      <td>0.523545</td>\n",
       "      <td>0.111264</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>174.164007</td>\n",
       "      <td>32.956448</td>\n",
       "      <td>3.937799</td>\n",
       "      <td>0.561161</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000702288</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>{'initial_filter_size': 64, 'learning_rate': 0...</td>\n",
       "      <td>0.198593</td>\n",
       "      <td>0.298696</td>\n",
       "      <td>0.287296</td>\n",
       "      <td>0.261527</td>\n",
       "      <td>0.044745</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>158.267027</td>\n",
       "      <td>9.172821</td>\n",
       "      <td>3.419936</td>\n",
       "      <td>0.109420</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0175085</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>{'initial_filter_size': 64, 'learning_rate': 0...</td>\n",
       "      <td>0.530490</td>\n",
       "      <td>0.385534</td>\n",
       "      <td>0.289151</td>\n",
       "      <td>0.401727</td>\n",
       "      <td>0.099190</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     174.528564      7.476765         3.558786        0.046541   \n",
       "1     102.593863      2.877537         2.320793        0.045181   \n",
       "2     100.441344      6.641100         1.516016        0.547886   \n",
       "3     129.495724      1.703665         2.462021        0.026847   \n",
       "4     140.590379      3.061455         2.847848        0.070740   \n",
       "5     336.932208      0.280884         5.049846        0.610363   \n",
       "6     152.809499      3.847469         3.475464        0.028792   \n",
       "7     110.711710      5.618870         2.453525        0.066396   \n",
       "8     174.164007     32.956448         3.937799        0.561161   \n",
       "9     158.267027      9.172821         3.419936        0.109420   \n",
       "\n",
       "  param_initial_filter_size param_learning_rate param_n_hidden  \\\n",
       "0                        64          0.00309662              3   \n",
       "1                        32          0.00150603              1   \n",
       "2                        16           0.0286736              1   \n",
       "3                        16          0.00293031              1   \n",
       "4                        32          0.00545897              3   \n",
       "5                        64          0.00327991              2   \n",
       "6                        64         0.000380521              1   \n",
       "7                        32         0.000359626              2   \n",
       "8                        64         0.000702288              3   \n",
       "9                        64           0.0175085              2   \n",
       "\n",
       "  param_n_neurons param_n_nidden_conv  \\\n",
       "0              55                   1   \n",
       "1              90                   1   \n",
       "2              29                   2   \n",
       "3              79                   3   \n",
       "4              99                   2   \n",
       "5               8                   3   \n",
       "6              27                   1   \n",
       "7              12                   1   \n",
       "8              17                   2   \n",
       "9               9                   1   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'initial_filter_size': 64, 'learning_rate': 0...           0.749918   \n",
       "1  {'initial_filter_size': 32, 'learning_rate': 0...           0.895113   \n",
       "2  {'initial_filter_size': 16, 'learning_rate': 0...           0.878968   \n",
       "3  {'initial_filter_size': 16, 'learning_rate': 0...           0.883386   \n",
       "4  {'initial_filter_size': 32, 'learning_rate': 0...           0.840515   \n",
       "5  {'initial_filter_size': 64, 'learning_rate': 0...           0.199411   \n",
       "6  {'initial_filter_size': 64, 'learning_rate': 0...           0.856660   \n",
       "7  {'initial_filter_size': 32, 'learning_rate': 0...           0.495582   \n",
       "8  {'initial_filter_size': 64, 'learning_rate': 0...           0.198593   \n",
       "9  {'initial_filter_size': 64, 'learning_rate': 0...           0.530490   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.741232           0.709431         0.733527        0.017403   \n",
       "1           0.895544           0.897780         0.896145        0.001169   \n",
       "2           0.891616           0.887634         0.886073        0.005280   \n",
       "3           0.891234           0.871489         0.882036        0.008117   \n",
       "4           0.852343           0.839088         0.843982        0.005941   \n",
       "5           0.096874           0.281405         0.192564        0.075489   \n",
       "6           0.858125           0.846943         0.853909        0.004962   \n",
       "7           0.403426           0.671630         0.523545        0.111264   \n",
       "8           0.298696           0.287296         0.261527        0.044745   \n",
       "9           0.385534           0.289151         0.401727        0.099190   \n",
       "\n",
       "   rank_test_score  \n",
       "0                6  \n",
       "1                1  \n",
       "2                2  \n",
       "3                3  \n",
       "4                5  \n",
       "5               10  \n",
       "6                4  \n",
       "7                7  \n",
       "8                9  \n",
       "9                8  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df = pd.DataFrame(rnd_search_cv.cv_results_)\n",
    "params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_filter_size': 32,\n",
       " 'learning_rate': 0.00150603481780574,\n",
       " 'n_hidden': 1,\n",
       " 'n_neurons': 90,\n",
       " 'n_nidden_conv': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 128us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8942999839782715"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cnn = rnd_search_cv.best_estimator_\n",
    "best_cnn.score(preprocessing_image_for_cnn(Xf_test), yf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_373 (Conv2D)          (None, 28, 28, 32)        1600      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_224 (MaxPoolin (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_374 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_375 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_225 (MaxPoolin (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_75 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 90)                282330    \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 10)                910       \n",
      "=================================================================\n",
      "Total params: 340,264\n",
      "Trainable params: 340,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_cnn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 15s 266us/step - loss: 0.5410 - accuracy: 0.8083 - val_loss: 0.3827 - val_accuracy: 0.8618\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 16s 293us/step - loss: 0.4210 - accuracy: 0.8494 - val_loss: 0.3379 - val_accuracy: 0.8764\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 14s 259us/step - loss: 0.3874 - accuracy: 0.8622 - val_loss: 0.3112 - val_accuracy: 0.8874\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 14s 258us/step - loss: 0.3697 - accuracy: 0.8690 - val_loss: 0.3014 - val_accuracy: 0.8914\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 16s 285us/step - loss: 0.3522 - accuracy: 0.8757 - val_loss: 0.2999 - val_accuracy: 0.8914\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 16s 285us/step - loss: 0.3452 - accuracy: 0.8770 - val_loss: 0.2959 - val_accuracy: 0.8924\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 15s 270us/step - loss: 0.3397 - accuracy: 0.8783 - val_loss: 0.2822 - val_accuracy: 0.8984\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 14s 257us/step - loss: 0.3258 - accuracy: 0.8836 - val_loss: 0.2786 - val_accuracy: 0.9024\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 12s 217us/step - loss: 0.3197 - accuracy: 0.8862 - val_loss: 0.2702 - val_accuracy: 0.9040\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 16s 288us/step - loss: 0.3168 - accuracy: 0.8867 - val_loss: 0.2642 - val_accuracy: 0.9066\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 16s 287us/step - loss: 0.3107 - accuracy: 0.8891 - val_loss: 0.2572 - val_accuracy: 0.9056\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 16s 285us/step - loss: 0.3070 - accuracy: 0.8901 - val_loss: 0.2647 - val_accuracy: 0.9048\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 13s 232us/step - loss: 0.3090 - accuracy: 0.8890 - val_loss: 0.2656 - val_accuracy: 0.9026\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 15s 273us/step - loss: 0.2998 - accuracy: 0.8918 - val_loss: 0.2612 - val_accuracy: 0.9022\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 16s 286us/step - loss: 0.2978 - accuracy: 0.8927 - val_loss: 0.2551 - val_accuracy: 0.9058\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 16s 288us/step - loss: 0.2950 - accuracy: 0.8951 - val_loss: 0.2620 - val_accuracy: 0.9054\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 16s 287us/step - loss: 0.2906 - accuracy: 0.8957 - val_loss: 0.2544 - val_accuracy: 0.9074\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 16s 287us/step - loss: 0.2913 - accuracy: 0.8959 - val_loss: 0.2533 - val_accuracy: 0.9080\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 16s 287us/step - loss: 0.2882 - accuracy: 0.8983 - val_loss: 0.2722 - val_accuracy: 0.9032\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 16s 288us/step - loss: 0.2891 - accuracy: 0.8965 - val_loss: 0.2588 - val_accuracy: 0.9038\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 16s 288us/step - loss: 0.2835 - accuracy: 0.9004 - val_loss: 0.2438 - val_accuracy: 0.9096\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 16s 288us/step - loss: 0.2807 - accuracy: 0.9014 - val_loss: 0.2576 - val_accuracy: 0.9082\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 16s 285us/step - loss: 0.2790 - accuracy: 0.9005 - val_loss: 0.2491 - val_accuracy: 0.9094\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 16s 288us/step - loss: 0.2767 - accuracy: 0.9005 - val_loss: 0.2381 - val_accuracy: 0.9148\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 16s 288us/step - loss: 0.2736 - accuracy: 0.9046 - val_loss: 0.2496 - val_accuracy: 0.9130\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 16s 288us/step - loss: 0.2719 - accuracy: 0.9037 - val_loss: 0.2497 - val_accuracy: 0.9106\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 16s 288us/step - loss: 0.2758 - accuracy: 0.9034 - val_loss: 0.2502 - val_accuracy: 0.9084\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 16s 288us/step - loss: 0.2730 - accuracy: 0.9040 - val_loss: 0.2484 - val_accuracy: 0.9080\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 16s 288us/step - loss: 0.2733 - accuracy: 0.9044 - val_loss: 0.2506 - val_accuracy: 0.9114\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 13s 243us/step - loss: 0.2740 - accuracy: 0.9030 - val_loss: 0.2428 - val_accuracy: 0.9116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f81f0f5d9d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cnn.fit(preprocessing_image_for_cnn(Xf_train), yf_train, epochs=30,\n",
    "             validation_data=(preprocessing_image_for_cnn(Xf_valid), yf_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 146us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26655174696445466, 0.9018999934196472]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cnn.model.evaluate(preprocessing_image_for_cnn(Xf_test), yf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cnn.model.save(\"./models/cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4Zd_JADIy7dx"
   ],
   "name": "Task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}